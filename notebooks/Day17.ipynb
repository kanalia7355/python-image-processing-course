{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 17: エッジ検出（Sobel、Laplacian、Canny）\n",
    "\n",
    "## Learning Objectives\n",
    "- Sobel演算子によるエッジ検出を理解する\n",
    "- Laplacianフィルタの原理と特性を把握する\n",
    "- Cannyエッジ検出アルゴリズムを完全に理解する\n",
    "- 各手法の特性と適用場面を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory (2 hours)\n",
    "\n",
    "## 17.1 エッジ検出の基本概念\n",
    "\n",
    "エッジ検出は画像処理における最も基本的なタスクの一つで、物体の輪郭や境界を検出する技術でございます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.1 エッジとは？\n",
    "\n",
    "```\n",
    "【エッジの定義】\n",
    "\n",
    "エッジは画像内の輝度値が急激に変化する領域でございます。\n",
    "\n",
    "物理的な意味:\n",
    "- 物体の境界\n",
    "- 表面の変化（材質、照明）\n",
    "- 深さや距離の不連続\n",
    "\n",
    "数学的表現:\n",
    "I(x,y) の勾配 ∇I = [∂I/∂x, ∂I/∂y] が大きい場所\n",
    "勾配の大きさ: |∇I| = √[(∂I/∂x)² + (∂I/∂y)²]\n",
    "勾配の方向: θ = tan⁻¹[(∂I/∂y)/(∂I/∂x)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.1.2 エッジ検出の評価指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 精度（Accuracy）\n",
    "\n",
    "```\n",
    "【評価方法】\n",
    "\n",
    "- True Positive: 実際のエッジを正しく検出\n",
    "- False Positive: 背景をエッジと誤検出\n",
    "- False Negative: 実際のエッジを検出失敗\n",
    "\n",
    "定量評価:\n",
    "- Precision = TP / (TP + FP)\n",
    "- Recall = TP / (TP + FN)\n",
    "- F1-score = 2 × (Precision × Recall) / (Precision + Recall)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 計算効率\n",
    "\n",
    "```\n",
    "【性能比較】\n",
    "\n",
    "- Sobel: O(n) - 高速、リアルタイム処理に適す\n",
    "- Laplacian: O(n) - 高速、二階微分なのでノイズに敏感\n",
    "- Canny: O(n log n) - 遅いが高精度、最適化可能\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17.2 Sobel演算子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2.1 Sobelの原理\n",
    "\n",
    "```\n",
    "【Sobelの特徴】\n",
    "\n",
    "1. 一次微分による勾配計算\n",
    "2. 3×3カーネルによる平滑化と微分の同時処理\n",
    "3. 方向別に水平・垂直成分を検出\n",
    "\n",
    "数学的表現:\n",
    "G_x = Σ Σ I(x,y) × G_x'(i,j)\n",
    "G_y = Σ Σ I(x,y) × G_y'(i,j)\n",
    "\n",
    "勾配の大きさ: G = √(G_x² + G_y²)\n",
    "勾配の方向: θ = tan⁻¹(G_y / G_x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2.2 Sobelカーネル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "【Sobelカーネルの設計】\n",
    "\n",
    "水平方向（G_x）:\n",
    "G_x = [-1  0  1]\n",
    "      [-2  0  2]\n",
    "      [-1  0  1]\n",
    "\n",
    "垂直方向（G_y）:\n",
    "G_y = [-1 -2 -1]\n",
    "      [ 0  0  0]\n",
    "      [ 1  2  1]\n",
    "\n",
    "特徴:\n",
    "- 中心の重みが大きい（微分強化）\n",
    "- 周辺が小さい（平滑化効果）\n",
    "- 45度方向のエッジも検出可能\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17.2.3 Sobelの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy import ndimage\n",
    "\n",
    "# Sobel演算子の実装\n",
    "def sobel_edge_detection(image):\n",
    "    \"\"\"Sobelエッジ検出の実装\"\"\"\n",
    "    # グレースケール変換\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Sobelカーネル\n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    sobel_y = np.array([\n",
    "        [-1, -2, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  2,  1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    # 畳み込み演算\n",
    "    grad_x = ndimage.convolve(image.astype(np.float32), sobel_x, mode='reflect')\n",
    "    grad_y = ndimage.convolve(image.astype(np.float32), sobel_y, mode='reflect')\n",
    "    \n",
    "    # 勾配の大きさと方向\n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    angle = np.arctan2(grad_y, grad_x) * 180 / np.pi\n",
    "    \n",
    "    return magnitude, angle, grad_x, grad_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## 17.3 Laplacianフィルタ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 17.3.1 Laplacianの原理\n",
    "\n",
    "```\n",
    "【Laplacianの特徴】\n",
    "\n",
    "1. 二階微分によるエッジ検出\n",
    "2. 方向に依存しない（ isotropic ）\n",
    "3. エッジの両側を検出（zero-crossing）\n",
    "\n",
    "数学的表現:\n",
    "∇²I = ∂²I/∂x² + ∂²I/∂y²\n",
    "\n",
    "離散化:\n",
    "∇²I(x,y) = I(x+1,y) + I(x-1,y) + I(x,y+1) + I(x,y-1) - 4I(x,y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 17.3.2 Laplacianカーネル"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### 標準Laplacian\n",
    "\n",
    "```\n",
    "【4近傍Laplacian】\n",
    "L = [ 0  1  0]\n",
    "    [ 1 -4  1]\n",
    "    [ 0  1  0]\n",
    "\n",
    "【8近傍Laplacian】\n",
    "L = [ 1  1  1]\n",
    "    [ 1 -8  1]\n",
    "    [ 1  1  1]\n",
    "\n",
    "特徴:\n",
    "- 中心が負、周辺が正\n",
    "- エッジで値が大きくなる\n",
    "- 方向に依存しない\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### LoG（Laplacian of Gaussian）\n",
    "\n",
    "```\n",
    "【LoGの利点】\n",
    "\n",
    "1. ガウシアン平滑化でノイズ除去\n",
    "2. 二階微分でエッジ検出\n",
    "3. 「Marr-Hildreth演算子」とも呼ばれる\n",
    "\n",
    "ガウシアン:\n",
    "G(x,y) = (1/2πσ²) × exp(-(x²+y²)/2σ²)\n",
    "\n",
    "LoG:\n",
    "LoG = ∇²G = -(x²+y²-σ²)/(2πσ⁴) × exp(-(x²+y²)/2σ²)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 17.3.3 Laplacianの実装"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Laplacianフィルタの実装\n",
    "def laplacian_edge_detection(image, use_log=False, sigma=1.0):\n",
    "    \"\"\"Laplacianエッジ検出の実装\"\"\"\n",
    "    # グレースケール変換\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    if use_log:\n",
    "        # LoG（Laplacian of Gaussian）\n",
    "        from scipy.ndimage import gaussian_filter\n",
    "        \n",
    "        # ガウシアン平滑化\n",
    "        smoothed = gaussian_filter(image.astype(np.float32), sigma=sigma)\n",
    "        \n",
    "        # Laplacian適用\n",
    "        laplacian_kernel = np.array([\n",
    "            [ 0,  1,  0],\n",
    "            [ 1, -4,  1],\n",
    "            [ 0,  1,  0]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        edges = ndimage.convolve(smoothed, laplacian_kernel, mode='reflect')\n",
    "    else:\n",
    "        # 通常のLaplacian\n",
    "        laplacian_kernel = np.array([\n",
    "            [ 0,  1,  0],\n",
    "            [ 1, -4,  1],\n",
    "            [ 0,  1,  0]\n",
    "        ], dtype=np.float32)\n",
    "        \n",
    "        edges = ndimage.convolve(image.astype(np.float32), laplacian_kernel, mode='reflect')\n",
    "    \n",
    "    # Zero-crossingの検出\n",
    "    edges = np.abs(edges)\n",
    "    \n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## 17.4 Cannyエッジ検出アルゴリズム"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 17.4.1 Cannyの特徴\n",
    "\n",
    "```\n",
    "【Cannyの特徴】\n",
    "\n",
    "1. 最適化されたエッジ検出アルゴリズム\n",
    "2. 6段階の処理ステップ\n",
    "3. 最大の SNR（信号対雑音比）を実現\n",
    "\n",
    "設計基準:\n",
    "- 優れた検出（エッジを漏らさない）\n",
    "- 優れた定位（エッジの位置を正確に）\n",
    "- 単一応答（1つのエッジに1つの応答）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### 17.4.2 Cannyの処理ステップ"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### ステップ1: ガウシアン平滑化\n",
    "\n",
    "```\n",
    "【ノイズ除去】\n",
    "\n",
    "目的:\n",
    "- 高周波ノイズの除去\n",
    "- スムーズなエッジ検出\n",
    "\n",
    "カーネルサイズの選択:\n",
    "- σ = 1.0: 弱い平滑化\n",
    " - σ = 2.0: 中程度の平滑化\n",
    " - σ = 3.0: 強い平滑化\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### ステップ2: 勾配計算\n",
    "\n",
    "```\n",
    "【Sobel演算子の適用】\n",
    "\n",
    "G_x = ∂I/∂x  （水平勾配）\n",
    "G_y = ∂I/∂y  （垂直勾配）\n",
    "\n",
    "勾配の大きさ: G = √(G_x² + G_y²)\n",
    "勾配の方向: θ = tan⁻¹(G_y / G_x)\n",
    "\n",
    "非极大値抑制の準備\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### ステップ3: 非极大値抑制\n",
    "\n",
    "```\n",
    "【エッジの幅を1ピクセルに】\n",
    "\n",
    "アルゴリズム:\n",
    "1. 勾配方向に隣接ピクセルを比較\n",
    "2. もし現在のピクセルが最大なら保持\n",
    "3. そうであれば、エッジではないとマーク\n",
    "\n",
    "方向量子化:\n",
    "- 0°, 45°, 90°, 135° の4方向に量子化\n",
    "- 計算を簡略化\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### ステップ4: 閾値処理\n",
    "\n",
    "```\n",
    "【二値化】\n",
    "\n",
    "低い閾値（low_threshold）\n",
    "- 弱いエッジの候補\n",
    "信頼性が低いがエッジを漏らさない\n",
    "\n",
    "高い閾値（high_threshold）\n",
    "- 強いエッジの候補\n",
    "信頼性が高い\n",
    "\n",
    "閾値比通常: 1:2 または 1:3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "#### ステップ5: エッジトラッキング（ヒステリシス閾値）\n",
    "\n",
    "```\n",
    "【連続性の考慮】\n",
    "\n",
    "アルゴリズム:\n",
    "1. 強いエッジ（high_threshold以上）を開始点とする\n",
    "2. 連続する弱いエッジを追跡\n",
    "3. 弱いエッジがlow_threshold以上なら保持\n",
    "4. low_thresholdを切ったら追跡終了\n",
    "\n",
    "利点:\n",
    "- エッジの連続性を維持\n",
    "- 孤立したノイズを除去\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### 17.4.3 Cannyの実装"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Cannyエッジ検出の実装\n",
    "def canny_edge_detection(image, low_threshold=0.05, high_threshold=0.15, sigma=1.0):\n",
    "    \"\"\"Cannyエッジ検出の実装\"\"\"\n",
    "    # グレースケール変換\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # ステップ1: ガウシアン平滑化\n",
    "    from scipy.ndimage import gaussian_filter\n",
    "    smoothed = gaussian_filter(image.astype(np.float32), sigma=sigma)\n",
    "    \n",
    "    # ステップ2: 勾配計算\n",
    "    sobel_x = np.array([\n",
    "        [-1, 0, 1],\n",
    "        [-2, 0, 2],\n",
    "        [-1, 0, 1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    sobel_y = np.array([\n",
    "        [-1, -2, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  2,  1]\n",
    "    ], dtype=np.float32)\n",
    "    \n",
    "    grad_x = ndimage.convolve(smoothed, sobel_x, mode='reflect')\n",
    "    grad_y = ndimage.convolve(smoothed, sobel_y, mode='reflect')\n",
    "    \n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    \n",
    "    # ステップ3: 非极大値抑制\n",
    "    suppressed = non_max_suppression(magnitude, grad_x, grad_y)\n",
    "    \n",
    "    # ステップ4と5: ヒステリシス閾値処理\n",
    "    edges = hysteresis_thresholding(suppressed, low_threshold, high_threshold)\n",
    "    \n",
    "    return edges.astype(np.uint8)\n",
    "\n",
    "def non_max_suppression(magnitude, grad_x, grad_y):\n",
    "    \"\"\"非极大値抑制の実装\"\"\"\n",
    "    # 方向の量子化\n",
    "    angle = np.arctan2(grad_y, grad_x) * 180 / np.pi\n",
    "    angle = np.where(angle < 0, angle + 180, angle)\n",
    "    \n",
    "    # 4方向に量子化\n",
    "    angle = np.round(angle / 45) * 45 % 180\n",
    "    \n",
    "    # 出力配列\n",
    "    suppressed = np.zeros_like(magnitude)\n",
    "    \n",
    "    # 各方向での非极大値抑制\n",
    "    h, w = magnitude.shape\n",
    "    \n",
    "    for i in range(1, h-1):\n",
    "        for j in range(1, w-1):\n",
    "            current_mag = magnitude[i, j]\n",
    "            current_angle = angle[i, j]\n",
    "            \n",
    "            if current_angle == 0:  # 水平方向\n",
    "                neighbor1 = magnitude[i, j-1]\n",
    "                neighbor2 = magnitude[i, j+1]\n",
    "            elif current_angle == 45:  # 45度方向\n",
    "                neighbor1 = magnitude[i-1, j+1]\n",
    "                neighbor2 = magnitude[i+1, j-1]\n",
    "            elif current_angle == 90:  # 垂直方向\n",
    "                neighbor1 = magnitude[i-1, j]\n",
    "                neighbor2 = magnitude[i+1, j]\n",
    "            else:  # 135度方向\n",
    "                neighbor1 = magnitude[i-1, j-1]\n",
    "                neighbor2 = magnitude[i+1, j+1]\n",
    "            \n",
    "            # もし現在のピクセルが最大なら保持\n",
    "            if current_mag >= neighbor1 and current_mag >= neighbor2:\n",
    "                suppressed[i, j] = current_mag\n",
    "    \n",
    "    return suppressed\n",
    "\n",
    "def hysteresis_thresholding(image, low_threshold, high_threshold):\n",
    "    \"\"\"ヒステリシス閾値処理の実装\"\"\"\n",
    "    # 閾値を正規化された値に変換\n",
    "    max_val = np.max(image)\n",
    "    if max_val > 0:\n",
    "        high_threshold = high_threshold * max_val\n",
    "        low_threshold = low_threshold * max_val\n",
    "    \n",
    "    # 強いエッジと弱いエッジをマーク\n",
    "    strong_edges = (image > high_threshold).astype(np.uint8)\n",
    "    weak_edges = ((image > low_threshold) & (image <= high_threshold)).astype(np.uint8)\n",
    "    \n",
    "    # エッジトラッキング\n",
    "    final_edges = np.zeros_like(image)\n",
    "    \n",
    "    # 強いエッジを起点に探索\n",
    "    for i in range(1, image.shape[0]-1):\n",
    "        for j in range(1, image.shape[1]-1):\n",
    "            if strong_edges[i, j] == 1:\n",
    "                # 強いエッジは保持\n",
    "                final_edges[i, j] = 255\n",
    "                # 8近傍の弱いエッジも保持\n",
    "                for di in [-1, 0, 1]:\n",
    "                    for dj in [-1, 0, 1]:\n",
    "                        if weak_edges[i+di, j+dj] == 1:\n",
    "                            final_edges[i+di, j+dj] = 255\n",
    "    \n",
    "    return final_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "---\n",
    "\n",
    "# Part 2: Practice (2 hours)\n",
    "\n",
    "それでは、学んだ知識を実際に使ってみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## Exercise 17.1: Sobelエッジ検出の実装"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# テスト画像の読み込み\n",
    "def create_test_image():\n",
    "    \"\"\"テスト用のシンプルな画像を作成\"\"\"\n",
    "    image = np.zeros((200, 200), dtype=np.uint8)\n",
    "    \n",
    "    # 白い四角形\n",
    "    image[50:150, 50:150] = 200\n",
    "    \n",
    "    # 斜めの線\n",
    "    for i in range(200):\n",
    "        image[i, i] = 200\n",
    "    \n",
    "    # 円\n",
    "    center_x, center_y = 150, 100\n",
    "    radius = 40\n",
    "    for y in range(200):\n",
    "        for x in range(200):\n",
    "            if (x - center_x)**2 + (y - center_y)**2 <= radius**2:\n",
    "                image[y, x] = 200\n",
    "    \n",
    "    return image\n",
    "\n",
    "# テスト画像を作成\n",
    "test_image = create_test_image()\n",
    "\n",
    "# Sobelエッジ検出の実行\n",
    "magnitude, angle, grad_x, grad_y = sobel_edge_detection(test_image)\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(grad_x, cmap='gray')\n",
    "plt.title('Gradient X')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(grad_y, cmap='gray')\n",
    "plt.title('Gradient Y')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(magnitude, cmap='gray')\n",
    "plt.title('Gradient Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "magnitude_normalized = magnitude / magnitude.max() * 255\n",
    "plt.imshow(magnitude_normalized, cmap='gray')\n",
    "plt.title('Normalized Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "angle_normalized = (angle + 180) / 360 * 255\n",
    "plt.imshow(angle_normalized, cmap='hsv')\n",
    "plt.title('Gradient Direction')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## Exercise 17.2: Laplacianエッジ検出の比較"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Laplacianエッジ検出の比較\n",
    "laplacian_edges = laplacian_edge_detection(test_image, use_log=False)\n",
    "log_edges = laplacian_edge_detection(test_image, use_log=True, sigma=1.0)\n",
    "\n",
    "# OpenCVのLaplacianとの比較\n",
    "opencv_laplacian = cv2.Laplacian(test_image, cv2.CV_64F)\n",
    "opencv_laplacian = np.abs(opencv_laplacian)\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(laplacian_edges, cmap='gray')\n",
    "plt.title('Laplacian Filter')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(log_edges, cmap='gray')\n",
    "plt.title('LoG (σ=1.0)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(opencv_laplacian, cmap='gray')\n",
    "plt.title('OpenCV Laplacian')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 異なるσのLoGの比較\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "sigmas = [0.5, 1.0, 2.0]\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    log_sigma = laplacian_edge_detection(test_image, use_log=True, sigma=sigma)\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(log_sigma, cmap='gray')\n",
    "    plt.title(f'LoG (σ={sigma})')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## Exercise 17.3: Cannyエッジ検出のパラメータ調整"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Cannyエッジ検出のパラメータ調整\n",
    "def compare_canny_parameters(image, low_thresholds=[0.05, 0.1, 0.2], high_threshold_ratios=[2, 3, 4]):\n",
    "    \"\"\"Cannyのパラメータ比較\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    idx = 1\n",
    "    for low_thresh in low_thresholds:\n",
    "        for ratio in high_threshold_ratios:\n",
    "            high_thresh = low_thresh * ratio\n",
    "            \n",
    "            canny_edges = canny_edge_detection(\n",
    "                image, \n",
    "                low_threshold=low_thresh,\n",
    "                high_threshold=high_thresh,\n",
    "                sigma=1.0\n",
    "            )\n",
    "            \n",
    "            plt.subplot(3, 3, idx)\n",
    "            plt.imshow(canny_edges, cmap='gray')\n",
    "            plt.title(f'Low={low_thresh:.2f}, High={high_thresh:.2f}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            idx += 1\n",
    "    \n",
    "    plt.suptitle('Canny Parameter Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# パラメータ比較\n",
    "compare_canny_parameters(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## Exercise 17.4: 実画像での比較"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# 実画像での比較\n",
    "from google.colab.patches import cv2_imshow\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# 画像の読み込み\n",
    "try:\n",
    "    url = 'https://upload.wikimedia.org/wikipedia/commons/4/43/Lenna.png'\n",
    "    response = requests.get(url)\n",
    "    image = cv2.imdecode(np.frombuffer(response.content, np.uint8), cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "except:\n",
    "    # エラー時はテスト画像を使用\n",
    "    image = test_image\n",
    "\n",
    "# 各手法の実行\n",
    "sobel_edges = sobel_edge_detection(image)\n",
    "laplacian_edges = laplacian_edge_detection(image, use_log=True, sigma=1.0)\n",
    "canny_edges = canny_edge_detection(image, low_threshold=0.1, high_threshold=0.2, sigma=1.0)\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(sobel_edges, cmap='gray')\n",
    "plt.title('Sobel Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(laplacian_edges, cmap='gray')\n",
    "plt.title('LoG Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(canny_edges, cmap='gray')\n",
    "plt.title('Canny Edge Detection')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "## Exercise 17.5: 性能比較と評価"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# 性能比較\n",
    "import time\n",
    "\n",
    "# 各手法の実行時間を計測\n",
    "methods = {\n",
    "    'Sobel': sobel_edge_detection,\n",
    "    'Laplacian': lambda img: laplacian_edge_detection(img, use_log=True),\n",
    "    'Canny': lambda img: canny_edge_detection(img, low_threshold=0.1, high_threshold=0.2)\n",
    "}\n",
    "\n",
    "# 結果の格納\n",
    "results = {}\n",
    "for name, method in methods.items():\n",
    "    start_time = time.time()\n",
    "    if name == 'Canny':\n",
    "        result = method(image)\n",
    "    else:\n",
    "        result = method(image)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    results[name] = {\n",
    "        'time': end_time - start_time,\n",
    "        'edges': result\n",
    "    }\n",
    "    print(f\"{name}: {end_time - start_time:.4f}秒\")\n",
    "\n",
    "# エッジ密度の比較\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(methods))\n",
    "\n",
    "# 実行時間\n",
    "times = [results[name]['time'] for name in methods.keys()]\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.bar(index, times, bar_width, color='blue', alpha=0.7)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Execution Time (s)')\n",
    "plt.title('Performance Comparison')\n",
    "plt.xticks(index, methods.keys())\n",
    "\n",
    "# エッジピクセル数\n",
    "edge_counts = []\n",
    "for name in methods.keys():\n",
    "    edges = results[name]['edges']\n",
    "    count = np.sum(edges > 0)\n",
    "    edge_counts.append(count)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.bar(index, edge_counts, bar_width, color='green', alpha=0.7)\n",
    "plt.xlabel('Method')\n",
    "plt.ylabel('Edge Pixels')\n",
    "plt.title('Edge Detection Results')\n",
    "plt.xticks(index, methods.keys())\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 結果の要約\n",
    "print(\"\\n=== 性能比較結果 ===\")\n",
    "for name in methods.keys():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  - 実行時間: {results[name]['time']:.4f}秒\")\n",
    "    print(f\"  - エッジピクセル数: {np.sum(results[name]['edges'] > 0)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "---\n",
    "\n",
    "# Self-Check (理解度確認)\n",
    "\n",
    "本日の学習内容を確認しましょう：\n",
    "\n",
    "## 基礎知識\n",
    "- [ ] Sobel演算子の原理とカーネルを理解した\n",
    "- [ ] Laplacianフィルタの特性とLoGの利点を理解した\n",
    "- [ ] Cannyアルゴリズムの6段階を理解した\n",
    "\n",
    "## 技術的知識\n",
    "- [ ] 勾配計算と非极大値抑制の概念を理解した\n",
    "- [ ] ヒステリシス閾値処理の利点を理解した\n",
    "- [ ] 各手法の特徴と適用場面を理解した\n",
    "\n",
    "## 実践力\n",
    "- [ ] Sobelエッジ検出を実装した\n",
    "- [ ] LaplacianとLoGの実装を比較した\n",
    "- [ ] Cannyのパラメータ調整を行った\n",
    "- [ ] 実際の画像で各手法を比較した\n",
    "\n",
    "**お疲れ様でした！** Day 17はこれで終了です。\n",
    "\n",
    "次回（Day 18）は「画像の幾何学変換」を学びます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
