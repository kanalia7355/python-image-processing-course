{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 23: 分類器の実装\n",
    "\n",
    "## Learning Objectives\n",
    "- 最近傍法（Nearest Neighbor）の実装\n",
    "- k-近傍法（k-NN）の実装\n",
    "- 交差検証（Cross Validation）の実装\n",
    "- 画像認識のための分類器を構築する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory (2 hours)\n",
    "\n",
    "## 23.1 画像認識と分類問題\n",
    "\n",
    "### 画像認識の基本的な考え方\n",
    "\n",
    "画像認識は、画像から特徴を抽出し、その特徴に基づいて分類を行うタスクです。\n",
    "\n",
    "**基本的なフロー**:\n",
    "1. **前処理**: 画像を正規化、リサイズ\n",
    "2. **特徴抽出**: 画像から特徴ベクトルを生成\n",
    "3. **分類**: 特徴ベクトルに基づいてクラスを予測\n",
    "4. **評価**: 予測結果の精度を評価\n",
    "\n",
    "**特徴量の種類**:\n",
    "- ピクセル値そのもの\n",
    "- ヒストグラム統計量\n",
    "- エッジ情報\n",
    "- テクスチャ特徴\n",
    "- 形状特徴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.2 最近傍法（Nearest Neighbor, NN）\n",
    "\n",
    "最近傍法は最もシンプルな分類アルゴリズムです。\n",
    "\n",
    "**基本的なアイデア**:\n",
    "- 予測対象のデータに最も近い学習データのクラスを予測値とする\n",
    "- 距離が最も近い1つのデータのみを使用する\n",
    "\n",
    "**距離の測り方**:\n",
    "\n",
    "1. **ユークリッド距離（L2ノルム）**:\n",
    "   $$d(x, y) = \\sqrt{\\sum_{i=1}^{n}(x_i - y_i)^2}$$\n",
    "\n",
    "2. **マンハッタン距離（L1ノルム）**:\n",
    "   $$d(x, y) = \\sum_{i=1}^{n}|x_i - y_i|$$\n",
    "\n",
    "3. **最大距離（L∞ノルム）**:\n",
    "   $$d(x, y) = \\max_{i}|x_i - y_i|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23.2.1 最近傍法の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\"ユークリッド距離の計算\"\"\"\n",
    "    return np.sqrt(sum((a - b) ** 2 for a, b in zip(x1, x2)))\n",
    "\n",
    "def manhattan_distance(x1, x2):\n",
    "    \"\"\"マンハッタン距離の計算\"\"\"\n",
    "    return sum(abs(a - b) for a, b in zip(x1, x2))\n",
    "\n",
    "class NearestNeighbor:\n",
    "    \"\"\"最近傍法分類器\"\"\"\n",
    "    \n",
    "    def __init__(self, distance_metric='euclidean'):\n",
    "        \"\"\"初期化\n",
    "        \n",
    "        Args:\n",
    "            distance_metric: 距離測定方法 ('euclidean' or 'manhattan')\n",
    "        \"\"\"\n",
    "        self.distance_metric = distance_metric\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"学習データを保存\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測を実行\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for x in X:\n",
    "            # 距離の計算\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            elif self.distance_metric == 'manhattan':\n",
    "                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported distance metric\")\n",
    "            \n",
    "            # 最も近いデータのインデックスを取得\n",
    "            nearest_idx = np.argmin(distances)\n",
    "            nearest_label = self.y_train[nearest_idx]\n",
    "            \n",
    "            predictions.append(nearest_label)\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def predict_with_distance(self, X):\n",
    "        \"\"\"予測結果と距離を返す（デバッグ用）\"\"\"\n",
    "        predictions = []\n",
    "        distances_list = []\n",
    "        \n",
    "        for x in X:\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            else:\n",
    "                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "            \n",
    "            nearest_idx = np.argmin(distances)\n",
    "            nearest_label = self.y_train[nearest_idx]\n",
    "            min_distance = distances[nearest_idx]\n",
    "            \n",
    "            predictions.append(nearest_label)\n",
    "            distances_list.append(min_distance)\n",
    "            \n",
    "        return predictions, distances_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.3 k-近傍法（k-Nearest Neighbors, k-NN）\n",
    "\n",
    "k-NNは最近傍法の拡張版です。\n",
    "\n",
    "**改良点**:\n",
    "- 予測対象のデータからk個の最近傍を考慮\n",
    "- 多数決によりクラスを決定\n",
    "- 以下の点で最近傍法より頑健\n",
    "  - ノイズに強い\n",
    "  - 複数の近傍から情報を得られる\n",
    "\n",
    "**多数決の方法**:\n",
    "1. **単純多数決**: 最も多いクラスを選択\n",
    "2. **重み付き多数決**: 距離に反比例した重み付け\n",
    "\n",
    "**kの選択**:\n",
    "- kが小さい: バリアンスが大きくなりやすい（過学習）\n",
    "- kが大きい: バイアスが大きくなりやすい（アンダーフィット）\n",
    "- 一般的にk=3, 5, 7などの奇数を選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    \"\"\"k-近傍法分類器\"\"\"\n",
    "    \n",
    "    def __init__(self, k=5, distance_metric='euclidean', weighted=False):\n",
    "        \"\"\"初期化\n",
    "        \n",
    "        Args:\n",
    "            k: 近傍の数\n",
    "            distance_metric: 距離測定方法\n",
    "            weighted: 重み付き多数決を使用するか\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weighted = weighted\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"学習データを保存\"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"予測を実行\"\"\"\n",
    "        predictions = []\n",
    "        \n",
    "        for x in X:\n",
    "            # 距離の計算\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            elif self.distance_metric == 'manhattan':\n",
    "                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported distance metric\")\n",
    "            \n",
    "            # 距離に基づいてインデックスをソート\n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = [self.y_train[i] for i in nearest_indices]\n",
    "            nearest_distances = [distances[i] for i in nearest_indices]\n",
    "            \n",
    "            # 多数決で予測\n",
    "            if self.weighted:\n",
    "                # 重み付き多数決（重み = 1/距離）\n",
    "                weights = [1.0 / (d + 1e-10) for d in nearest_distances]\n",
    "                weighted_votes = {}\n",
    "                for label, weight in zip(nearest_labels, weights):\n",
    "                    weighted_votes[label] = weighted_votes.get(label, 0) + weight\n",
    "                prediction = max(weighted_votes, key=weighted_votes.get)\n",
    "            else:\n",
    "                # 単純多数決\n",
    "                prediction = Counter(nearest_labels).most_common(1)[0][0]\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def predict_with_neighbors(self, X):\n",
    "        \"\"\"予測結果と近傍情報を返す（デバッグ用）\"\"\"\n",
    "        predictions = []\n",
    "        neighbors_info = []\n",
    "        \n",
    "        for x in X:\n",
    "            if self.distance_metric == 'euclidean':\n",
    "                distances = [euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            else:\n",
    "                distances = [manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "            \n",
    "            nearest_indices = np.argsort(distances)[:self.k]\n",
    "            nearest_labels = [self.y_train[i] for i in nearest_indices]\n",
    "            nearest_distances = [distances[i] for i in nearest_indices]\n",
    "            \n",
    "            if self.weighted:\n",
    "                weights = [1.0 / (d + 1e-10) for d in nearest_distances]\n",
    "                weighted_votes = {}\n",
    "                for label, weight in zip(nearest_labels, weights):\n",
    "                    weighted_votes[label] = weighted_votes.get(label, 0) + weight\n",
    "                prediction = max(weighted_votes, key=weighted_votes.get)\n",
    "                votes = weighted_votes\n",
    "            else:\n",
    "                prediction = Counter(nearest_labels).most_common(1)[0][0]\n",
    "                votes = Counter(nearest_labels)\n",
    "            \n",
    "            predictions.append(prediction)\n",
    "            neighbors_info.append({\n",
    "                'indices': nearest_indices,\n",
    "                'labels': nearest_labels,\n",
    "                'distances': nearest_distances,\n",
    "                'votes': votes\n",
    "            })\n",
    "            \n",
    "        return predictions, neighbors_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.4 交差検証（Cross Validation）\n",
    "\n",
    "交差検証は、モデルの評価方法の一つです。\n",
    "\n",
    "**目的**:\n",
    "- モデルの汎化性能を正確に評価\n",
    "- データ分割の影響を減らす\n",
    "- ハイパーパラメータチューニング\n",
    "\n",
    "**k-fold交差検証の流れ**:\n",
    "1. データをk個のグループ（fold）に分割\n",
    "2. k-1グループを学習データ、1グループを検証データとする\n",
    "3. すべての組み合わせでk回評価\n",
    "4. 精度の平均値を最終評価値とする\n",
    "\n",
    "**kの選択**:\n",
    "- k=10: 最も一般的\n",
    "- LOOCV（Leave-One-Out-CV, k=n）: 厳密だば計算量大\n",
    "- k=5: 計算量と精度のバランス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, classifier, k_folds=5, **kwargs):\n",
    "    \"\"\"k-fold交差検証を実行\n",
    "    \n",
    "    Args:\n",
    "        X: 特徴ベクトル\n",
    "        y: ラベル\n",
    "        classifier: 分類器クラス\n",
    "        k_folds: foldの数\n",
    "        **kwargs: 分類器のパラメータ\n",
    "        \n",
    "    Returns:\n",
    "        平均精度と各foldの精度リスト\n",
    "    \"\"\"\n",
    "    # データをシャッフル\n",
    "    indices = list(range(len(X)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # k-fold分割\n",
    "    fold_size = len(X) // k_folds\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k_folds):\n",
    "        # テストデータのインデックス\n",
    "        test_start = i * fold_size\n",
    "        test_end = (i + 1) * fold_size if i < k_folds - 1 else len(X)\n",
    "        test_indices = indices[test_start:test_end]\n",
    "        \n",
    "        # 学習データのインデックス\n",
    "        train_indices = [idx for idx in indices if idx not in test_indices]\n",
    "        \n",
    "        # データ分割\n",
    "        X_train = [X[idx] for idx in train_indices]\n",
    "        y_train = [y[idx] for idx in train_indices]\n",
    "        X_test = [X[idx] for idx in test_indices]\n",
    "        y_test = [y[idx] for idx in test_indices]\n",
    "        \n",
    "        # モデルの学習と評価\n",
    "        model = classifier(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # 精度計算\n",
    "        accuracy = sum(1 for pred, true in zip(predictions, y_test) if pred == true) / len(y_test)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Fold {i+1}/{k_folds}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # 平均精度\n",
    "    mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"\\n平均精度: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    return mean_accuracy, std_accuracy, accuracies\n",
    "\n",
    "def cross_validate_stratified(X, y, classifier, k_folds=5, **kwargs):\n",
    "    \"\"\"層化k-fold交差検証（各foldにクラスの分布を保持）\"\"\"\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "    # StratifiedKFoldを使用\n",
    "    skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        # データ分割\n",
    "        X_train = [X[i] for i in train_idx]\n",
    "        y_train = [y[i] for i in train_idx]\n",
    "        X_test = [X[i] for i in test_idx]\n",
    "        y_test = [y[i] for i in test_idx]\n",
    "        \n",
    "        # モデルの学習と評価\n",
    "        model = classifier(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # 精度計算\n",
    "        accuracy = sum(1 for pred, true in zip(predictions, y_test) if pred == true) / len(y_test)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        print(f\"Fold {fold+1}/{k_folds}: Accuracy = {accuracy:.4f}\")\n",
    "    \n",
    "    # 平均精度\n",
    "    mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    \n",
    "    print(f\"\\n平均精度: {mean_accuracy:.4f} ± {std_accuracy:.4f}\")\n",
    "    \n",
    "    return mean_accuracy, std_accuracy, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23.5 特徴量の正規化\n",
    "\n",
    "k-NNでは、特徴量のスケールが大きく影響します。\n",
    "\n",
    "**問題点**:\n",
    "- 距離計算時にスケールの大きい特徴量が支配的になる\n",
    "- 例: 画素値(0-255) vs エッジ強度(0-1)\n",
    "\n",
    "**解決策**:\n",
    "1. **Min-Max正規化**:\n",
    "   $$x_{\\text{norm}} = \\frac{x - \\min}{\\max - \\min}$$\n",
    "\n",
    "2. **Z正規化（標準化）**:\n",
    "   $$x_{\\text{std}} = \\frac{x - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X, method='min_max'):\n",
    "    \"\"\"特徴量の正規化\n",
    "    \n",
    "    Args:\n",
    "        X: 特徴ベクトルリスト\n",
    "        method: 'min_max' または 'z_score'\n",
    "        \n",
    "    Returns:\n",
    "        正規化された特徴量リスト\n",
    "    \"\"\"\n",
    "    if method == 'min_max':\n",
    "        # Min-Max正規化\n",
    "        min_vals = min(min(sample) for sample in X)\n",
    "        max_vals = max(max(sample) for sample in X)\n",
    "        \n",
    "        if max_vals == min_vals:\n",
    "            return [[0.5 for _ in sample] for sample in X]\n",
    "        \n",
    "        range_val = max_vals - min_vals\n",
    "        return [[(x - min_vals) / range_val for x in sample] for sample in X]\n",
    "    \n",
    "    elif method == 'z_score':\n",
    "        # Z正規化（特徴量ごとに）\n",
    "        X_array = np.array(X)\n",
    "        means = X_array.mean(axis=0)\n",
    "        stds = X_array.std(axis=0)\n",
    "        \n",
    "        # 標準偏差が0の場合を処理\n",
    "        stds[stds == 0] = 1.0\n",
    "        \n",
    "        X_normalized = (X_array - means) / stds\n",
    "        return X_normalized.tolist()\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unsupported normalization method\")\n",
    "\n",
    "def normalize_features_per_feature(X, method='min_max'):\n",
    "    \"\"\"各特徴量（次元）ごとに正規化\"\"\"\n",
    "    X_array = np.array(X)\n",
    "    normalized = []\n",
    "    \n",
    "    for dim in range(X_array.shape[1]):\n",
    "        feature = X_array[:, dim]\n",
    "        \n",
    "        if method == 'min_max':\n",
    "            min_val = feature.min()\n",
    "            max_val = feature.max()\n",
    "            if max_val == min_val:\n",
    "                normalized_feature = np.zeros_like(feature)\n",
    "            else:\n",
    "                normalized_feature = (feature - min_val) / (max_val - min_val)\n",
    "        \n",
    "        elif method == 'z_score':\n",
    "            mean_val = feature.mean()\n",
    "            std_val = feature.std()\n",
    "            if std_val == 0:\n",
    "                normalized_feature = np.zeros_like(feature)\n",
    "            else:\n",
    "                normalized_feature = (feature - mean_val) / std_val\n",
    "        \n",
    "        normalized.append(normalized_feature)\n",
    "    \n",
    "    # 次元ごとの正規化を結合\n",
    "    X_normalized = np.column_stack(normalized)\n",
    "    return X_normalized.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Practice (2 hours)\n",
    "\n",
    "それでは、学んだ知識を使って手書き数字認識を実装してみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.1: 手書き数字データの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_digit_images(num_samples=100, image_size=8):\n",
    "    \"\"\"手書き数字（0-9）のサンプル画像を生成\n",
    "    \n",
    "    Returns:\n",
    "        images: 画像データ（2次元リスト）のリスト\n",
    "        labels: 数字ラベル（0-9）\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for digit in range(10):\n",
    "        digit_samples = num_samples // 10\n",
    "        \n",
    "        for _ in range(digit_samples):\n",
    "            # 数字の画像を生成\n",
    "            image = [[0 for _ in range(image_size)] for _ in range(image_size)]\n",
    "            \n",
    "            # 簡単な数字のパターン\n",
    "            if digit == 0:  # 0\n",
    "                for i in range(1, image_size-1):\n",
    "                    for j in range(1, image_size-1):\n",
    "                        if (i in [1, image_size-2] or j in [1, image_size-2]):\n",
    "                            image[i][j] = random.randint(150, 255)\n",
    "            elif digit == 1:  # 1\n",
    "                for i in range(image_size):\n",
    "                    if i != 0 and i != image_size-1:\n",
    "                        image[i][image_size//2] = random.randint(150, 255)\n",
    "                    if image_size//2 != 0 and image_size//2 != image_size-1:\n",
    "                        image[image_size//2][i] = random.randint(150, 255)\n",
    "            elif digit == 2:  # 2\n",
    "                # 上半分\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                    if j < image_size-2:\n",
    "                        image[2][j] = random.randint(150, 255)\n",
    "                # 中間\n",
    "                for i in range(1, image_size-1):\n",
    "                    if i != image_size//2:\n",
    "                        image[i][image_size-3] = random.randint(150, 255)\n",
    "                # 下半分\n",
    "                for j in range(image_size-1, -1, -1):\n",
    "                    image[image_size-2][j] = random.randint(150, 255)\n",
    "                    if j > 1:\n",
    "                        image[image_size-3][j] = random.randint(150, 255)\n",
    "            elif digit == 3:  # 3\n",
    "                # 上半分\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                # 右側\n",
    "                for i in range(1, image_size-1):\n",
    "                    image[i][image_size-2] = random.randint(150, 255)\n",
    "                # 下半分\n",
    "                for j in range(image_size):\n",
    "                    image[image_size-2][j] = random.randint(150, 255)\n",
    "                # 中の横棒\n",
    "                for j in range(2, image_size-2):\n",
    "                    image[image_size//2][j] = random.randint(150, 255)\n",
    "            elif digit == 4:  # 4\n",
    "                # 左側\n",
    "                for i in range(1, image_size-1):\n",
    "                    image[i][1] = random.randint(150, 255)\n",
    "                # 中央縦棒\n",
    "                for i in range(1, image_size-1):\n",
    "                    image[i][image_size//2] = random.randint(150, 255)\n",
    "                # 上横棒\n",
    "                for j in range(1, image_size//2+1):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                # 下横棒\n",
    "                for j in range(image_size//2, image_size-1):\n",
    "                    image[image_size//2][j] = random.randint(150, 255)\n",
    "            elif digit == 5:  # 5\n",
    "                # 上半分\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                    if j > 1:\n",
    "                        image[2][j] = random.randint(150, 255)\n",
    "                # 左側\n",
    "                for i in range(1, image_size-1):\n",
    "                    if i != image_size//2:\n",
    "                        image[i][1] = random.randint(150, 255)\n",
    "                # 下半分\n",
    "                for j in range(image_size-1, -1, -1):\n",
    "                    image[image_size-2][j] = random.randint(150, 255)\n",
    "                    if j < image_size-2:\n",
    "                        image[image_size-3][j] = random.randint(150, 255)\n",
    "            elif digit == 6:  # 6\n",
    "                # 外枠\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = image[image_size-2][j] = random.randint(150, 255)\n",
    "                for i in range(2, image_size-2):\n",
    "                    image[i][1] = image[i][image_size-2] = random.randint(150, 255)\n",
    "                # 内部横棒\n",
    "                for j in range(3, image_size-2):\n",
    "                    image[image_size//2][j] = random.randint(150, 255)\n",
    "            elif digit == 7:  # 7\n",
    "                # 上横棒\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                # 斜め\n",
    "                for i in range(2, image_size-1):\n",
    "                    j = image_size - 2 - (i - 2)\n",
    "                    if j >= 1:\n",
    "                        image[i][j] = random.randint(150, 255)\n",
    "                # 下部分\n",
    "                image[image_size-1][1] = random.randint(150, 255)\n",
    "            elif digit == 8:  # 8\n",
    "                # 上下円\n",
    "                for i in [1, image_size-2]:\n",
    "                    for j in range(1, image_size-1):\n",
    "                        if i == 1 or i == image_size-2:\n",
    "                            image[i][j] = random.randint(150, 255)\n",
    "                # 左右円\n",
    "                for i in range(2, image_size-2):\n",
    "                    for j in [1, image_size-2]:\n",
    "                        image[i][j] = random.randint(150, 255)\n",
    "                # 中の横棒\n",
    "                for j in range(2, image_size-2):\n",
    "                    image[image_size//2][j] = random.randint(150, 255)\n",
    "            elif digit == 9:  # 9\n",
    "                # 上半分\n",
    "                for j in range(image_size):\n",
    "                    image[1][j] = random.randint(150, 255)\n",
    "                # 右側\n",
    "                for i in range(1, image_size-1):\n",
    "                    if i != image_size//2:\n",
    "                        image[i][image_size-2] = random.randint(150, 255)\n",
    "                # 下半分\n",
    "                for j in range(image_size):\n",
    "                    image[image_size-2][j] = random.randint(150, 255)\n",
    "                # 中の横棒\n",
    "                for j in range(2, image_size-2):\n",
    "                    image[image_size//2][j] = random.randint(150, 255)\n",
    "            \n",
    "            # ノイズを追加\n",
    "            for i in range(image_size):\n",
    "                for j in range(image_size):\n",
    "                    if image[i][j] == 0 and random.random() < 0.05:\n",
    "                        image[i][j] = random.randint(50, 100)\n",
    "                    elif image[i][j] > 0 and random.random() < 0.1:\n",
    "                        image[i][j] = random.randint(0, 50)\n",
    "            \n",
    "            images.append(image)\n",
    "            labels.append(digit)\n",
    "    \n",
    "    return images, labels\n",
    "\n",
    "# データの生成と可視化\n",
    "images, labels = generate_digit_images(num_samples=500, image_size=8)\n",
    "print(f\"生成データ: {len(images)}枚\")\n",
    "print(f\"ラベル分布: {Counter(labels)}\")\n",
    "\n",
    "# サンプル画像の表示\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(f\"Digit: {labels[i]}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.2: 画像から特徴量を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_simple_features(image):\n",
    "    \"\"\"画像から簡単な特徴量を抽出\n",
    "    \n",
    "    Args:\n",
    "        image: 2D画像データ（H×W）\n",
    "        \n",
    "    Returns:\n",
    "        特徴量ベクトル\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    # 1. 平均輝度\n",
    "    features.append(sum(sum(row) for row in image) / (len(image) * len(image[0])))\n",
    "    \n",
    "    # 2. 輝度の分散\n",
    "    mean_brightness = features[0]\n",
    "    variance = sum(sum((pixel - mean_brightness) ** 2 for pixel in row) for row in image) / (len(image) * len(image[0]))\n",
    "    features.append(variance)\n",
    "    \n",
    "    # 3. 非ゼロピクセルの割合\n",
    "    non_zero_pixels = sum(1 for row in image for pixel in row if pixel > 0)\n",
    "    features.append(non_zero_pixels / (len(image) * len(image[0])))\n",
    "    \n",
    "    # 4. 各象限の平均輝度\n",
    "    height, width = len(image), len(image[0])\n",
    "    mid_h, mid_w = height // 2, width // 2\n",
    "    \n",
    "    # 左上象限\n",
    "    q1 = sum(sum(image[i][j] for j in range(mid_w)) for i in range(mid_h)) / (mid_h * mid_w)\n",
    "    features.append(q1)\n",
    "    \n",
    "    # 右上象限\n",
    "    q2 = sum(sum(image[i][j] for j in range(mid_w, width)) for i in range(mid_h)) / (mid_h * (width - mid_w))\n",
    "    features.append(q2)\n",
    "    \n",
    "    # 左下象限\n",
    "    q3 = sum(sum(image[i][j] for j in range(mid_w)) for i in range(mid_h, height)) / ((height - mid_h) * mid_w)\n",
    "    features.append(q3)\n",
    "    \n",
    "    # 右下象限\n",
    "    q4 = sum(sum(image[i][j] for j in range(mid_w, width)) for i in range(mid_h, height)) / ((height - mid_h) * (width - mid_w))\n",
    "    features.append(q4)\n",
    "    \n",
    "    # 5. 水平方向のヒストグラム（3バケット）\n",
    "    hist_h = [0, 0, 0]\n",
    "    bucket_w = width // 3\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            bucket = j // bucket_w\n",
    "            hist_h[bucket] += image[i][j]\n",
    "    \n",
    "    # 平均化\n",
    "    for i in range(3):\n",
    "        hist_h[i] /= (height * (bucket_w if i < 2 else width - 2*bucket_w))\n",
    "        features.append(hist_h[i])\n",
    "    \n",
    "    # 6. 垂直方向のヒストグラム（3バケット）\n",
    "    hist_v = [0, 0, 0]\n",
    "    bucket_h = height // 3\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            bucket = i // bucket_h\n",
    "            hist_v[bucket] += image[i][j]\n",
    "    \n",
    "    # 平均化\n",
    "    for i in range(3):\n",
    "        hist_v[i] /= ((bucket_h if i < 2 else height - 2*bucket_h) * width)\n",
    "        features.append(hist_v[i])\n",
    "    \n",
    "    # 7. エッジ密度（簡易版）\n",
    "    edge_pixels = 0\n",
    "    for i in range(1, height-1):\n",
    "        for j in range(1, width-1):\n",
    "            # ラプラシアン演算子の簡易版\n",
    "            laplacian = (image[i-1][j] + image[i+1][j] + \n",
    "                        image[i][j-1] + image[i][j+1] - \n",
    "                        4 * image[i][j])\n",
    "            if abs(laplacian) > 50:\n",
    "                edge_pixels += 1\n",
    "    \n",
    "    features.append(edge_pixels / ((height-2) * (width-2)))\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 全画像から特徴量を抽出\n",
    "print(\"特徴量抽出中...\")\n",
    "X = [extract_simple_features(img) for img in images]\n",
    "y = labels\n",
    "print(f\"特徴量の次元: {len(X[0])}\")\n",
    "print(f\"特徴量サンプル: {X[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.3: 最近傍法の実装と評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データを学習用とテスト用に分割\n",
    "split_ratio = 0.8\n",
    "split_idx = int(len(X) * split_ratio)\n",
    "\n",
    "X_train = X[:split_idx]\n",
    "y_train = y[:split_idx]\n",
    "X_test = X[split_idx:]\n",
    "y_test = y[split_idx:]\n",
    "\n",
    "print(f\"学習データ: {len(X_train)}サンプル\")\n",
    "print(f\"テストデータ: {len(X_test)}サンプル\")\n",
    "\n",
    "# 最近傍法の学習と評価\n",
    "print(\"\\n=== 最近傍法（Euclidean距離） ===\")\n",
    "nn_model = NearestNeighbor(distance_metric='euclidean')\n",
    "nn_model.fit(X_train, y_train)\n",
    "\n",
    "# テストデータの予測\n",
    "y_pred = nn_model.predict(X_test)\n",
    "accuracy = sum(1 for pred, true in zip(y_pred, y_test) if pred == true) / len(y_test)\n",
    "\n",
    "print(f\"テスト精度: {accuracy:.4f}\")\n",
    "\n",
    "# マンハッタン距離での評価\n",
    "print(\"\\n=== 最近傍法（Manhattan距離） ===\")\n",
    "nn_model_manhattan = NearestNeighbor(distance_metric='manhattan')\n",
    "nn_model_manhattan.fit(X_train, y_train)\n",
    "\n",
    "y_pred_manhattan = nn_model_manhattan.predict(X_test)\n",
    "accuracy_manhattan = sum(1 for pred, true in zip(y_pred_manhattan, y_test) if pred == true) / len(y_test)\n",
    "\n",
    "print(f\"テスト精度: {accuracy_manhattan:.4f}\")\n",
    "\n",
    "# 予測結果の可視化\n",
    "def plot_predictions(X_test, y_test, y_pred, title=\"\"):\n",
    "    \"\"\"予測結果を表示\"\"\"\n",
    "    correct = 0\n",
    "    \n",
    "    # 予測結果のサンプルを表示\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(min(12, len(X_test))):\n",
    "        # 元の画像を再構築（元のimagesから取得）\n",
    "        original_index = split_idx + i\n",
    "        if original_index < len(images):\n",
    "            axes[i].imshow(images[original_index], cmap='gray')\n",
    "        \n",
    "        # 真のラベルと予測ラベル\n",
    "        true_label = y_test[i]\n",
    "        pred_label = y_pred[i]\n",
    "        \n",
    "        # 色で正誤を表示\n",
    "        if true_label == pred_label:\n",
    "            color = 'green'\n",
    "            correct += 1\n",
    "        else:\n",
    "            color = 'red'\n",
    "        \n",
    "        axes[i].set_title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"{title} (Accuracy: {correct/len(y_test):.2%})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 結果の表示\n",
    "plot_predictions(X_test, y_test, y_pred, \"最近傍法（Euclidean距離）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.4: k-NNの実装とkの最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NNのk値を変えて評価\n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "k_accuracies = []\n",
    "\n",
    "print(\"=== k-NNのk値による精度比較 ===\")\n",
    "for k in k_values:\n",
    "    model = KNearestNeighbors(k=k, distance_metric='euclidean', weighted=False)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = sum(1 for pred, true in zip(y_pred, y_test) if pred == true) / len(y_test)\n",
    "    k_accuracies.append(accuracy)\n",
    "    print(f\"k={k}: {accuracy:.4f}\")\n",
    "\n",
    "# k値と精度の関係を可視化\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, k_accuracies, 'bo-')\n",
    "plt.xlabel('k (Number of Neighbors)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('k-NN: Effect of k on Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 最適なkで予測\n",
    "best_k = k_values[np.argmax(k_accuracies)]\n",
    "print(f\"\\n最適なk値: {best_k}\")\n",
    "print(f\"最高精度: {max(k_accuracies):.4f}\")\n",
    "\n",
    "# 重み付きk-NNの評価\n",
    "print(\"\\n=== 重み付きk-NN（Euclidean距離） ===\")\n",
    "knn_weighted = KNearestNeighbors(k=best_k, distance_metric='euclidean', weighted=True)\n",
    "knn_weighted.fit(X_train, y_train)\n",
    "y_pred_weighted = knn_weighted.predict(X_test)\n",
    "accuracy_weighted = sum(1 for pred, true in zip(y_pred_weighted, y_test) if pred == true) / len(y_test)\n",
    "\n",
    "print(f\"テスト精度: {accuracy_weighted:.4f}\")\n",
    "\n",
    "# 重み付きと非重み付きの比較\n",
    "plot_predictions(X_test, y_test, y_pred_weighted, f\"重み付きk-NN (k={best_k})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.5: 特徴量正規化の影響"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正規化なしでの精度\n",
    "print(\"=== 正規化なし ===\")\n",
    "nn_model = NearestNeighbor(distance_metric='euclidean')\n",
    "nn_model.fit(X_train, y_train)\n",
    "y_pred = nn_model.predict(X_test)\n",
    "accuracy_raw = sum(1 for pred, true in zip(y_pred, y_test) if pred == true) / len(y_test)\n",
    "print(f\"テスト精度: {accuracy_raw:.4f}\")\n",
    "\n",
    "# Min-Max正規化\n",
    "print(\"\\n=== Min-Max正規化 ===\")\n",
    "X_train_normalized = normalize_features(X_train, method='min_max')\n",
    "X_test_normalized = normalize_features(X_test, method='min_max')\n",
    "\n",
    "nn_model_norm = NearestNeighbor(distance_metric='euclidean')\n",
    "nn_model_norm.fit(X_train_normalized, y_train)\n",
    "y_pred_norm = nn_model_norm.predict(X_test_normalized)\n",
    "accuracy_norm = sum(1 for pred, true in zip(y_pred_norm, y_test) if pred == true) / len(y_test)\n",
    "print(f\"テスト精度: {accuracy_norm:.4f}\")\n",
    "\n",
    "# Z正規化\n",
    "print(\"\\n=== Z正規化 ===\")\n",
    "X_train_znorm = normalize_features(X_train, method='z_score')\n",
    "X_test_znorm = normalize_features(X_test, method='z_score')\n",
    "\n",
    "nn_model_znorm = NearestNeighbor(distance_metric='euclidean')\n",
    "nn_model_znorm.fit(X_train_znorm, y_train)\n",
    "y_pred_znorm = nn_model_znorm.predict(X_test_znorm)\n",
    "accuracy_znorm = sum(1 for pred, true in zip(y_pred_znorm, y_test) if pred == true) / len(y_test)\n",
    "print(f\"テスト精度: {accuracy_znorm:.4f}\")\n",
    "\n",
    "# 結果の比較\n",
    "plt.figure(figsize=(10, 6))\n",
    "methods = ['Raw', 'Min-Max', 'Z-Score']\n",
    "accuracies = [accuracy_raw, accuracy_norm, accuracy_znorm]\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "bars = plt.bar(methods, accuracies, color=colors)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Effect of Feature Normalization')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# バーに値を表示\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.6: 交差検証によるモデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交差検証の実行\n",
    "print(\"=== 5-fold交差検証 ===\")\n",
    "print(\"最近傍法（Euclidean距離）:\")\n",
    "nn_cv_mean, nn_cv_std, nn_cv_accs = cross_validate(\n",
    "    X, y, NearestNeighbor, k_folds=5, distance_metric='euclidean'\n",
    ")\n",
    "\n",
    "print(\"\\nk-NN（k=5, Euclidean）:\")\n",
    "knn_cv_mean, knn_cv_std, knn_cv_accs = cross_validate(\n",
    "    X, y, KNearestNeighbors, k_folds=5, k=5, distance_metric='euclidean'\n",
    ")\n",
    "\n",
    "print(\"\\n層化交差検証（sklearn使用）:\")\n",
    "knn_strat_mean, knn_strat_std, knn_strat_accs = cross_validate_stratified(\n",
    "    X, y, KNearestNeighbors, k_folds=5, k=5, distance_metric='euclidean'\n",
    ")\n",
    "\n",
    "# 交差検証結果の可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([nn_cv_accs, knn_cv_accs, knn_strat_accs], \n",
    "            labels=['NN (Euclidean)', 'k-NN (k=5)', 'k-NN (Stratified)'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Results Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 各モデルの性能比較\n",
    "models = ['NN (Raw)', 'NN (Min-Max)', 'NN (Z-Score)', \n",
    "         'k-NN (k=3)', 'k-NN (k=5)', 'k-NN (Weighted)',\n",
    "         '5-fold CV (NN)', '5-fold CV (k-NN)']\n",
    "all_accuracies = [\n",
    "    accuracy_raw,\n",
    "    accuracy_norm,\n",
    "    accuracy_znorm,\n",
    "    max([k_accuracies[i] for i, k in enumerate(k_values) if k == 3]),  # k=3の精度\n",
    "    max(k_accuracies),  # k=5の精度\n",
    "    accuracy_weighted,\n",
    "    nn_cv_mean,\n",
    "    knn_cv_mean\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "bars = plt.bar(range(len(models)), all_accuracies, color='skyblue')\n",
    "plt.xticks(range(len(models)), models, rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# バーに値を表示\n",
    "for bar, acc in zip(bars, all_accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 23.7: 混同行列の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, title=\"\"):\n",
    "    \"\"\"混同行列を表示\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # 混同行列の計算\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ヒートマップで表示\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix\\n{title}')\n",
    "    plt.show()\n",
    "    \n",
    "    # 各クラスの精度を計算\n",
    "    class_accuracies = []\n",
    "    for i in range(10):\n",
    "        if cm[i, :].sum() > 0:\n",
    "            class_acc = cm[i, i] / cm[i, :].sum()\n",
    "        else:\n",
    "            class_acc = 0\n",
    "        class_accuracies.append(class_acc)\n",
    "    \n",
    "    print(f\"\\n各クラスの精度:\")\n",
    "    for digit, acc in enumerate(class_accuracies):\n",
    "        print(f\"Digit {digit}: {acc:.3f}\")\n",
    "    \n",
    "    # 最も間違いやすいペアを特定\n",
    "    errors = []\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            if i != j and cm[i, j] > 0:\n",
    "                errors.append((i, j, cm[i, j]))\n",
    "    \n",
    "    errors.sort(key=lambda x: x[2], reverse=True)\n",
    "    print(\"\\n最も多い間違い:\")\n",
    "    for true_pred, pred, count in errors[:5]:\n",
    "        print(f\"Digit {true_pred} → {pred}: {count}回\")\n",
    "\n",
    "# 最も良いモデルの混同行列を表示\n",
    "print(\"\\n=== 最も性能の良いモデルの混同行列 ===\")\n",
    "if nn_cv_mean > knn_cv_mean:\n",
    "    # 最近傍法が良い場合\n",
    "    best_model = NearestNeighbor(distance_metric='euclidean')\n",
    "    model_name = \"Nearest Neighbor (Euclidean)\"\n",
    "else:\n",
    "    # k-NNが良い場合\n",
    "    best_model = KNearestNeighbors(k=best_k, distance_metric='euclidean')\n",
    "    model_name = f\"k-NN (k={best_k})\"\n",
    "\n",
    "best_model.fit(X_train, y_train)\n",
    "best_predictions = best_model.predict(X_test)\n",
    "\n",
    "plot_confusion_matrix(y_test, best_predictions, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追加課題：パフォーマンス分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測時間の計測\n",
    "import time\n",
    "\n",
    "def measure_prediction_time(model, X_test, num_trials=10):\n",
    "    \"\"\"予測にかかる時間を計測\"\"\"\n",
    "    times = []\n",
    "    for _ in range(num_trials):\n",
    "        start_time = time.time()\n",
    "        model.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    return np.mean(times), np.std(times)\n",
    "\n",
    "print(\"=== モデルのパフォーマンス分析 ===\")\n",
    "\n",
    "# 各モデルの予測時間\n",
    "models_to_test = [\n",
    "    (NearestNeighbor(distance_metric='euclidean'), \"NN (Euclidean)\"),\n",
    "    (NearestNeighbor(distance_metric='manhattan'), \"NN (Manhattan)\"),\n",
    "    (KNearestNeighbors(k=1), \"k-NN (k=1)\"),\n",
    "    (KNearestNeighbors(k=3), \"k-NN (k=3)\"),\n",
    "    (KNearestNeighbors(k=5), \"k-NN (k=5)\"),\n",
    "    (KNearestNeighbors(k=5, weighted=True), \"k-NN (Weighted)\")\n",
    "]\n",
    "\n",
    "model_names = []\n",
    "mean_times = []\n",
    "std_times = []\n",
    "accuracies = []\n",
    "\n",
    "for model, name in models_to_test:\n",
    "    # 学習\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 精度計算\n",
    "    pred = model.predict(X_test)\n",
    "    acc = sum(1 for p, t in zip(pred, y_test) if p == t) / len(y_test)\n",
    "    \n",
    "    # 時間計測\n",
    "    mean_time, std_time = measure_prediction_time(model, X_test)\n",
    "    \n",
    "    model_names.append(name)\n",
    "    accuracies.append(acc)\n",
    "    mean_times.append(mean_time)\n",
    "    std_times.append(std_time)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  精度: {acc:.4f}\")\n",
    "    print(f\"  予測時間: {mean_time*1000:.2f} ± {std_time*1000:.2f} ms\")\n",
    "    print()\n",
    "\n",
    "# パレートフロントの可視化（精度 vs 時間）\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(mean_times, accuracies, \n",
    "                     c=range(len(model_names)), cmap='viridis', s=100)\n",
    "\n",
    "for i, name in enumerate(model_names):\n",
    "    plt.annotate(name, (mean_times[i], accuracies[i]), \n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.xlabel('Prediction Time (seconds)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Prediction Time Trade-off')\n",
    "plt.colorbar(scatter, label='Model Index')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Self-Check (理解度確認)\n",
    "\n",
    "本日の学習内容を確認しましょう：\n",
    "\n",
    "## 基礎知識\n",
    "- [ ] 最近傍法（NN）の概念と実装方法を理解した\n",
    "- [ ] k-NNの概念と多数決の仕組みを理解した\n",
    "- [ ] 距離測定方法（Euclidean, Manhattan）の違いを理解した\n",
    "- [ ] k値の選択がモデル性能に与える影響を理解した\n",
    "\n",
    "## 特徴量と前処理\n",
    "- [ ] 特徴量抽出の重要性を理解した\n",
    "- [ ] 正規化（Min-Max, Z-score）の目的と効果を理解した\n",
    "- [ ] なぜk-NNでは特徴量のスケールが重要なのか理解した\n",
    "\n",
    "## 評価方法\n",
    "- [ ] 交差検証の概念と目的を理解した\n",
    "- [ ] k-fold交差検証の実装方法を理解した\n",
    "- [ ] 混同行列の読み方を理解した\n",
    "- [ ] 各クラスの精度と全体精度の違いを理解した\n",
    "\n",
    "## 実践力\n",
    "- [ ] 手書き数字認識を実装した\n",
    "- [ ] 異なるパラメータでモデル性能を比較した\n",
    "- [ ] 正規化の影響を分析した\n",
    "- [ ] 混同行列を使って誤分類パターンを分析した\n",
    "- [ ] モデルのパフォーマンス（精度 vs 速度）を評価した\n",
    "\n",
    "---\n",
    "\n",
    "**お疲れ様でした！** Day 23はこれで終了です。\n",
    "\n",
    "次回（Day 24）は、モデルの評価結果に基づいて改善策を講じ、より高性能な分類器を構築します。\n",
    "\n",
    "復習課題：\n",
    "1. k-NNの計算量がO(n)であることを証明する（nは学習データ数）\n",
    "2. 近傍数kを最適化する方法を考えてみる\n",
    "3. どのような特徴量を追加すると精度が向上するか考えてみる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}