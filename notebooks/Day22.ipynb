{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 22: 画像認識プロジェクト - データセット準備と前処理\n",
    "\n",
    "## Learning Objectives\n",
    "- 手書き数字データを生成する\n",
    "- 画像前処理パイプラインを実装する\n",
    "- 特徴抽出技術を理解する\n",
    "- データ拡張の手法を学ぶ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory (2 hours)\n",
    "\n",
    "## 1.1 画像認識の概要\n",
    "\n",
    "画像認識（Image Recognition）とは、画像から特定の物体やパターンを識別する技術です。\n",
    "\n",
    "**手書き数字認識の意義**:\n",
    "- 最も基本的な画像認識タスク\n",
    "- 機械学習の分野における「Hello, World」\n",
    "- OCR（光学文字認識）の基礎\n",
    "- 他の複雑な認識タスクの土台"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNISTデータセット\n",
    "\n",
    "MNIST（Modified National Institute of Standards and Technology）は、機械学習で最も有名なデータセットの一つです。\n",
    "\n",
    "**特徴**:\n",
    "- 70,000枚の手書き数字画像（60,000枚学習用 + 10,000枚テスト用）\n",
    "- 各画像は28×28ピクセル（グレースケール）\n",
    "- ラベル：0-9の数字（教師あり学習）\n",
    "\n",
    "**画像構造**:\n",
    "画像サイズ: 28×28 = 784ピクセル\n",
    "画素値: 0(黒) - 255(白)\n",
    "チャンネル数: 1（グレースケール）\n",
    "    \n",
    "例: 数字 '5' の28×28ピクセル配列\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 データの生成と生成モデル\n",
    "\n",
    "### ランダムな手書き数字の生成\n",
    "\n",
    "実際のデータセットを使用せず、プログラムで手書き数字を生成する方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from sklearn.datasets import make_classification\n",
    "import random\n",
    "\n",
    "# matplotlibで日本語対応\n",
    "plt.rcParams['font.family'] = 'Meiryo'  # Windowsの場合\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 負号の表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 簡単な手書き数字の生成（バージョン1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_simple_digit(digit, size=28, width=20):\n",
    "    \"\"\"シンプルな数字を生成する関数\"\"\"\n",
    "    # 白い背景の画像を作成\n",
    "    img = np.ones((size, size), dtype=np.uint8) * 255\n",
    "    \n",
    "    # 中心位置\n",
    "    center = size // 2\n",
    "    \n",
    "    if digit == 0:  # 円\n",
    "        cv2.circle(img, (center, center), width//2, 0, thickness=3)\n",
    "    elif digit == 1:  # 縦棒\n",
    "        cv2.line(img, (center-2, center-width//2), (center-2, center+width//2), 0, 3)\n",
    "    elif digit == 2:  # 2\n",
    "        cv2.line(img, (center-width//2, center-width//2), (center+width//2, center-width//2), 0, 3)  # 上横\n",
    "        cv2.line(img, (center+width//2, center-width//2), (center+width//2, center), 0, 3)  # 右縦\n",
    "        cv2.line(img, (center+width//2, center), (center-width//2, center), 0, 3)  # 中横\n",
    "        cv2.line(img, (center-width//2, center), (center-width//2, center+width//2), 0, 3)  # 左縦\n",
    "        cv2.line(img, (center-width//2, center+width//2), (center+width//2, center+width//2), 0, 3)  # 下横\n",
    "    \n",
    "    return img\n",
    "\n",
    "# 0-9の数字を生成して表示\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    digit_img = create_simple_digit(i)\n",
    "    ax.imshow(digit_img, cmap='gray')\n",
    "    ax.set_title(f'Digit: {i}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### より自然な手書き数字の生成（バージョン2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_handwritten_digit(digit, size=28):\n",
    "    \"\"\"より自然な手書き数字を生成する関数\"\"\"\n",
    "    # 白い背景\n",
    "    img = Image.new('L', (size, size), 255)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # ランダムな傾きとノイズを追加\n",
    "    angle = random.randint(-10, 10)\n",
    "    offset_x = random.randint(-2, 2)\n",
    "    offset_y = random.randint(-2, 2)\n",
    "    \n",
    "    # パラメトリックな数式で数字を描画\n",
    "    center_x, center_y = size//2 + offset_x, size//2 + offset_y\n",
    "    \n",
    "    if digit == 0:  # 0 - 楕円形\n",
    "        # 外円\n",
    "        draw.ellipse([center_x-10, center_y-12, center_x+10, center_y+12], outline=0, width=3)\n",
    "    elif digit == 1:  # 1 - 斜めの直線\n",
    "        # 縦棒（少し右に傾く）\n",
    "        points = [(center_x-2, center_y-10), (center_x+1, center_y+10)]\n",
    "        draw.line(points, fill=0, width=3)\n",
    "        # 上横棒\n",
    "        points = [(center_x-2, center_y-10), (center_x+2, center_y-10)]\n",
    "        draw.line(points, fill=0, width=2)\n",
    "    elif digit == 2:  # 2\n",
    "        # 上弧\n",
    "        draw.arc([center_x-10, center_y-12, center_x+10, center_y-2], 0, 180, fill=0, width=3)\n",
    "        # 横棒\n",
    "        draw.line([center_x+10, center_y-2, center_x-10, center_y+2], fill=0, width=3)\n",
    "        # 下弧\n",
    "        draw.arc([center_x-10, center_y+2, center_x+10, center_y+12], 180, 360, fill=0, width=3)\n",
    "    \n",
    "    # ノイズを追加\n",
    "    for _ in range(20):\n",
    "        x = random.randint(2, size-3)\n",
    "        y = random.randint(2, size-3)\n",
    "        draw.point([(x, y)], fill=random.randint(0, 100))\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "# 時間がかかるので、5つの数字だけを生成\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    digit_img = create_handwritten_digit(i * 2)  # 0, 2, 4, 6, 8\n",
    "    ax.imshow(digit_img, cmap='gray')\n",
    "    ax.set_title(f'Digit: {i*2}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 画像前処理パイプライン\n",
    "\n",
    "画像認識の精度を向上させるため、画像に対して一連の前処理を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_image(image):\n",
    "    \"\"\"画像前処理パイプライン\n",
    "    \n",
    "    前処理ステップ:\n",
    "    1. グレースケール化（すでであれば不要）\n",
    "    2. サイズ統一（28×28）\n",
    "    3. 二値化（必要に応じて）\n",
    "    4. 正規化（0-1）\n",
    "    5. ゼロパディング（必要に応じて）\n",
    "    \"\"\"\n",
    "    # 2. サイズ統一\n",
    "    if image.shape != (28, 28):\n",
    "        image = cv2.resize(image, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # 3. 二値化（閾値処理）\n",
    "    _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # 4. 正規化（0-1）\n",
    "    normalized = binary / 255.0\n",
    "    \n",
    "    # 5. 中央値フィルタ（ノイズ除去）\n",
    "    denoised = cv2.medianBlur((normalized * 255).astype(np.uint8), 3)\n",
    "    denoised = denoised / 255.0\n",
    "    \n",
    "    return denoised\n",
    "\n",
    "# 前処理の実例\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 7))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 元の画像\n",
    "original = create_handwritten_digit(7)\n",
    "axes[0].imshow(original, cmap='gray')\n",
    "axes[0].set_title('Original (255)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 二値化\n",
    "_, binary = cv2.threshold(original, 127, 255, cv2.THRESH_BINARY)\n",
    "axes[1].imshow(binary, cmap='gray')\n",
    "axes[1].set_title('Binary')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 正規化\n",
    "normalized = binary / 255.0\n",
    "axes[2].imshow(normalized, cmap='gray')\n",
    "axes[2].set_title('Normalized (0-1)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# ノイズ除去\n",
    "denoised = cv2.medianBlur(binary, 3)\n",
    "axes[3].imshow(denoised, cmap='gray')\n",
    "axes[3].set_title('Denoised')\n",
    "axes[3].axis('off')\n",
    "\n",
    "# 閾値調整\n",
    "_, binary_thresh = cv2.threshold(original, 150, 255, cv2.THRESH_BINARY)\n",
    "axes[4].imshow(binary_thresh, cmap='gray')\n",
    "axes[4].set.title('Binary (thresh=150)')\n",
    "axes[4].axis('off')\n",
    "\n",
    "# 最終前処理\n",
    "final_processed = preprocess_image(original)\n",
    "axes[5].imshow(final_processed, cmap='gray')\n",
    "axes[5].set_title('Final Processed')\n",
    "axes[5].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 特徴抽出の基礎\n",
    "\n",
    "特徴抽出とは、画像から認識に有用な情報を抽出するプロセスです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特徴量の種類\n",
    "\n",
    "#### 1. ピクセルレベルの特徴\n",
    "- ピクセル値そのもの\n",
    "- ヒストグラム（明度分布）\n",
    "\n",
    "#### 2. 統計的特徴\n",
    "- 平均、分散、標準偏差\n",
    "- エントロピー（ランダムさ）\n",
    "\n",
    "#### 3. 形状的特徴\n",
    "- 重心\n",
    "- 横長・縦長の比率\n",
    "- モーメント（慣性モーメント）\n",
    "\n",
    "#### 4. エッジ特徴\n",
    "- エッジの数\n",
    "- エッジの方向分布\n",
    "\n",
    "#### 5. トポロジカル特徴\n",
    "- 穴の数\n",
    "- 結合成分の数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_features(image):\n",
    "    \"\"\"画像から特徴を抽出する関数\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 1. 基本的な統計量\n",
    "    features['mean'] = np.mean(image)\n",
    "    features['std'] = np.std(image)\n",
    "    features['min'] = np.min(image)\n",
    "    features['max'] = np.max(image)\n",
    "    \n",
    "    # 2. 画像のサイズ情報\n",
    "    features['height'] = image.shape[0]\n",
    "    features['width'] = image.shape[1]\n",
    "    features['aspect_ratio'] = features['width'] / features['height']\n",
    "    \n",
    "    # 3. ピクセル値のヒストグラム\n",
    "    hist, _ = np.histogram(image.flatten(), bins=10, range=(0, 1))\n",
    "    features['histogram'] = hist\n",
    "    features['histogram_peak'] = np.argmax(hist) / 10  # ピーク位置\n",
    "    \n",
    "    # 4. 重心（ピクセルの質量中心）\n",
    "    y, x = np.mgrid[0:image.shape[0], 0:image.shape[1]]\n",
    "    # 濃度が濃いほど重みが大きくなる\n",
    "    weighted_sum = np.sum(image)\n",
    "    if weighted_sum > 0:\n",
    "        features['centroid_x'] = np.sum(x * image) / weighted_sum\n",
    "        features['centroid_y'] = np.sum(y * image) / weighted_sum\n",
    "    else:\n",
    "        features['centroid_x'] = image.shape[1] / 2\n",
    "        features['centroid_y'] = image.shape[0] / 2\n",
    "    \n",
    "    # 5. 分散（画像の広がり）\n",
    "    if weighted_sum > 0:\n",
    "        features['variance_x'] = np.sum((x - features['centroid_x'])**2 * image) / weighted_sum\n",
    "        features['variance_y'] = np.sum((y - features['centroid_y'])**2 * image) / weighted_sum\n",
    "    else:\n",
    "        features['variance_x'] = 0\n",
    "        features['variance_y'] = 0\n",
    "    \n",
    "    # 6. エッジ検出\n",
    "    # Sobelフィルタ\n",
    "    sobel_x = cv2.Sobel(image.astype(np.float32), cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image.astype(np.float32), cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    features['edge_magnitude'] = np.sqrt(sobel_x**2 + sobel_y**2).mean()\n",
    "    features['edge_direction'] = np.arctan2(sobel_y.mean(), sobel_x.mean())\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 特徴抽出の実例\n",
    "sample_digit = create_handwritten_digit(4)\n",
    "processed_digit = preprocess_image(sample_digit)\n",
    "features = extract_features(processed_digit)\n",
    "\n",
    "print(\"抽出された特徴:\")\n",
    "for key, value in features.items():\n",
    "    if key != 'histogram':\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "# ヒストグラムの表示\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(processed_digit, cmap='gray')\n",
    "plt.title('Processed Digit')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(10), features['histogram'])\n",
    "plt.xlabel('Bin (0-1)')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Pixel Value Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 データ拡張（Data Augmentation）\n",
    "\n",
    "データ拡張は、既存のデータから新しいデータを作成してデータセットを増やす技術です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def augment_image(image, rotation_range=10, noise_level=0.1):\n",
    "    \"\"\"データ拡張関数\n",
    "    \n",
    "    Args:\n",
    "        image: 入力画像\n",
    "        rotation_range: 回転角度の範囲（度）\n",
    "        noise_level: ノイズの強さ（0-1）\n",
    "    \"\"\"\n",
    "    augmented = image.copy()\n",
    "    \n",
    "    # 1. 回転\n",
    "    angle = np.random.uniform(-rotation_range, rotation_range)\n",
    "    rows, cols = image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "    augmented = cv2.warpAffine(augmented, M, (cols, rows), flags=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # 2. ノイズ追加\n",
    "    noise = np.random.normal(0, noise_level, image.shape)\n",
    "    augmented = np.clip(augmented + noise, 0, 1)\n",
    "    \n",
    "    # 3. スケーリング（拡大縮小）\n",
    "    scale = np.random.uniform(0.9, 1.1)\n",
    "    scaled = cv2.resize(augmented, None, fx=scale, fy=scale, interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # トリミングして元のサイズに戻す\n",
    "    if scale > 1:\n",
    "        # 拡大の場合は中心をトリミング\n",
    "        h, w = scaled.shape\n",
    "        start_h = (h - rows) // 2\n",
    "        start_w = (w - cols) // 2\n",
    "        augmented = scaled[start_h:start_h+rows, start_w:start_w+cols]\n",
    "    elif scale < 1:\n",
    "        # 縮小の場合はパディング\n",
    "        h, w = scaled.shape\n",
    "        pad_h = (rows - h) // 2\n",
    "        pad_w = (cols - w) // 2\n",
    "        augmented = np.pad(scaled, ((pad_h, rows - h - pad_h), (pad_w, cols - w - pad_w)), 'constant')\n",
    "    \n",
    "    # 4. 明るさ調整\n",
    "    brightness_factor = np.random.uniform(0.8, 1.2)\n",
    "    augmented = np.clip(augmented * brightness_factor, 0, 1)\n",
    "    \n",
    "    return augmented\n",
    "\n",
    "# データ拡張の例\n",
    "base_digit = create_handwritten_digit(8)\n",
    "processed_base = preprocess_image(base_digit)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 元の画像\n",
    "axes[0].imshow(processed_base, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 拡張例\n",
    "for i in range(1, 8):\n",
    "    augmented = augment_image(processed_base)\n",
    "    axes[i].imshow(augmented, cmap='gray')\n",
    "    axes[i].set_title(f'Augmented {i}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### さまざまな拡張手法の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_augmented_samples(original, num_samples=16):\n",
    "    \"\"\"拡張サンプルを作成する\"\"\"\n",
    "    samples = []\n",
    "    \n",
    "    # 元の画像\n",
    "    samples.append(('Original', original))\n",
    "    \n",
    "    # 種々の拡張パターン\n",
    "    for i in range(num_samples - 1):\n",
    "        # 異なるパラメータで拡張\n",
    "        rotation = 15 if i < 5 else 0  # 最初の5つだけ回転\n",
    "        noise = 0.05 + (i % 3) * 0.05  # ノイズレベルを変化\n",
    "        \n",
    "        augmented = augment_image(original, rotation_range=rotation, noise_level=noise)\n",
    "        \n",
    "        # パターン名\n",
    "        if rotation > 0 and noise > 0.1:\n",
    "            name = f'Rot+Noise{i-4}'\n",
    "        elif rotation > 0:\n",
    "            name = f'Rot{i+1}'\n",
    "        else:\n",
    "            name = f'Noise{i-4}'\n",
    "            \n",
    "        samples.append((name, augmented))\n",
    "    \n",
    "    return samples\n",
    "\n",
    "# 拡張サンプルのグリッド表示\n",
    "def display_augmentation_grid(samples, title=\"Data Augmentation Examples\"):\n",
    "    \"\"\"拡張サンプルをグリッドで表示\"\"\"\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, img) in enumerate(samples):\n",
    "        if i < len(axes):\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(name)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    # 空白のサブプロットを非表示\n",
    "    for i in range(len(samples), len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 拡張サンプルを作成して表示\n",
    "augmented_samples = create_augmented_samples(processed_base, 16)\n",
    "display_augmentation_grid(augmented_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 データセットの分割\n",
    "\n",
    "学習データとテストデータを分割する重要性と方法です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_dataset(num_samples_per_digit=500, test_ratio=0.2, augment=True):\n",
    "    \"\"\"手書き数字データセットを作成する\"\"\"\n",
    "    dataset = {\n",
    "        'X_train': [], 'y_train': [],\n",
    "        'X_test': [], 'y_test': [],\n",
    "        'X_raw': [], 'y_raw': []\n",
    "    }\n",
    "    \n",
    "    # それぞれの数字についてデータを作成\n",
    "    for digit in range(10):\n",
    "        print(f\"Digit {digit} の生成中...\")\n",
    "        \n",
    "        # 基本サンプル\n",
    "        raw_samples = []\n",
    "        for _ in range(num_samples_per_digit):\n",
    "            raw_sample = create_handwritten_digit(digit)\n",
    "            raw_samples.append(raw_sample)\n",
    "        \n",
    "        # 拡張\n",
    "        if augment:\n",
    "            augmented_samples = []\n",
    "            for sample in raw_samples:\n",
    "                # 2つの拡張サンプルを追加\n",
    "                for _ in range(2):\n",
    "                    augmented = augment_image(preprocess_image(sample))\n",
    "                    augmented_samples.append(augmented)\n",
    "            \n",
    "            # 元のサンプルも追加\n",
    "            all_samples = [preprocess_image(sample) for sample in raw_samples] + augmented_samples\n",
    "        else:\n",
    "            all_samples = [preprocess_image(sample) for sample in raw_samples]\n",
    "        \n",
    "        # データの分割\n",
    "        n_samples = len(all_samples)\n",
    "        n_test = int(n_samples * test_ratio)\n",
    "        \n",
    "        # ランダムにテストデータを選択\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        test_indices = indices[:n_test]\n",
    "        train_indices = indices[n_test:]\n",
    "        \n",
    "        # データセットに追加\n",
    "        dataset['X_train'].extend([all_samples[i] for i in train_indices])\n",
    "        dataset['y_train'].extend([digit] * len(train_indices))\n",
    "        dataset['X_test'].extend([all_samples[i] for i in test_indices])\n",
    "        dataset['y_test'].extend([digit] * len(test_indices))\n",
    "        dataset['X_raw'].extend(raw_samples)\n",
    "        dataset['y_raw'].extend([digit] * len(raw_samples))\n",
    "    \n",
    "    # NumPy配列に変換\n",
    "    for key in dataset:\n",
    "        if key.startswith('X_'):\n",
    "            dataset[key] = np.array(dataset[key])\n",
    "        elif key.startswith('y_'):\n",
    "            dataset[key] = np.array(dataset[key])\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# データセットの作成（時間がかかるので少なめに）\n",
    "print(\"データセットの生成を開始...\")\n",
    "dataset = create_dataset(num_samples_per_digit=100, test_ratio=0.2, augment=True)\n",
    "\n",
    "# データセットの情報表示\n",
    "print(f\"\\nデータセットのサイズ:\")\n",
    "print(f\"学習データ: {dataset['X_train'].shape} (画像), {dataset['y_train'].shape} (ラベル)\")\n",
    "print(f\"テストデータ: {dataset['X_test'].shape} (画像), {dataset['y_test'].shape} (ラベル)\")\n",
    "\n",
    "# データセットの分布を確認\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "unique, counts = np.unique(dataset['y_train'], return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('Training Data Distribution')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "unique, counts = np.unique(dataset['y_test'], return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('Test Data Distribution')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 特徴の可視化\n",
    "\n",
    "抽出した特徴を可視化し、異なる数字の特徴の違いを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def extract_features_for_dataset(dataset):\n",
    "    \"\"\"データセット全体から特徴を抽出する\"\"\"\n",
    "    features_per_digit = {i: [] for i in range(10)}\n",
    "    \n",
    "    # 最初の100サンプルから特徴を抽出（時間節約）\n",
    "    max_samples = 100\n",
    "    \n",
    "    for digit in range(10):\n",
    "        # この数字のデータからサンプリング\n",
    "        digit_indices = np.where(dataset['y_train'] == digit)[0]\n",
    "        sample_indices = np.random.choice(digit_indices, min(max_samples, len(digit_indices)), replace=False)\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            features = extract_features(dataset['X_train'][idx])\n",
    "            features_per_digit[digit].append(features)\n",
    "    \n",
    "    return features_per_digit\n",
    "\n",
    "# 特徴抽出（時間がかかるので注意）\n",
    "print(\"特徴抽出を開始...\")\n",
    "features_per_digit = extract_features_for_dataset(dataset)\n",
    "\n",
    "# 特徴の平均値を計算\n",
    "feature_means = {i: {} for i in range(10)}\n",
    "for digit in range(10):\n",
    "    for key in features_per_digit[digit][0].keys():\n",
    "        if key != 'histogram':\n",
    "            values = [f[key] for f in features_per_digit[digit]]\n",
    "            feature_means[digit][key] = np.mean(values)\n",
    "\n",
    "# 特徴を可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. 平均値の比較\n",
    "plt.subplot(2, 2, 1)\n",
    "means = [feature_means[d]['mean'] for d in range(10)]\n",
    "plt.bar(range(10), means)\n",
    "plt.title('Mean Pixel Value')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Mean')\n",
    "\n",
    "# 2. 分散の比較\n",
    "plt.subplot(2, 2, 2)\n",
    "vars_ = [feature_means[d]['std']**2 for d in range(10)]  # 分散 = 標準偏差^2\n",
    "plt.bar(range(10), vars_)\n",
    "plt.title('Variance')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Variance')\n",
    "\n",
    "# 3. エッジ強度の比較\n",
    "plt.subplot(2, 2, 3)\n",
    "edges = [feature_means[d]['edge_magnitude'] for d in range(10)]\n",
    "plt.bar(range(10), edges)\n",
    "plt.title('Edge Magnitude')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('Edge Strength')\n",
    "\n",
    "# 4. 重心のX座標比較\n",
    "plt.subplot(2, 2, 4)\n",
    "centroids_x = [feature_means[d]['centroid_x'] for d in range(10)]\n",
    "plt.bar(range(10), centroids_x)\n",
    "plt.title('Centroid X Position')\n",
    "plt.xlabel('Digit')\n",
    "plt.ylabel('X Position')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Practice (2 hours)\n",
    "\n",
    "それでは、学んだ知識を実際に使ってみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: データセットの拡充\n",
    "\n",
    "手書き数字データセットを1000サンプル/数字作成し、CSVファイルに保存せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def save_large_dataset(num_samples=1000, filename='handwritten_digits.csv'):\n",
    "    \"\"\"大きいデータセットを作成して保存する\"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    print(f\"{num_samples}サンプル/数字のデータセット作成中...\")\n",
    "    \n",
    "    # データを保存するリスト\n",
    "    data = []\n",
    "    \n",
    "    for digit in range(10):\n",
    "        print(f\"Digit {digit} を生成中...\")\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            # 画像生成\n",
    "            raw_img = create_handwritten_digit(digit)\n",
    "            processed_img = preprocess_image(raw_img)\n",
    "            \n",
    "            # 画像を1次元に変換\n",
    "            flattened = processed_img.flatten()\n",
    "            \n",
    "            # ラベルを追加\n",
    "            row = [digit] + flattened.tolist()\n",
    "            \n",
    "            data.append(row)\n",
    "    \n",
    "    # DataFrameに変換\n",
    "    columns = ['label'] + [f'pixel_{i}' for i in range(28*28)]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # CSVとして保存\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"データセットを {filename} に保存しました\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 小規模版で実行\n",
    "df_small = save_large_dataset(num_samples=100, filename='small_digits.csv')\n",
    "print(f\"\\nデータセットの形状: {df_small.shape}\")\n",
    "print(f\"最初の5行:\\n{df_small.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: 前処理の最適化\n",
    "\n",
    "異なる前処理方法を試し、最適な組み合わせを見つけよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def preprocess_with_methods(image, methods):\n",
    "    \"\"\"指定された前処理メソッドを適用する\"\"\"\n",
    "    processed = image.copy().astype(np.float64)\n",
    "    \n",
    "    for method in methods:\n",
    "        if method == 'normalize':\n",
    "            # 正規化\n",
    "            processed = (processed - processed.min()) / (processed.max() - processed.min())\n",
    "        elif method == 'binarize':\n",
    "            # 二値化（適切な閾値で）\n",
    "            threshold = np.percentile(processed, 50)\n",
    "            processed = (processed > threshold).astype(float)\n",
    "        elif method == 'equalize':\n",
    "            # ヒストグラム平坦化\n",
    "            processed = cv2.equalizeHist((processed * 255).astype(np.uint8)) / 255.0\n",
    "        elif method == 'denoise':\n",
    "            # ノイズ除去\n",
    "            processed = cv2.medianBlur((processed * 255).astype(np.uint8), 3) / 255.0\n",
    "        elif method == 'blur':\n",
    "            # ぼかし（ノイズ除去の代わり）\n",
    "            processed = cv2.GaussianBlur(processed, (3, 3), 0)\n",
    "        elif method == 'threshold':\n",
    "            # 固定閾値\n",
    "            _, processed = cv2.threshold((processed * 255).astype(np.uint8), 127, 255, cv2.THRESH_BINARY)\n",
    "            processed = processed / 255.0\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# 異なる前処理パイプラインの比較\n",
    "def compare_preprocessing_methods(test_digit=3):\n",
    "    \"\"\"前処理方法の比較\"\"\"\n",
    "    # テスト用画像\n",
    "    original = create_handwritten_digit(test_digit)\n",
    "    \n",
    "    # 前処理パイプラインの定義\n",
    "    pipelines = {\n",
    "        'Original': original,\n",
    "        'Normalize Only': preprocess_with_methods(original, ['normalize']),\n",
    "        'Binary Only': preprocess_with_methods(original, ['binarize']),\n",
    "        'Denoised': preprocess_with_methods(original, ['normalize', 'denoise']),\n",
    "        'Equalized': preprocess_with_methods(original, ['normalize', 'equalize']),\n",
    "        'Threshold': preprocess_with_methods(original, ['normalize', 'threshold']),\n",
    "        'Full Pipeline': preprocess_with_methods(original, ['normalize', 'denoise', 'threshold'])\n",
    "    }\n",
    "    \n",
    "    # 表示\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (name, img) in enumerate(pipelines.items()):\n",
    "        if i < len(axes):\n",
    "            axes[i].imshow(img, cmap='gray')\n",
    "            axes[i].set_title(name)\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Digit {test_digit} - Preprocessing Comparison', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 特徴比較\n",
    "    features_comparison = {}\n",
    "    for name, img in pipelines.items():\n",
    "        if name != 'Original':\n",
    "            features_comparison[name] = extract_features(img)\n",
    "    \n",
    "    return features_comparison\n",
    "\n",
    "# 前処理方法の比較\n",
    "features_comp = compare_preprocessing_methods(7)\n",
    "\n",
    "# 特徴の比較\n",
    "print(\"\\n特徴量の比較:\")\n",
    "for method, features in features_comp.items():\n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  平均: {features['mean']:.4f}\")\n",
    "    print(f\"  標準偏差: {features['std']:.4f}\")\n",
    "    print(f\"  エッジ強度: {features['edge_magnitude']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: カスタム特徴量の実装\n",
    "\n",
    "新たな特徴量を3つ以上追加し、その有用性を評価せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "source": [
     "def extract_advanced_features(image):\n",
    "    \"\"\"高度な特徴量を抽出する関数\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # 画像サイズ\n",
    "    h, w = image.shape\n",
    "    \n",
    "    # 1. 水平/垂直方向の投影プロファイル\n",
    "    horizontal_proj = np.sum(image, axis=1)  # 行方向の合計\n",
    "    vertical_proj = np.sum(image, axis=0)    # 列方向の合計\n",
    "    \n",
    "    features['horizontal_max'] = np.max(horizontal_proj)\n",
    "    features['horizontal_std'] = np.std(horizontal_proj)\n",
    "    features['vertical_max'] = np.max(vertical_proj)\n",
    "    features['vertical_std'] = np.std(vertical_proj)\n",
    "    \n",
    "    # 2. 密度分布\n",
    "    threshold = 0.5\n",
    "    density_above = np.sum(image > threshold) / (h * w)\n",
    "    features['density_above_threshold'] = density_above\n",
    "    \n",
    "    # 3. Zernikeモーメント（近似）\n",
    "    # 中心からの座標\n",
    "    y, x = np.mgrid[0:h, 0:w]\n",
    "    center_y, center_x = h//2, w//2\n",
    "    \n",
    "    # 中心からの座標（正規化）\n",
    "    norm_y = (y - center_y) / (h/2)\n",
    "    norm_x = (x - center_x) / (w/2)\n",
    "    \n",
    "    # 0次Zernikeモーメント（画像の重み合計）\n",
    "    features['zernike_00'] = np.sum(image)\n",
    "    \n",
    "    # 1次モーメント（重心の近似）\n",
    "    if features['zernike_00'] > 0:\n",
    "        features['zernike_10'] = np.sum(norm_x * image) / features['zernike_00']\n",
    "        features['zernike_01'] = np.sum(norm_y * image) / features['zernike_00']\n",
    "    else:\n",
    "        features['zernike_10'] = 0\n",
    "        features['zernike_01'] = 0\n",
    "    \n",
    "    # 2次モーメント（慣性モーメントの近似）\n",
    "    if features['zernike_00'] > 0:\n",
    "        features['zernike_20'] = np.sum(norm_x**2 * image) / features['zernike_00']\n",
    "        features['zernike_02'] = np.sum(norm_y**2 * image) / features['zernike_00']\n",
    "        features['zernike_11'] = np.sum(norm_x * norm_y * image) / features['zernike_00']\n",
    "    else:\n",
    "        features['zernike_20'] = 0\n",
    "        features['zernike_02'] = 0\n",
    "        features['zernike_11'] = 0\n",
    "    \n",
    "    # 4. ラプラシアンエネルギー（エッジの鋭さ）\n",
    "    laplacian = cv2.Laplacian(image.astype(np.float32), cv2.CV_64F)\n",
    "    features['laplacian_energy'] = np.sum(np.abs(laplacian))\n",
    "    \n",
    "    # 5. HOG特徴（Histogram of Oriented Gradients）の簡易版\n",
    "    # Sobelで勾配を計算\n",
    "    sobel_x = cv2.Sobel(image.astype(np.float32), cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(image.astype(np.float32), cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # 勾配の大きさと角度\n",
    "    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    angle = np.arctan2(sobel_y, sobel_x) * 180 / np.pi\n",
    "    \n",
    "    # 角度を9つのビンに分類\n",
    "    angle_bins = np.digitize(angle, bins=np.linspace(-180, 180, 10)) - 1\n",
    "    \n",
    "    # HOGヒストグラム\n",
    "    hog_hist = np.zeros(9)\n",
    "    for i in range(9):\n",
    "        hog_hist[i] = np.sum(magnitude[angle_bins == i])\n",
    "    \n",
    "    features['hog_max'] = np.max(hog_hist)\n",
    "    features['hog_mean'] = np.mean(hog_hist)\n",
    "    features['hog_std'] = np.std(hog_hist)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# 高度な特徴抽出の実例\n",
    "sample_digits = [0, 3, 7]  # 代表的な数字を選択\n",
    "\n",
    "for digit in sample_digits:\n",
    "    print(f\"\\n=== Digit {digit} ===\")\n",
    "    \n",
    "    # 画像生成と前処理\n",
    "    original = create_handwritten_digit(digit)\n",
    "    processed = preprocess_image(original)\n",
    "    \n",
    "    # 特徴抽出\n",
    "    basic_features = extract_features(processed)\n",
    "    advanced_features = extract_advanced_features(processed)\n",
    "    \n",
    "    print(\"基本特徴量:\")\n",
    "    for key, value in basic_features.items():\n",
    "        if key != 'histogram':\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\n高度な特徴量:\")\n",
    "    for key, value in advanced_features.items():\n",
    "        if isinstance(value, np.ndarray) and value.ndim == 1:\n",
    "            print(f\"  {key}: mean={value.mean():.4f}, std={value.std():.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "## Exercise 2.4: 特徴の分布分析\n",
     "\n",
     "異なる数字の特徴の分布を分析し、識別しやすい特徴を見つけよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "source": [
     "def analyze_feature_distribution(dataset, feature_name):\n",
    "    \"\"\"特定の特徴の分布を分析する\"\"\"\n",
    "    feature_values = {i: [] for i in range(10)}\n",
    "    \n",
    "    # 各数字から特徴を抽出\n",
    "    for digit in range(10):\n",
    "        digit_indices = np.where(dataset['y_train'] == digit)[0]\n",
    "        \n",
    "        # サンプリング（計算時間節約）\n",
    "        sample_indices = np.random.choice(digit_indices, min(50, len(digit_indices)), replace=False)\n",
    "        \n",
    "        for idx in sample_indices:\n",
    "            features = extract_features(dataset['X_train'][idx])\n",
    "            feature_values[digit].append(features[feature_name])\n",
    "    \n",
    "    # 分布を可視化\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # ヒストグラム\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for digit in range(10):\n",
    "        plt.hist(feature_values[digit], alpha=0.5, label=f'Digit {digit}', bins=20)\n",
    "    plt.xlabel(feature_name)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Distribution of {feature_name}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 箱ひげ図\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot([feature_values[d] for d in range(10)], labels=[str(d) for d in range(10)])\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel(feature_name)\n",
    "    plt.title(f'{feature_name} by Digit')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_values\n",
    "\n",
    "# 有望な特徴のリスト\n",
    "promising_features = [\n",
    "    'mean',          # 平均輝度\n",
    "    'std',           # 標準偏差\n",
    "    'edge_magnitude', # エッジ強度\n",
    "    'centroid_x',    # 重心X座標\n",
    "    'variance_x',    # X方向の分散\n",
    "    'aspect_ratio'   # アスペクト比\n",
    "]\n",
    "\n",
    "# 特徴の分布分析\n",
    "for feature in promising_features:\n",
    "    print(f\"\\n--- Analyzing {feature} ---\")\n",
    "    feature_values = analyze_feature_distribution(dataset, feature)\n",
    "    \n",
    "    # クラス間分離度を計算（Fisher's Discriminant Ratio）\n",
    "    between_class_variance = 0\n",
    "    within_class_variance = 0\n",
    "    overall_mean = np.mean([np.mean(feature_values[d]) for d in range(10)])\n",
    "    \n",
    "    for digit in range(10):\n",
    "        digit_mean = np.mean(feature_values[digit])\n",
    "        digit_var = np.var(feature_values[digit])\n",
    "        \n",
    "        between_class_variance += len(feature_values[digit]) * (digit_mean - overall_mean)**2\n",
    "        within_class_variance += (len(feature_values[digit]) - 1) * digit_var\n",
    "    \n",
    "    if within_class_variance > 0:\n",
    "        fisher_ratio = between_class_variance / within_class_variance\n",
    "        print(f\"\\nFisher's Discriminant Ratio: {fisher_ratio:.4f}\")\n",
    "        \n",
    "        # Fisher比が大きいほどクラスが分離しやすい\n",
    "        if fisher_ratio > 2:\n",
    "            print(f\"  ✅ {feature} はクラスを識別しやすい特徴量です\")\n",
    "        elif fisher_ratio > 1:\n",
    "            print(f\"  ⚠️  {feature} は中程度の識別力があります\")\n",
    "        else:\n",
    "            print(f\"  ❌ {feature} は識別にあまり役立ちません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "## Exercise 2.5: データセットの保存と読み込み\n",
     "\n",
     "作成したデータセットをNumPy形式で保存し、後で読み込めるようにせよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "source": [
     "import os\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "def save_dataset_with_features(dataset, base_filename='digits_dataset'):\n",
    "    \"\"\"データセットと特徴を保存する\"\"\"\n",
    "    print(\"データセットの準備と保存を開始...\")\n",
    "    \n",
    "    # ファイルパス\n",
    "    npy_dir = 'datasets'\n",
    "    os.makedirs(npy_dir, exist_ok=True)\n",
    "    \n",
    "    # データセットを保存\n",
    "    np.save(f'{npy_dir}/{base_filename}_X_train.npy', dataset['X_train'])\n",
    "    np.save(f'{npy_dir}/{base_filename}_y_train.npy', dataset['y_train'])\n",
    "    np.save(f'{npy_dir}/{base_filename}_X_test.npy', dataset['X_test'])\n",
    "    np.save(f'{npy_dir}/{base_filename}_y_test.npy', dataset['y_test'])\n",
    "    \n",
    "    print(f\"NumPy形式で保存完了: {npy_dir}/{base_filename}_*.npy\")\n",
    "    \n",
    "    # 特徴データセットを作成\n",
    "    print(\"特徴データセットを作成中...\")\n",
    "    \n",
    "    # 訓練データから特徴を抽出（サンプリングして計算時間を節約）\n",
    "    sample_size = min(1000, len(dataset['X_train']))\n",
    "    sample_indices = np.random.choice(len(dataset['X_train']), sample_size, replace=False)\n",
    "    \n",
    "    X_features = []\n",
    "    y_features = []\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        features = extract_features(dataset['X_train'][idx])\n",
    "        feature_vector = [\n",
    "            features['mean'],\n",
    "            features['std'],\n",
    "            features['aspect_ratio'],\n",
    "            features['centroid_x'] / 28,  # 正規化\n",
    "            features['centroid_y'] / 28,  # 正規化\n",
    "            features['edge_magnitude'],\n",
    "            features['variance_x'] / (28**2),  # 正規化\n",
    "            features['variance_y'] / (28**2)   # 正規化\n",
    "        ]\n",
    "        X_features.append(feature_vector)\n",
    "        y_features.append(dataset['y_train'][idx])\n",
    "    \n",
    "    # 特徴データセットを保存\n",
    "    np.save(f'{npy_dir}/{base_filename}_features.npy', np.array(X_features))\n",
    "    np.save(f'{npy_dir}/{base_filename}_feature_labels.npy', np.array(y_features))\n",
    "    \n",
    "    print(f\"特徴データセットを保存: {npy_dir}/{base_filename}_features.npy\")\n",
    "    \n",
    "    # メタデータを保存\n",
    "    metadata = {\n",
    "        'num_train_samples': len(dataset['X_train']),\n",
    "        'num_test_samples': len(dataset['X_test']),\n",
    "        'num_features': 8,\n",
    "        'image_shape': dataset['X_train'].shape[1:],\n",
    "        'feature_names': [\n",
    "            'mean', 'std', 'aspect_ratio', \n",
    "            'centroid_x', 'centroid_y', \n",
    "            'edge_magnitude', 'variance_x', 'variance_y'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    with open(f'{npy_dir}/{base_filename}_metadata.pkl', 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "    \n",
    "    print(f\"メタデータを保存: {npy_dir}/{base_filename}_metadata.pkl\")\n",
    "    \n",
    "    return npy_dir, base_filename\n",
    "\n",
    "def load_dataset_with_features(npz_dir='datasets', base_filename='digits_dataset'):\n",
    "    \"\"\"保存されたデータセットを読み込む\"\"\"\n",
    "    print(\"データセットの読み込みを開始...\")\n",
    "    \n",
    "    # ディレクトリの確認\n",
    "    if not os.path.exists(npz_dir):\n",
    "        raise FileNotFoundError(f\"ディレクトリ {npz_dir} が存在しません\")\n",
    "    \n",
    "    # ファイルパス\n",
    "    paths = {\n",
    "        'X_train': f'{npz_dir}/{base_filename}_X_train.npy',\n",
    "        'y_train': f'{npz_dir}/{base_filename}_y_train.npy',\n",
    "        'X_test': f'{npz_dir}/{base_filename}_X_test.npy',\n",
    "        'y_test': f'{npz_dir}/{base_filename}_y_test.npy',\n",
    "        'features': f'{npz_dir}/{base_filename}_features.npy',\n",
    "        'feature_labels': f'{npz_dir}/{base_filename}_feature_labels.npy',\n",
    "        'metadata': f'{npz_dir}/{base_filename}_metadata.pkl'\n",
    "    }\n",
    "    \n",
    "    # ファイルの存在確認\n",
    "    for name, path in paths.items():\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"ファイル {path} が存在しません\")\n",
    "    \n",
    "    # データの読み込み\n",
    "    loaded_data = {}\n",
    "    for name in ['X_train', 'y_train', 'X_test', 'y_test', 'features', 'feature_labels']:\n",
    "        loaded_data[name] = np.load(paths[name])\n",
    "    \n",
    "    # メタデータの読み込み\n",
    "    with open(paths['metadata'], 'rb') as f:\n",
    "        loaded_data['metadata'] = pickle.load(f)\n",
    "    \n",
    "    print(\"読み込んだデータセットの情報:\")\n",
    "    print(f\"訓練画像: {loaded_data['X_train'].shape}\")\n",
    "    print(f\"訓練ラベル: {loaded_data['y_train'].shape}\")\n",
    "    print(f\"テスト画像: {loaded_data['X_test'].shape}\")\n",
    "    print(f\"テストラベル: {loaded_data['y_test'].shape}\")\n",
    "    print(f\"特徴ベクトル: {loaded_data['features'].shape}\")\n",
    "    print(f\"特徴ラベル: {loaded_data['feature_labels'].shape}\")\n",
    "    \n",
    "    return loaded_data\n",
    "\n",
    "# 保存を実行（データセットが存在すれば）\n",
    "if 'dataset' in locals() and len(dataset['X_train']) > 0:\n",
    "    npz_dir, base_filename = save_dataset_with_features(dataset)\n",
    "    \n",
    "    # 読み込みのテスト\n",
    "    loaded_data = load_dataset_with_features(npz_dir, base_filename)\n",
    "    \n",
    "    # データのサンプル表示\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # 元の画像のサンプル\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sample_idx = 0\n",
    "    plt.imshow(loaded_data['X_train'][sample_idx], cmap='gray')\n",
    "    plt.title(f\"Original Image (Label: {loaded_data['y_train'][sample_idx]})\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 特徴ベクトルの表示\n",
    "    plt.subplot(1, 3, 2)\n",
    "    feature_names = loaded_data['metadata']['feature_names']\n",
    "    plt.barh(range(len(feature_names)), loaded_data['features'][sample_idx])\n",
    "    plt.yticks(range(len(feature_names)), feature_names)\n",
    "    plt.title(\"Feature Vector\")\n",
    "    plt.xlabel(\"Value\")\n",
    "    \n",
    "    # 特徴の分布\n",
    "    plt.subplot(1, 3, 3)\n",
    "    for digit in range(10):\n",
    "        digit_features = loaded_data['features'][loaded_data['feature_labels'] == digit]\n",
    "        plt.scatter([digit] * len(digit_features), feature_names, \n",
    "                   alpha=0.3, label=f'Digit {digit}')\n",
    "    \n",
    "    plt.title(\"Feature Distribution by Digit\")\n",
    "    plt.xlabel(\"Digit\")\n",
    "    plt.ylabel(\"Feature Names\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "## Exercise 2.6: データセットのバリデーション\n",
     "\n",
     "保存したデータセットの整合性を確認し、問題がないことを検証せよ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "source": [
     "def validate_dataset(dataset_path='datasets', dataset_name='digits_dataset'):\n",
    "    \"\"\"データセットの整合性を検証する\"\"\"\n",
    "    print(f\"データセット {dataset_name} の整合性検証...\")\n",
    "    \n",
    "    # ファイルの存在確認\n",
    "    required_files = [\n",
    "        f'{dataset_path}/{dataset_name}_X_train.npy',\n",
    "        f'{dataset_path}/{dataset_name}_y_train.npy',\n",
    "        f'{dataset_path}/{dataset_name}_X_test.npy',\n",
    "        f'{dataset_path}/{dataset_name}_y_test.npy',\n",
    "        f'{dataset_path}/{dataset_name}_features.npy',\n",
    "        f'{dataset_path}/{dataset_name}_metadata.pkl'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n1. ファイル存在チェック\")\n",
    "    for file in required_files:\n",
    "        if os.path.exists(file):\n",
    "            size = os.path.getsize(file) / (1024 * 1024)  # MB\n",
    "            print(f\"  ✅ {os.path.basename(file)} ({size:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"  ❌ {os.path.basename(file)} - ファイルが見つかりません\")\n",
    "            return False\n",
    "    \n",
    "    # データの読み込み\n",
    "    print(\"\\n2. データ読み込み\")\n",
    "    try:\n",
    "        X_train = np.load(f'{dataset_path}/{dataset_name}_X_train.npy')\n",
    "        y_train = np.load(f'{dataset_path}/{dataset_name}_y_train.npy')\n",
    "        X_test = np.load(f'{dataset_path}/{dataset_name}_X_test.npy')\n",
    "        y_test = np.load(f'{dataset_path}/{dataset_name}_y_test.npy')\n",
    "        features = np.load(f'{dataset_path}/{dataset_name}_features.npy')\n",
    "        \n",
    "        with open(f'{dataset_path}/{dataset_name}_metadata.pkl', 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        print(\"  ✅ すべてのファイルを読み込み成功\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ データ読み込みエラー: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # データ形状の検証\n",
    "    print(\"\\n3. データ形状の検証\")\n",
    "    \n",
    "    # ラベルの範囲チェック\n",
    "    print(f\"  - 訓練ラベルの範囲: {min(y_train)} - {max(y_train)}\")\n",
    "    print(f\"  - テストラベルの範囲: {min(y_test)} - {max(y_test)}\")\n",
    "    \n",
    "    # 画像形状のチェック\n",
    "    print(f\"  - 訓練画像の形状: {X_train.shape}\")\n",
    "    print(f\"  - テスト画像の形状: {X_test.shape}\")\n",
    "    \n",
    "    # 画像値の範囲チェック\n",
    "    X_train_min, X_train_max = X_train.min(), X_train.max()\n",
    "    X_test_min, X_test_max = X_test.min(), X_test.max()\n",
    "    print(f\"  - 訓練画像の値の範囲: [{X_train_min:.4f}, {X_train_max:.4f}]\")\n",
    "    print(f\"  - テスト画像の値の範囲: [{X_test_min:.4f}, {X_test_max:.4f}]\")\n",
    "    \n",
    "    # メタデータとの一致確認\n",
    "    print(\"\\n4. メタデータの検証\")\n",
    "    print(f\"  - 訓練サンプル数: {metadata['num_train_samples']} (実数: {len(X_train)})\")\n",
    "    print(f\"  - テストサンプル数: {metadata['num_test_samples']} (実数: {len(X_test)})\")\n",
    "    print(f\"  - 画像形状: {metadata['image_shape']} (実数: {X_train.shape[1:]})\")\n",
    "    \n",
    "    # データのランダムサンプリングで表示\n",
    "    print(\"\\n5. データサンプルの確認\")\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        # ランダムにインデックスを選択\n",
    "        idx = np.random.randint(len(X_train))\n",
    "        ax.imshow(X_train[idx], cmap='gray')\n",
    "        ax.set_title(f\"Label: {y_train[idx]}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # データ分布の検証\n",
    "    print(\"\\n6. データ分布の検証\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # 訓練データの分布\n",
    "    plt.subplot(1, 2, 1)\n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    plt.bar(unique, counts)\n",
    "    plt.title('Training Data Distribution')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # テストデータの分布\n",
    "    plt.subplot(1, 2, 2)\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    plt.bar(unique, counts)\n",
    "    plt.title('Test Data Distribution')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✅ データセットの整合性検証が完了しました\")\n",
    "    return True\n",
    "\n",
    "# データセットの検証（保存されている場合）\n",
    "if os.path.exists('datasets'):\n",
    "    validation_result = validate_dataset()\n",
    "    if validation_result:\n",
    "        print(\"\\nデータセットは正常に使用できます\")\n",
    "    else:\n",
    "        print(\"\\nデータセットに問題が検出されました\")\n",
    "else:\n",
    "    print(\"保存されたデータセットが見つかりません\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "## Challenge: 高度なデータ拡張\n",
     "\n",
     "GAN（敵対的生成ネットワーク）を用いて、より現実的な手書き数字を生成するプロトタイプを実装せよ。\n",
     "（ヒント: 事前学習モデルを利用またはシンプルなGANを実装）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "source": [
     "# Challenge問題: GANによる手書き数字生成\n",
     "# 時間の関係で、シンプルなGANの実装を示します\n",
     "\n",
     "class SimpleGAN:\n",
    "    \"\"\"シンプルなGANの実装（概念）\"\"\"\n",
    "    def __init__(self, latent_dim=100, image_shape=(28, 28)):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.image_shape = image_shape\n",
    "        self.generator = None\n",
    "        self.discriminator = None\n",
    "        \n",
    "    def build_generator(self):\n",
    "        \"\"\"生成器を構築（実際の実装ではKeras/TensorFlow/PyTorchを使用）\"\"\"\n",
    "        # ここではダミーの実装\n",
    "        print(\"Generator: ノイズから画像を生成するニューラルネットワーク\")\n",
    "        print(f\"  入力: 潜在空間のベクトル (size={self.latent_dim})\")\n",
    "        print(f\"  出力: {self.image_shape} の画像\")\n",
    "        return \"Generator built\"\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        \"\"\"識別器を構築\"\"\"\n",
    "        # ここではダミーの実装\n",
    "        print(\"Discriminator: 本物/偽物を識別するニューラルネットワーク\")\n",
    "        print(f\"  入力: {self.image_shape} の画像\")\n",
    "        print(\"  出力: 本物確率（0-1）\")\n",
    "        return \"Discriminator built\"\n",
    "    \n",
    "    def train(self, dataset, epochs=10):\n",
    "        \"\"\"GANを訓練\"\"\"\n",
    "        print(f\"GANの訓練を開始... (Epochs: {epochs})\")\n",
    "        print(\"実際の実装では、KerasやPyTorchを使用\")\n",
    "        \n",
    "        # 訓練ループの概念\n",
    "        for epoch in range(epochs):\n",
    "            # 1. 識別器の訓練\n",
    "            # 2. 生成器の訓練\n",
    "            # 3. 損失の計算\n",
    "            print(f\"  Epoch {epoch+1}/{epochs} - completed\")\n",
    "        \n",
    "        print(\"訓練完了\")\n",
    "        return self\n",
    "    \n",
    "    def generate_images(self, num_images=10):\n",
    "        \"\"\"画像を生成\"\"\"\n",
    "        print(f\"{num_images} 枚の画像を生成...\")\n",
    "        print(\"実際には、訓練済みの生成器を使用\")\n",
    "        \n",
    "        # ダミーの生成（ランダムノイズ）\n",
    "        dummy_images = []\n",
    "        for i in range(num_images):\n",
    "            # 乱数ベクトルから画像を生成\n",
    "            noise = np.random.randn(self.latent_dim)\n",
    "            # 生成器による変換（ここでは単なる乱数の可視化）\n",
    "            fake_image = np.random.rand(*self.image_shape) * 0.5 + 0.25\n",
    "            dummy_images.append(fake_image)\n",
    "        \n",
    "        return dummy_images\n",
    "\n",
    "# GANの使用例\n",
    "print(\"\\n=== GANによる手書き数字生成の概念 ===\")\n",
    "gan = SimpleGAN()\n",
    "gan.build_generator()\n",
    "gan.build_discriminator()\n",
    "\n",
    "# 訓練（実際には多くのデータと時間が必要）\n",
    "# gan.train(dataset, epochs=100)\n",
    "\n",
    "# 生成\n",
    "generated_images = gan.generate_images(10)\n",
    "\n",
    "# 生成された画像の表示\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(generated_images):\n",
    "        ax.imshow(generated_images[i], cmap='gray')\n",
    "        ax.set_title(f'Generated {i}')\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.suptitle('GAN Generated Images (Conceptual)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n実際のGANの実装には以下の技術が必要です:\")\n",
    "print(\"- ディープラーニングフレームワーク (TensorFlow/Keras, PyTorch)\")\n",
    "print(\"- バッチ正規化とドロップアウト\")\n",
    "print(\"- オプティマイザ（Adamなど）\")\n",
    "print(\"- 損失関数（二値交差エントロピー）\")\n",
    "print(\"- 勾配クリッピングなど）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "---\n",
     "\n",
     "# Self-Check (理解度確認)\n",
     "\n",
     "本日の学習内容を確認しましょう：\n",
     "\n",
     "## 基礎知識\n",
     "- [ ] 手書き数字認識の目的とMNISTデータセットの特徴を理解した\n",
     "- [ ] 画像前処理パイプラインの各ステップを説明できる\n",
     "- [ ] 特徴抽出の目的と重要性を理解した\n",
     "- [ ] データ拡張の意義と手法を理解した\n",
     "\n",
     "## 技術要素\n",
     "- [ ] 画像生成アルゴリズムを理解した\n",
     "- [ ] 前処理手法（正規化、二値化、ノイズ除去など）を実装できる\n",
     "- [ ] 基本的な特徴量（統計量、重心、エッジなど）を抽出できる\n",
     "- [ ] データ拡張の様々な手法を実装できる\n",
     "\n",
     "## 実践力\n",
     "- [ ] 手書き数字データセットを生成した\n",
     "- [ ] データの保存と読み込みを実装した\n",
     "- [ ] 特徴分布分析を実行した\n",
     "- [ ] データセットの整合性検証を行った\n",
     "\n",
     "## 発展的トピック\n",
     "- [ ] GANの基本概念を理解した\n",
     "- [ ] 高度な特徴量（Zernikeモーメント、HOGなど）を理解した\n",
     "- [ ] データ拡張の戦略（回転、スケーリング、明度変更）を設計した\n",
     "\n",
     "---\n",
     "\n",
     "**お疲れ様でした！** Day 22はこれで終了です。\n",
     "\n",
     "次回（Day 23）は「分類器の実装」を学び、k-NNなどのアルゴリズムを実装します。\n",
     "\n",
     "復習課題：\n",
    "1. 生成したデータセットをロードし、特徴量を可視化する\n",
    "2. 異なる前処理手法の効果を比較する\n",
    "3. データ拡張が認識性能に与える影響を分析する"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}