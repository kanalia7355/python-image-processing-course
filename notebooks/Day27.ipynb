{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 27: 物体検出の基礎 - YOLOとSSDの実装\n",
    "\n",
    "## Learning Objectives\n",
    "- 物体検出の概念を理解する\n",
    "- Two-stage detectors (Faster R-CNN) と One-stage detectors (YOLO, SSD) の違いを理解する\n",
    "- YOLOとSSDのアーキテクチャと動作原理を学ぶ\n",
    "- Anchor boxesとNMSの概念を理解する\n",
    "- 実際の物体検出システムをPythonで実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: 理論セクション（2時間）\n",
    "\n",
    "## 1.1 物体検出とは？\n",
    "\n",
    "物体検出（Object Detection）は、画像中の物体の位置とクラスを同時に行うタスクです。\n",
    "\n",
    "**定義**:\n",
    "- **物体の位置**: Bounding Box (バウンディングボックス) で表現\n",
    "- **物体のクラス**: 「犬」「猫」「自動車」などのカテゴリ\n",
    "\n",
    "**出力形式**:\n",
    "```\n",
    " [x_min, y_min, x_max, y_max, confidence, class_id]\n",
    "```\n",
    "\n",
    "**例**: [10, 20, 110, 210, 0.95, 2]\n",
    "- 位置: (10, 20)から(110, 210)の矩形領域\n",
    "- 信頼度: 95%\n",
    "- クラスID: 2（例: 自動車）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体検出の応用例\n",
    "\n",
    "1. **自動運転**: 歩行者、車、信号の検出\n",
    "2. **監視カメラ**: 不審人物の追跡\n",
    "3. **医療画像**: 病変部位の検出\n",
    "4. **eコマース**: 商品の特定\n",
    "5. **ロボット**: 物体の認識と操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 物体検出の評価指標\n",
    "\n",
    "1. **IoU (Intersection over Union)**:\n",
    "   - 予測とGround Truthの重なり度合い\n",
    "   - \n",
    "   \n",
    "   ```\n",
    "   IoU = (予測 ∩ 正解) / (予測 ∪ 正解)\n",
    "   ```\n",
    "\n",
    "2. **mAP (mean Average Precision)**:\n",
    "   - 各クラスのAPの平均\n",
    "   - 物体検出で最も一般的な指標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Two-stage Detectors vs One-stage Detectors\n",
    "\n",
    "### Two-stage Detectors（二段階検出器）\n",
    "\n",
    "**代表例**: R-CNN → Fast R-CNN → Faster R-CNN\n",
    "\n",
    "**特徴**:\n",
    "- 1段階: Region Proposal（領域提案）\n",
    "- 2段階: Classification and Bounding Box Regression\n",
    "- **精度**: 高いが遅い\n",
    "- **速度**: 約2-5 FPS\n",
    "\n",
    "**Faster R-CNNのアーキテクチャ**:\n",
    "```\n",
    "入力画像 → ResNet → RPN → RoI Pooling → FC層 → クラス分類・回帰\n",
    "```\n",
    "\n",
    "**RPN (Region Proposal Network)**:\n",
    "- 画像全体から物体の存在が可能性のある領域を提案\n",
    "- Anchor boxesを使った提案生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-stage Detectors（一段階検出器）\n",
    "\n",
    "**代表例**: YOLO, SSD, RetinaNet\n",
    "\n",
    "**特徴**:\n",
    "- 1段階でClassificationとRegressionを行う\n",
    "- **精度**: Two-stageより低いが高速\n",
    "- **速度**: 15-60 FPS\n",
    "\n",
    "**比較表**:\n",
    "| 特性 | Two-stage | One-stage |\n",
    "|------|-----------|----------|\n",
    "| 精度 | 高い | 中程度 |\n",
    "| 速度 | 遅い | 速い |\n",
    "| 計算量 | 大 | 中 |\n",
    "| 応用 | 高精度な検出 | リアルタイムアプリケーション |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 YOLO (You Only Look Once)\n",
    "\n",
    "### YOLOの基本思想\n",
    "\n",
    "- 画像をグリッドに分割\n",
    "- 各グリッドセルが物体の中心を検出\n",
    "- 物体が存在するセルのみが予測を行う\n",
    "\n",
    "**YOLO v3のアーキテクチャ**:\n",
    "```\n",
    "入力(416x416x3) → Darknet-53 → Feature Maps (3サイズ) → Yolo Layers\n",
    "```\n",
    "\n",
    "**Darknet-53**: ResNetを改良したネットワーク\n",
    "- Residual blocksを使用\n",
    "- 53層の深いネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOの予測仕組み\n",
    "\n",
    "入力画像はS×Sのグリッドに分割されます。\n",
    "\n",
    "**グリッドセルあたりの予測**:\n",
    "- 5個のBounding Box\n",
    "- 各Boxには:\n",
    "  - 4つの座標 (x, y, w, h)\n",
    "  - 1つの信頼度 (confidence)\n",
    "  - 20個のクラス確率（COCOデータセットの場合）\n",
    "\n",
    "**Boxの表現**:\n",
    "```\n",
    "[x, y, w, h, confidence, class_1, class_2, ..., class_20]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOの損失関数\n",
    "\n",
    "```\n",
    "L = λ_coord * L_coord + λ_obj * L_obj + λ_noobj * L_noobj + L_class\n",
    "```\n",
    "\n",
    "**各項目の意味**:\n",
    "- L_coord: 座標の誤差 (x, y, w, h)\n",
    "- L_obj: 物体がある場合の誤差\n",
    "- L_noobj: 物体がない場合の誤差\n",
    "- L_class: クラス分類の誤差\n",
    "\n",
    "**重み係数**:\n",
    "- λ_coord = 5\n",
    "- λ_obj = 1\n",
    "- λ_noobj = 0.5\n",
    "\n",
    "座標誤差を重くする理由: 正確な位置が物体検出で最も重要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 SSD (Single Shot MultiBox Detector)\n",
    "\n",
    "### SSDの基本思想\n",
    "\n",
    "- 複数のサイズのFeature Mapで検出\n",
    "- 各Feature Mapに異なるサイズのAnchor boxesを適用\n",
    "- Multi-scaleでの検出が可能\n",
    "\n",
    "**SSD v3のアーキテクチャ**:\n",
    "```\n",
    "入力(300x300x3) → VGG16 → 特徴マルチスケール(6サイズ) → 検出ヘッド\n",
    "```\n",
    "\n",
    "**特徴マルチスケール**:\n",
    "- 38x38 (小物体)\n",
    "- 19x19\n",
    "- 10x10\n",
    "- 5x5\n",
    "- 3x3\n",
    "- 1x1 (大物体)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSDの予測仕組み\n",
    "\n",
    "各Feature Map位置に複数のAnchor boxesを配置:\n",
    "\n",
    "**検出ヘッドの出力**:\n",
    "- 各Anchor boxに対して:\n",
    "  - 4つの座標変換 (dx, dy, dw, dh)\n",
    "  - 1つの物体信頼度\n",
    "  - C個のクラス確率\n",
    "\n",
    "**座標変換の式**:\n",
    "```\n",
    "cx = dx * pw + px\n",
    "cy = dy * ph + py\n",
    "w = pw * exp(dw)\n",
    "h = ph * exp(dh)\n",
    "```\n",
    "\n",
    "- (px, py, pw, ph): Anchor boxの座標とサイズ\n",
    "- (dx, dy, dw, dh): ネットワークからの予測値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Anchor Boxes\n",
    "\n",
    "### Anchor boxesとは\n",
    "\n",
    "- 事前に定義された矩形の集合\n",
    "- 物体の多様な形状をカバーする\n",
    "- 検出の性能向上に貢献\n",
    "\n",
    "**Anchor boxの選定**:\n",
    "- Aspect Ratios: 1:1, 1:2, 2:1\n",
    "- Scales: 小・中・大\n",
    "\n",
    "**YOLO v3のAnchor boxes**:\n",
    "```\n",
    "#[10,13],  [16,30],  [33,23],  # 小\n",
    "#[30,61],  [62,45],  [59,119], # 中\n",
    "#[116,90], [156,198], [373,326] # 大\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor boxesの生成\n",
    "\n",
    "```\n",
    " def generate_anchors(scales, aspect_ratios):\n",
    "    \"\"\"Anchor boxesを生成\"\"\"\n",
    "    anchors = []\n",
    "    for scale in scales:\n",
    "        for ar in aspect_ratios:\n",
    "            # w = scale * sqrt(ar), h = scale / sqrt(ar)\n",
    "            w = scale * math.sqrt(ar)\n",
    "            h = scale / math.sqrt(ar)\n",
    "            anchors.append([w, h])\n",
    "    return anchors\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Non-Maximum Suppression (NMS)\n",
    "\n",
    "### NMSの必要性\n",
    "\n",
    "- 同じ物体に対する重複した検出を削除\n",
    "- より良い予測を選択する\n",
    "\n",
    "### NMSのアルゴリズム\n",
    "```\n",
    "1. すべての検出を信頼度でソート\n",
    "2. 一番信頼度の高い検出を選択\n",
    "3. その検出とIoUが閾値以上の検出をすべて削除\n",
    "4. 2-3を繰り返し\n",
    "```\n",
    "\n",
    "### Soft NMS（改良版NMS）\n",
    "```\n",
    "score' = score × (1 - IoU)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 画像処理のための数学的基礎\n",
    "\n",
    "### IoUの計算\n",
    "\n",
    "IoU（Intersection over Union）は二つの矩形領域の重なり度合いを測る指標です。\n",
    "\n",
    "```\n",
    "IoU = area(A ∩ B) / area(A ∪ B)\n",
    "```\n",
    "\n",
    "### 矩形の交差面積の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"IoUを計算\n",
    "    \n",
    "    Args:\n",
    "        box1: [x1, y1, x2, y2]\n",
    "        box2: [x1, y1, x2, y2]\n",
    "    \n",
    "    Returns:\n",
    "        IoU値\n",
    "    \"\"\"\n",
    "    # 交差領域の座標を計算\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    \n",
    "    # 交差面積を計算\n",
    "    width_inter = max(0, x2_inter - x1_inter)\n",
    "    height_inter = max(0, y2_inter - y1_inter)\n",
    "    area_inter = width_inter * height_inter\n",
    "    \n",
    "    # 各矩形の面積を計算\n",
    "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    # 結合面積を計算\n",
    "    area_union = area1 + area2 - area_inter\n",
    "    \n",
    "    # IoUを計算\n",
    "    iou = area_inter / area_union if area_union > 0 else 0\n",
    "    \n",
    "    return iou\n",
    "\n",
    "# テスト\n",
    "box1 = [10, 10, 50, 50]  # 50x50の正方形\n",
    "box2 = [20, 20, 60, 60]  # 重なる部分がある\n",
    "box3 = [60, 60, 100, 100]  # 重なっていない\n",
    "\n",
    "print(f\"Box1: {box1}\")\n",
    "print(f\"Box2: {box2}\")\n",
    "print(f\"Box3: {box3}\")\n",
    "print(f\"\\nIoU(Box1, Box2) = {calculate_iou(box1, box2):.4f}\")\n",
    "print(f\"IoU(Box1, Box3) = {calculate_iou(box1, box3):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Tensor演算\n",
    "\n",
    "物体検出ではテンソル（多次元配列）の演算が頻繁に行われます。\n",
    "\n",
    "### ベクトルの内積と行列の乗算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def vector_add(v1, v2):\n",
    "    \"\"\"ベクトルの加法\"\"\"\n",
    "    return [v1[i] + v2[i] for i in range(len(v1))]\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    \"\"\"ベクトルの内積\"\"\"\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"行列の積\"\"\"\n",
    "    rows_A, cols_A = len(A), len(A[0])\n",
    "    rows_B, cols_B = len(B), len(B[0])\n",
    "    \n",
    "    if cols_A != rows_B:\n",
    "        raise ValueError(\"行列のサイズが整合しません\")\n",
    "    \n",
    "    C = [[0 for _ in range(cols_B)] for _ in range(rows_A)]\n",
    "    for i in range(rows_A):\n",
    "        for j in range(cols_B):\n",
    "            C[i][j] = sum(A[i][k] * B[k][j] for k in range(cols_A))\n",
    "    return C\n",
    "\n",
    "# テスト\n",
    "v1 = [1, 2, 3]\n",
    "v2 = [4, 5, 6]\n",
    "print(f\"ベクトル v1 = {v1}\")\n",
    "print(f\"ベクトル v2 = {v2}\")\n",
    "print(f\"v1 + v2 = {vector_add(v1, v2)}\")\n",
    "print(f\"v1 · v2 = {dot_product(v1, v2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 実践セクション（2時間）\n",
    "\n",
    "それでは、学んだ理論を実際に実装してみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 環境準備\n",
    "\n",
    "必要なライブラリをインポートします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリのインポート\n",
    "import math\n",
    "import random\n",
    "import numpy as np  # 教育用のnumpyの一部機能を模倣\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# 乱数シードの固定\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 日本語フォントの設定\n",
    "plt.rcParams['font.family'] = 'IPAexGothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exercise 1: Simple Bounding Box Detector\n",
    "\n",
    "まず、シンプルなバウンディングボックス検出器を実装してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDetector:\n",
    "    \"\"\"シンプルな物体検出器\"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size=7, num_classes=10):\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "        self.boxes_per_cell = 2\n",
    "        \n",
    "        # Anchor boxes（簡略化版）\n",
    "        self.anchors = [\n",
    "            [0.1, 0.1],  # 小物体\n",
    "            [0.3, 0.3]   # 大物体\n",
    "        ]\n",
    "    \n",
    "    def detect(self, image_features):\n",
    "        \"\"\"物体を検出\n",
    "        \n",
    "        Args:\n",
    "            image_features: 画像の特徴マップ\n",
    "            \n",
    "        Returns:\n",
    "            検出結果のリスト [x, y, w, h, confidence, class_id]\n",
    "        \"\"\"\n",
    "        detections = []\n",
    "        \n",
    "        # 各グリッドセルを処理\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                # 特徴量に基づいて信頼度を計算（簡略化）\n",
    "                confidence = min(1.0, abs(image_features[i, j]) / 0.5)\n",
    "                \n",
    "                if confidence > 0.3:  # 閾値処理\n",
    "                    # 各anchor boxに対して予測\n",
    "                    for anchor_idx, anchor in enumerate(self.anchors):\n",
    "                        # 予測された位置とサイズ\n",
    "                        cell_x = j + 0.5\n",
    "                        cell_y = i + 0.5\n",
    "                        \n",
    "                        # 予測ボックスを計算\n",
    "                        box = [\n",
    "                            cell_x / self.grid_size,  # x（正規化）\n",
    "                            cell_y / self.grid_size,  # y（正規化）\n",
    "                            anchor[0],                # w\n",
    "                            anchor[1],                # h\n",
    "                            confidence,\n",
    "                            0  # クラスID（簡略化）\n",
    "                        ]\n",
    "                        detections.append(box)\n",
    "        \n",
    "        return detections\n",
    "\n",
    "# テスト用の特徴マップを生成\n",
    "grid_size = 7\n",
    "feature_map = np.zeros((grid_size, grid_size))\n",
    "\n",
    " # 物体のある場所に特徴量を設定\n",
    "feature_map[2, 3] = 0.8  # 物体1\n",
    "feature_map[4, 5] = 0.9  # 物体2\n",
    "feature_map[1, 1] = 0.2  # ノイズ（検出されない）\n",
    "\n",
    "# 検出器の作成と実行\n",
    "detector = SimpleDetector(grid_size=7)\n",
    "detections = detector.detect(feature_map)\n",
    "\n",
    "print(f\"検出結果: {len(detections)}個の物体を検出\")\n",
    "for i, det in enumerate(detections):\n",
    "    print(f\"物体{i+1}: 位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f}), 信頼度={det[4]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Exercise 2: Anchor Box Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anchors(base_sizes, aspect_ratios):\n",
    "    \"\"\"Anchor boxesを生成\n",
    "    \n",
    "    Args:\n",
    "        base_sizes: 基本サイズのリスト\n",
    "        aspect_ratios: アスペクト比のリスト\n",
    "    \n",
    "    Returns:\n",
    "        Anchor boxesのリスト [w, h]\n",
    "    \"\"\"\n",
    "    anchors = []\n",
    "    for size in base_sizes:\n",
    "        for ar in aspect_ratios:\n",
    "            # w = size * sqrt(ar), h = size / sqrt(ar)\n",
    "            w = size * math.sqrt(ar)\n",
    "            h = size / math.sqrt(ar)\n",
    "            anchors.append([w, h])\n",
    "    return anchors\n",
    "\n",
    "# YOLO v3風のAnchor boxes\n",
    "scales = [10, 16, 33]  # スケール\n",
    "aspect_ratios = [0.5, 1.0, 2.0]  # アスペクト比\n",
    "\n",
    "anchors = generate_anchors(scales, aspect_ratios)\n",
    "\n",
    "print(f\"生成されたAnchor boxes ({len(anchors)}個):\")\n",
    "for i, anchor in enumerate(anchors):\n",
    "    print(f\"Anchor {i+1}: w={anchor[0]:.2f}, h={anchor[1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Exercise 3: NMSの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(boxes, scores, iou_threshold=0.5):\n",
    "    \"\"\"Non-Maximum Suppressionを実装\n",
    "    \n",
    "    Args:\n",
    "        boxes: バウンディングボックスのリスト [x, y, w, h]\n",
    "        scores: 各ボックスのスコア\n",
    "        iou_threshold: IoUの閾値\n",
    "    \n",
    "    Returns:\n",
    "        フィルタリングされたボックスのインデックスリスト\n",
    "    \"\"\"\n",
    "    # スコアでソート\n",
    "    indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)\n",
    "    \n",
    "    selected_indices = []\n",
    "    \n",
    "    while indices:\n",
    "        # 最もスコアの高いボックスを選択\n",
    "        current_index = indices[0]\n",
    "        selected_indices.append(current_index)\n",
    "        \n",
    "        # 残りのボックスからIoUが高いものを削除\n",
    "        remaining_indices = []\n",
    "        for idx in indices[1:]:\n",
    "            # 矩形を[cx, cy, w, h]から[x_min, y_min, x_max, y_max]に変換\n",
    "            box1 = boxes[current_index]\n",
    "            box1 = [box1[0] - box1[2]/2, box1[1] - box1[3]/2, \n",
    "                    box1[0] + box1[2]/2, box1[1] + box1[3]/2]\n",
    "            \n",
    "            box2 = boxes[idx]\n",
    "            box2 = [box2[0] - box2[2]/2, box2[1] - box2[3]/2,\n",
    "                    box2[0] + box2[2]/2, box2[1] + box2[3]/2]\n",
    "            \n",
    "            # IoUを計算\n",
    "            iou = calculate_iou(box1, box2)\n",
    "            \n",
    "            if iou <= iou_threshold:\n",
    "                remaining_indices.append(idx)\n",
    "        \n",
    "        indices = remaining_indices\n",
    "    \n",
    "    return selected_indices\n",
    "\n",
    "# テストデータ\n",
    "boxes = [\n",
    "    [0.5, 0.5, 0.2, 0.2],  # 中心(0.5, 0.5), 幅0.2, 高さ0.2\n",
    "    [0.5, 0.5, 0.25, 0.25],  # 重なるボックス\n",
    "    [0.8, 0.8, 0.1, 0.1],  # 別の物体\n",
    "    [0.7, 0.7, 0.15, 0.15]   # 重なるボックス\n",
    "]\n",
    "scores = [0.9, 0.85, 0.8, 0.75]\n",
    "\n",
    "print(\"NMS前:\")\n",
    "for i, (box, score) in enumerate(zip(boxes, scores)):\n",
    "    print(f\"ボックス{i+1}: 位置({box[0]:.2f}, {box[1]:.2f}), サイズ({box[2]:.2f}×{box[3]:.2f}), スコア={score:.2f}\")\n",
    "\n",
    "# NMSの実行\n",
    "selected_indices = non_max_suppression(boxes, scores, iou_threshold=0.4)\n",
    "\n",
    "print(\"\\nNMS後:\")\n",
    "for idx in selected_indices:\n",
    "    print(f\"選択されたボックス{idx+1}: スコア={scores[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Exercise 4: YOLO Detectorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLODetector:\n",
    "    \"\"\"YOLO風の物体検出器\"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size=7, num_classes=20, num_anchors=2):\n",
    "        self.grid_size = grid_size\n",
    "        self.num_classes = num_classes\n",
    "        self.num_anchors = num_anchors\n",
    "        \n",
    "        # Anchor boxesを定義\n",
    "        self.anchors = [\n",
    "            [0.1, 0.1],  # 小物体用\n",
    "            [0.3, 0.3]   # 大物体用\n",
    "        ]\n",
    "    \n",
    "    def forward(self, feature_maps):\n",
    "        \"\"\"Forward pass\n",
    "        \n",
    "        Args:\n",
    "            feature_maps: 特徴マップ [grid_size, grid_size, anchors * (5 + num_classes)]\n",
    "        \n",
    "        Returns:\n",
    "            前処理済みの予測\n",
    "        \"\"\"\n",
    "        # シンプルな前処理\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                for anchor_idx in range(self.num_anchors):\n",
    "                    # 各anchor boxの予測を取得\n",
    "                    base_idx = anchor_idx * (5 + self.num_classes)\n",
    "                    \n",
    "                    # シミュレーションとしてランダムな値を生成\n",
    "                    # 実装ではネットワークの出力を使用\n",
    "                    confidence = random.uniform(0, 1)\n",
    "                    \n",
    "                    # 座標とサイズを計算\n",
    "                    cell_x = j + random.uniform(-0.5, 0.5)\n",
    "                    cell_y = i + random.uniform(-0.5, 0.5)\n",
    "                    \n",
    "                    # 予測ボックス\n",
    "                    box = [\n",
    "                        cell_x / self.grid_size,  # x\n",
    "                        cell_y / self.grid_size,  # y\n",
    "                        self.anchors[anchor_idx][0],  # w\n",
    "                        self.anchors[anchor_idx][1],  # h\n",
    "                        confidence,  # confidence\n",
    "                        0  # class_id（ランダム）\n",
    "                    ]\n",
    "                    \n",
    "                    # クラス確率を生成\n",
    "                    class_probs = [random.uniform(0, 1) for _ in range(self.num_classes)]\n",
    "                    \n",
    "                    predictions.append((box, class_probs))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "    def filter_detections(self, predictions, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "        \"\"\"予測をフィルタリング\n",
    "        \n",
    "        Args:\n",
    "            predictions: forwardの出力\n",
    "            confidence_threshold: 信頼度の閾値\n",
    "            iou_threshold: NMSのIoU閾値\n",
    "        \n",
    "        Returns:\n",
    "            フィルタリングされた検出結果\n",
    "        \"\"\"\n",
    "        # 信頼度でフィルタリング\n",
    "        filtered = []\n",
    "        for box, class_probs in predictions:\n",
    "            if box[4] > confidence_threshold:\n",
    "                # 最も可能性の高いクラスを選択\n",
    "                class_id = class_probs.index(max(class_probs))\n",
    "                box[5] = class_id\n",
    "                filtered.append(box)\n",
    "        \n",
    "        # NMSの適用\n",
    "        if len(filtered) > 0:\n",
    "            # データをNMS関数に適合させる\n",
    "            boxes = [box[:4] for box in filtered]\n",
    "            scores = [box[4] for box in filtered]\n",
    "            \n",
    "            selected_indices = non_max_suppression(boxes, scores, iou_threshold)\n",
    "            \n",
    "            final_detections = [filtered[i] for i in selected_indices]\n",
    "            return final_detections\n",
    "        \n",
    "        return []\n",
    "\n",
    "# YOLO検出器のテスト\n",
    "detector = YOLODetector(grid_size=7, num_classes=20)\n",
    "\n",
    "# シミュレーションの特徴マップ\n",
    "feature_maps = np.random.rand(7, 7, 2 * (5 + 20))\n",
    "\n",
    "# 予測の実行\n",
    "predictions = detector.forward(feature_maps)\n",
    "print(f\"初期予測数: {len(predictions)}\")\n",
    "\n",
    "# フィルタリングの実行\n",
    "detections = detector.filter_detections(predictions, confidence_threshold=0.7)\n",
    "print(f\"フィルタリング後の検出数: {len(detections)}\")\n",
    "\n",
    "print(\"\\n検出結果:\")\n",
    "for i, det in enumerate(detections):\n",
    "    print(f\"物体{i+1}: 位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f}),\")\n",
    "    print(f\"          信頼度={det[4]:.2f}, クラスID={det[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Exercise 5: SSD Detectorの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSDDetector:\n",
    "    \"\"\"SSD風の物体検出器\"\"\"\n",
    "    \n",
    "    def __init__(self, feature_sizes=[38, 19, 10, 5, 3, 1], num_classes=20):\n",
    "        self.feature_sizes = feature_sizes\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 各特徴サイズのAnchor boxesを生成\n",
    "        self.anchors_per_cell = 6\n",
    "        self.anchors = self._generate_anchors()\n",
    "    \n",
    "    def _generate_anchors(self):\n",
    "        \"\"\"マルチスケールのAnchor boxesを生成\"\"\"\n",
    "        all_anchors = []\n",
    "        \n",
    "        # 各特徴サイズに対して\n",
    "        for idx, size in enumerate(self.feature_sizes):\n",
    "            anchors_for_scale = []\n",
    "            \n",
    "            # セルあたりのAnchor boxes\n",
    "            for i in range(self.anchors_per_cell):\n",
    "                # スケールを特徴サイズに基づいて調整\n",
    "                scale = 0.1 * (2 ** (idx / 3))\n",
    "                aspect_ratio = [0.5, 1.0, 2.0][i % 3]\n",
    "                \n",
    "                w = scale * math.sqrt(aspect_ratio)\n",
    "                h = scale / math.sqrt(aspect_ratio)\n",
    "                \n",
    "                anchors_for_scale.append([w, h])\n",
    "            \n",
    "            all_anchors.append(anchors_for_scale)\n",
    "        \n",
    "        return all_anchors\n",
    "\n",
    "    def detect(self, feature_maps):\n",
    "        \"\"\"マルチスケールの物体検出\n",
    "        \n",
    "        Args:\n",
    "            feature_maps: 各特徴サイズのマップのリスト\n",
    "        \n",
    "        Returns:\n",
    "            すべての検出結果のリスト\n",
    "        \"\"\"\n",
    "        all_detections = []\n",
    "        \n",
    "        for scale_idx, feature_map in enumerate(feature_maps):\n",
    "            size = self.feature_sizes[scale_idx]\n",
    "            anchors = self.anchors[scale_idx]\n",
    "            \n",
    "            # 各特徴マップを処理\n",
    "            for i in range(size):\n",
    "                for j in range(size):\n",
    "                    for anchor_idx, anchor in enumerate(anchors):\n",
    "                        # シミュレーションとしてランダムな値を生成\n",
    "                        confidence = random.uniform(0, 1)\n",
    "                        \n",
    "                        # 位置変換をシミュレート\n",
    "                        dx = random.uniform(-1, 1) * 0.2\n",
    "                        dy = random.uniform(-1, 1) * 0.2\n",
    "                        dw = random.uniform(-1, 1) * 0.2\n",
    "                        dh = random.uniform(-1, 1) * 0.2\n",
    "                        \n",
    "                        # Anchor boxの中心とサイズ\n",
    "                        px = (j + 0.5) / size\n",
    "                        py = (i + 0.5) / size\n",
    "                        pw = anchor[0]\n",
    "                        ph = anchor[1]\n",
    "                        \n",
    "                        # 変換されたボックス\n",
    "                        cx = dx * pw + px\n",
    "                        cy = dy * ph + py\n",
    "                        w = pw * math.exp(dw)\n",
    "                        h = ph * math.exp(dh)\n",
    "                        \n",
    "                        # クラス確率\n",
    "                        class_probs = [random.uniform(0, 1) for _ in range(self.num_classes)]\n",
    "                        class_id = class_probs.index(max(class_probs))\n",
    "                        \n",
    "                        # 検出ボックス\n",
    "                        detection = [cx, cy, w, h, confidence, class_id]\n",
    "                        all_detections.append(detection)\n",
    "        \n",
    "        return all_detections\n",
    "\n",
    "# SSD検出器のテスト\n",
    "ssd_detector = SSDDetector()\n",
    "\n",
    "# シミュレーションの特徴マップを生成\n",
    "feature_maps = []\n",
    "for size in [38, 19, 10, 5, 3, 1]:\n",
    "    feature_maps.append(np.random.rand(size, size, 6 * (5 + 20)))\n",
    "\n",
    "# 検出の実行\n",
    "detections = ssd_detector.detect(feature_maps)\n",
    "print(f\"SSD検出結果: {len(detections)}個の物体を検出\")\n",
    "\n",
    "print(\"\\nサンプル検出結果（最初の5件）:\")\n",
    "for i, det in enumerate(detections[:5]):\n",
    "    print(f\"物体{i+1}: 位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f}),\")\n",
    "    print(f\"          信頼度={det[4]:.2f}, クラスID={det[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Exercise 6: 可視化関数の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(image_size, detections, title=\"検出結果\"):\n",
    "    \"\"\"検出結果を可視化\n",
    "    \n",
    "    Args:\n",
    "        image_size: 画像サイズ [width, height]\n",
    "        detections: 検出結果のリスト\n",
    "        title: グラフのタイトル\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # 背景を描画\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # ランダムな色の生成\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(detections)))\n",
    "    \n",
    "    # 各検出を描画\n",
    "    for i, det in enumerate(detections):\n",
    "        x, y, w, h = det[0], det[1], det[2], det[3]\n",
    "        confidence = det[4]\n",
    "        class_id = det[5]\n",
    "        \n",
    "        # 矩形の座標を計算\n",
    "        x_min = x - w/2\n",
    "        y_min = y - h/2\n",
    "        x_max = x + w/2\n",
    "        y_max = y + h/2\n",
    "        \n",
    "        # 矩形を描画\n",
    "        rect = Rectangle((x_min, y_min), w, h, \n",
    "                        fill=False, \n",
    "                        edgecolor=colors[i],\n",
    "                        linewidth=2,\n",
    "                        label=f\"Class {class_id}: {confidence:.2f}\")\n",
    "        plt.gca().add_patch(rect)\n",
    "        \n",
    "        # ラベルを描画\n",
    "        plt.text(x_min, y_min - 0.05, f\"C{class_id}\", \n",
    "                color=colors[i], fontsize=10, weight='bold')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('X (正規化座標)')\n",
    "    plt.ylabel('Y (正規化座標)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# YOLO検出結果の可視化\n",
    "print(\"YOLO検出結果の可視化:\")\n",
    "visualize_detections([1, 1], detections, \"YOLO検出結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Exercise 7: 検出性能の比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_ground_truth(num_objects=5):\n",
    "    \"\"\"Ground Truthをシミュレート\n",
    "    \n",
    "    Args:\n",
    "        num_objects: 物体の数\n",
    "    \n",
    "    Returns:\n",
    "        Ground Truthのリスト\n",
    "    \"\"\"\n",
    "    ground_truth = []\n",
    "    \n",
    "    for i in range(num_objects):\n",
    "        # ランダムな位置とサイズ\n",
    "        x = random.uniform(0.2, 0.8)\n",
    "        y = random.uniform(0.2, 0.8)\n",
    "        w = random.uniform(0.1, 0.3)\n",
    "        h = random.uniform(0.1, 0.3)\n",
    "        \n",
    "        # クラスID（0-4の5クラス）\n",
    "        class_id = i % 5\n",
    "        \n",
    "        ground_truth.append([x, y, w, h, 1.0, class_id])\n",
    "    \n",
    "    return ground_truth\n",
    "\n",
    "def calculate_precision_recall(detections, ground_truth, iou_threshold=0.5):\n",
    "    \"\"\"PrecisionとRecallを計算\n",
    "    \n",
    "    Args:\n",
    "        detections: 検出結果\n",
    "        ground_truth: 正解データ\n",
    "        iou_threshold: IoUの閾値\n",
    "    \n",
    "    Returns:\n",
    "        precision, recall\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    \n",
    "    # 各検出に対してGround Truthと比較\n",
    "    used_gt = [False] * len(ground_truth)\n",
    "    \n",
    "    for det in detections:\n",
    "        best_iou = 0\n",
    "        best_gt_idx = -1\n",
    "        \n",
    "        # Ground TruthとのIoUを計算\n",
    "        for i, gt in enumerate(ground_truth):\n",
    "            if not used_gt[i] and det[5] == gt[5]:  # 同じクラス\n",
    "                iou = calculate_iou(\n",
    "                    [det[0]-det[2]/2, det[1]-det[3]/2, det[0]+det[2]/2, det[1]+det[3]/2],\n",
    "                    [gt[0]-gt[2]/2, gt[1]-gt[3]/2, gt[0]+gt[2]/2, gt[1]+gt[3]/2]\n",
    "                )\n",
    "                \n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt_idx = i\n",
    "        \n",
    "        if best_iou > iou_threshold:\n",
    "            true_positives += 1\n",
    "            used_gt[best_gt_idx] = True\n",
    "        else:\n",
    "            false_positives += 1\n",
    "    \n",
    "    # Recallの計算\n",
    "    false_negatives = sum(1 for used in used_gt if not used)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "# Ground Truthを生成\n",
    "ground_truth = simulate_ground_truth(num_objects=5)\n",
    "print(f\"Ground Truth: {len(ground_truth)}個の物体\")\n",
    "\n",
    "# YOLOの性能を測定\n",
    "yolo_precision, yolo_recall = calculate_precision_recall(detections, ground_truth)\n",
    "\n",
    "print(f\"\\nYOLOの性能:\")\n",
    "print(f\"Precision: {yolo_precision:.3f}\")\n",
    "print(f\"Recall: {yolo_recall:.3f}\")\n",
    "print(f\"F1 Score: {2 * yolo_precision * yolo_recall / (yolo_precision + yolo_recall):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Exercise 8: データ拡張\n",
    "\n",
    "物体検出ではデータ拡張が重要です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "class DataAugmentation:\n",
    "    \"\"\"データ拡張クラス\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def flip_horizontal(image, bboxes):\n",
    "        \"\"\"水平反転\n",
    "        \n",
    "        Args:\n",
    "            image: 画像データ（ここではダミー）\n",
    "            bboxes: バウンディングボックス [x, y, w, h, confidence, class_id]\n",
    "        \n",
    "        Returns:\n",
    "            反転後のバウンディングボックス\n",
    "        \"\"\"\n",
    "        flipped = []\n",
    "        for bbox in bboxes:\n",
    "            x, y, w, h, conf, cls = bbox\n",
    "            # X座標を反転\n",
    "            flipped.append([1 - x, y, w, h, conf, cls])\n",
    "        return flipped\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_crop(image, bboxes, crop_ratio=0.8):\n",
    "        \"\"\"ランダムなクロップ\n",
    "        \n",
    "        Args:\n",
    "            image: 画像データ\n",
    "            bboxes: バウンディングボックス\n",
    "            crop_ratio: クロップする割合\n",
    "\n",
    "        Returns:\n",
    "            クロップ後のバウンディングボックス\n",
    "        \"\"\"\n",
    "        # クロップ領域を決定\n",
    "        crop_size = 1.0 * crop_ratio\n",
    "        crop_x = random.uniform(0, 1 - crop_size)\n",
    "        crop_y = random.uniform(0, 1 - crop_size)\n",
    "        \n",
    "        cropped = []\n",
    "        for bbox in bboxes:\n",
    "            x, y, w, h, conf, cls = bbox\n",
    "            \n",
    "            # クロップ領域内にあるかチェック\n",
    "            if (x - w/2 > crop_x and x + w/2 < crop_x + crop_size and\n",
    "                y - h/2 > crop_y and y + h/2 < crop_y + crop_size):\n",
    "                # クロップ領域内の相対座標に変換\n",
    "                new_x = (x - crop_x) / crop_size\n",
    "                new_y = (y - crop_y) / crop_size\n",
    "                # サイズも調整\n",
    "                new_w = w / crop_size\n",
    "                new_h = h / crop_size\n",
    "                \n",
    "                cropped.append([new_x, new_y, new_w, new_h, conf, cls])\n",
    "        \n",
    "        return cropped\n",
    "\n",
    "# データ拡張のテスト\n",
    "detections = [\n",
    "    [0.3, 0.5, 0.2, 0.3, 0.9, 0],\n",
    "    [0.7, 0.6, 0.15, 0.2, 0.8, 1],\n",
    "    [0.2, 0.3, 0.1, 0.1, 0.7, 2]\n",
    "]\n",
    "\n",
    "print(\"元の検出:\")\n",
    "for det in detections:\n",
    "    print(f\"位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f})\")\n",
    "\n",
    "# 水平反転\n",
    "flipped = DataAugmentation.flip_horizontal(None, detections)\n",
    "print(\"\\n水平反転後:\")\n",
    "for det in flipped:\n",
    "    print(f\"位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f})\")\n",
    "\n",
    "# ランダムクロップ\n",
    "cropped = DataAugmentation.random_crop(None, detections)\n",
    "print(f\"\\nランダムクロップ後（{len(cropped)}個の物体が残りました）:\")\n",
    "for det in cropped:\n",
    "    print(f\"位置({det[0]:.2f}, {det[1]:.2f}), サイズ({det[2]:.2f}×{det[3]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "## 2.10 Challenge: 物体検出システムの構築\n",
     "\n",
     "これまで学んだ要素を使って、完全な物体検出システムを構築しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
    "source": [
     "class ObjectDetectionSystem:\n",
     "    \"\"\"完全な物体検出システム\"\"\"\n",
     "    \n",
     "    def __init__(self, detector_type='yolo'):\n",
     "        self.detector_type = detector_type\n",
     "        \n",
     "        if detector_type == 'yolo':\n",
     "            self.detector = YOLODetector()\n",
     "        elif detector_type == 'ssd':\n",
     "            self.detector = SSDDetector()\n",
     "        \n",
     "        self.confidence_threshold = 0.5\n",
     "        self.iou_threshold = 0.5\n",
     "    \n",
     "    def detect(self, image_features, apply_augmentation=False):\n",
     "        \"\"\"物体検出を実行\n",
     "        \n",
     "        Args:\n",
     "            image_features: 画像の特徴マップ\n",
     "            apply_augmentation: データ拡張を適用するか\n",
     "        \n",
     "        Returns:\n",
     "            検出結果\n",
     "        \"\"\"\n",
     "        # 検出を実行\n",
     "        if self.detector_type == 'yolo':\n",
     "            predictions = self.detector.forward(image_features)\n",
     "            detections = self.detector.filter_detections(predictions)\n",
     "        else:  # SSD\n",
     "            detections = self.detector.detect(image_features)\n",
     "        \n",
     "        # データ拡張を適用\n",
     "        if apply_augmentation:\n",
     "            detections = DataAugmentation.flip_horizontal(None, detections)\n",
     "            \n",
     "        return detections\n",
     "    \n",
     "    def evaluate(self, test_images, ground_truths):\n",
     "        \"\"\"システムの性能を評価\n",
     "        \n",
     "        Args:\n",
     "            test_images: テスト画像のリスト\n",
     "            ground_truths: 各画像のGround Truth\n",
     "        \n",
     "        Returns:\n",
     "            評価結果\n",
     "        \"\"\"\n",
     "        total_precision = 0\n",
     "        total_recall = 0\n",
     "        total_f1 = 0\n",
     "        \n",
     "        for i, (image, gt) in enumerate(zip(test_images, ground_truths)):\n",
     "            # 検出を実行\n",
     "            detections = self.detect(image)\n",
     "            \n",
     "            # 性能を計算\n",
     "            precision, recall = calculate_precision_recall(detections, gt, self.iou_threshold)\n",
     "            f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
     "            \n",
     "            total_precision += precision\n",
     "            total_recall += recall\n",
     "            total_f1 += f1\n",
     "            \n",
     "            # 進捗表示\n",
     "            if (i + 1) % 10 == 0:\n",
     "                print(f\"処理中: {i+1}/{len(test_images)} images, 平均F1: {total_f1/(i+1):.3f}\")\n",
     "        \n",
     "        # 平均を計算\n",
     "        avg_precision = total_precision / len(test_images)\n",
     "        avg_recall = total_recall / len(test_images)\n",
     "        avg_f1 = total_f1 / len(test_images)\n",
     "        \n",
     "        return {\n",
     "            'precision': avg_precision,\n",
     "            'recall': avg_recall,\n",
     "            'f1': avg_f1\n",
     "        }\n",
     "    \n",
     "    def set_thresholds(self, confidence_threshold, iou_threshold):\n",
     "        \"\"\"閾値を設定\n",
     "        \n",
     "        Args:\n",
     "            confidence_threshold: 信頼度の閾値\n",
     "            iou_threshold: NMSのIoU閾値\n",
     "        \"\"\"\n",
     "        self.confidence_threshold = confidence_threshold\n",
     "        self.iou_threshold = iou_threshold\n",
     "        \n",
     "        if self.detector_type == 'yolo':\n",
     "            self.detector.confidence_threshold = confidence_threshold\n",
     "            self.detector.iou_threshold = iou_threshold\n",
     "\n",
     "# システムのテスト\n",
     "print(\"物体検出システムのテスト:\")\n",
     "\n",
     "# YOLOシステムの作成と評価\n",
     "yolo_system = ObjectDetectionSystem(detector_type='yolo')\n",
     "yolo_system.set_thresholds(0.6, 0.5)\n",
     "\n",
     "# シミュレーションデータを作成\n",
     "test_images = [np.random.rand(7, 7, 2 * (5 + 20)) for _ in range(20)]\n",
     "ground_truths = [simulate_ground_truth(num_objects=3) for _ in range(20)]\n",
     "\n",
     "# 評価実行（速度のためサブセットを使用）\n",
     "evaluation = yolo_system.evaluate(test_images[:5], ground_truths[:5])\n",
     "\n",
     "print(\"\\nYOLOシステムの評価結果:\")\n",
     "print(f\"平均Precision: {evaluation['precision']:.3f}\")\n",
     "print(f\"平均Recall: {evaluation['recall']:.3f}\")\n",
     "print(f\"平均F1 Score: {evaluation['f1']:.3f}\")\n",
     "\n",
     "# SSDシステムの比較\n",
     "print(\"\\nSSDシステムの比較:\")\n",
     "ssd_system = ObjectDetectionSystem(detector_type='ssd')\n",
     "ssd_system.set_thresholds(0.6, 0.5)\n",
     "\n",
     "# シミュレーションデータを調整\n",
     "ssd_test_images = []\n",
     "for size in [38, 19, 10, 5, 3, 1]:\n",
     "    ssd_test_images.append(np.random.rand(size, size, 6 * (5 + 20)))\n",
     "\n",
     "# SSDの評価\n",
     "ssd_detections = ssd_system.detect(ssd_test_images)\n",
     "print(f\"SSD検出数: {len(ssd_detections)}\")\n",
     "\n",
     "print(\"\\nシステム構築完了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
     "---\n",
     "\n",
     "# Self-Check (理解度確認)\n",
     "\n",
     "本日の学習内容を確認しましょう：\n",
     "\n",
     "## 基礎知識\n",
     "- [ ] 物体検出の概念（位置+クラス検出）を理解した\n",
     "- [ ] Two-stageとOne-stage検出器の違いを理解した\n",
     "- [ ] YOLOとSSDの基本原理を理解した\n",
     "\n",
     "## アルゴリズム\n",
     "- [ ] **Anchor boxesの概念と生成方法を理解した**\n",
     "- [ ] **NMSのアルゴリズムを理解・実装した**\n",
     "- [ ] **IoUの計算方法を理解した**\n",
     "\n",
     "## 実装力\n",
     "- [ ] Simple Detectorを実装した\n",
     "- [ ] YOLO Detectorを実装した\n",
     "- [ ] SSD Detectorを実装した\n",
     "- [ ] NMSを実装した\n",
     "- [ ] 検出結果を可視化した\n",
     "\n",
     "## 応用\n",
     "- [ ] データ拡張の概念を理解した\n",
     "- [ ] 評価指標（Precision, Recall, F1）を理解した\n",
     "- [ ] 完全な物体検出システムを構築した\n",
     "\n",
     "---\n",
     "\n",
     "**お疲れ様でした！** Day 27の学習はこれで終了です。\n",
     "\n",
     "次回（Day 28）からは3つの最終プロジェクトを進めます：\n",
     "1. 画像フィルタアプリケーション\n",
     "2. 画像分類アプリケーション\n",
     "3. 総合アプリケーション\n",
     "\n",
     "復習課題：\n",
     "1. このNotebookのコードをすべて実行し、結果を確認する\n",
     "2. IoUの計算を手動で行ってみる\n",
     "3. NMSを自分の言葉で説明できるように整理する\n",
     "4. YOLOとSSDの長所・短所を表にまとめる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}