{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 30: 最終プロジェクト（完成と展開）\n",
    "\n",
    "## Learning Objectives\n",
    "- モデルの最適化方法を学ぶ\n",
    "- ONNX形式への変換を実装する\n",
    "- Webアプリケーションの展開方法を理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モデルの最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# 必要なライブラリのインポート\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow_model_optimization.python import kernel_library as kl\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity_params\n",
    "from tensorflow_model_optimization.python.core import grappler \\\n",
    "  as tf_opt\n",
    "import tempfile\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### 1.1 量子化による最適化"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "def create_simple_model():\n",
    "    \"\"\"テスト用の簡単なモデルを作成\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def benchmark_model(model, test_data, model_name):\n",
    "    \"\"\"モデルのベンチマーク\"\"\"\n",
    "    start_time = time.time()\n",
    "    predictions = model.predict(test_data)\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # モデルサイズの取得\n",
    "    model_size = sum(np.prod(v.shape) for v in model.get_weights()) * 4 / 1024 / 1024  # MB\n",
    "    \n",
    "    # FLOPsの見積もり\n",
    "    flops = model.count_params() * 2  # 粗略な見積もり\n",
    "    \n",
    "    return {\n",
    "        'inference_time': inference_time,\n",
    "        'fps': len(test_data) / inference_time,\n",
    "        'model_size_mb': model_size,\n",
    "        'flops': flops\n",
    "    }\n",
    "\n",
    "# 量子化手法の比較\n",
    "def compare_quantization_methods():\n",
    "    # テストデータの作成\n",
    "    test_data = np.random.rand(10, 256, 256, 3).astype(np.float32)\n",
    "    \n",
    "    # オリジナルモデル\n",
    "    model_original = create_simple_model()\n",
    "    print(\"オリジナルモデルの作成完了\")\n",
    "    \n",
    "    # ダミーの訓練データで学習（実際のアプリケーションでは実際のデータを使用）\n",
    "    dummy_labels = np.random.randint(0, 10, (100,))\n",
    "    model_original.fit(np.random.rand(100, 256, 256, 3).astype(np.float32), \n",
    "                      dummy_labels, epochs=2, verbose=0)\n",
    "    \n",
    "    # ベンチマーク\n",
    "    print(\"\\nオリジナルモデルのベンチマーク:\")\n",
    "    original_metrics = benchmark_model(model_original, test_data, \"Original\")\n",
    "    print(f\"推論時間: {original_metrics['inference_time']:.3f}s\")\n",
    "    print(f\"FPS: {original_metrics['fps']:.1f}\")\n",
    "    print(f\"モデルサイズ: {original_metrics['model_size_mb']:.2f}MB\")\n",
    "    \n",
    "    # 1. ダイナミック量子化（Dynamic Quantization）\n",
    "    print(\"\\n--- ダイナミック量子化 ---\")\n",
    "    model_dynamic_quant = tfmot.quantization.keras.quantize_model(model_original)\n",
    "    model_dynamic_quant.compile(optimizer='adam',\n",
    "                              loss='sparse_categorical_crossentropy',\n",
    "                              metrics=['accuracy'])\n",
    "    \n",
    "    dynamic_metrics = benchmark_model(model_dynamic_quant, test_data, \"Dynamic\")\n",
    "    print(f\"推論時間: {dynamic_metrics['inference_time']:.3f}s\")\n",
    "    print(f\"FPS: {dynamic_metrics['fps']:.1f}\")\n",
    "    print(f\"モデルサイズ: {dynamic_metrics['model_size_mb']:.2f}MB\")\n",
    "    \n",
    "    # 2. 整数量子化（Integer Quantization）\n",
    "    print(\"\\n--- 整数量子化 ---\")\n",
    "    def representative_dataset():\n",
    "        for data in test_data:\n",
    "            yield [data]\n",
    "    \n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model_original)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.representative_dataset = representative_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    converter.inference_input_type = tf.uint8\n",
    "    converter.inference_output_type = tf.uint8\n",
    "    \n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    # TFLiteモデルのサイズ\n",
    "    quant_size = len(tflite_quant_model) / 1024 / 1024  # MB\n",
    "    print(f\"量子化後のモデルサイズ: {quant_size:.2f}MB\")\n",
    "    print(f\"サイズ削減率: {(1 - quant_size/original_metrics['model_size_mb'])*100:.1f}%\")\n",
    "    \n",
    "    # 3. プルーニング（Pruning）\n",
    "    print(\"\\n--- プルーニング ---\")\n",
    "    \n",
    "    def apply_pruning_to_conv(layer):\n",
    "        pruning_params = sparsity_params.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
    "        return kl.PruneLowMagnitude(layer, pruning_params=pruning_params)\n",
    "    \n",
    "    # プルーニングを適用したモデルの作成\n",
    "    model_pruned = models.Sequential()\n",
    "    model_pruned.add(apply_pruning_to_conv(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                                       input_shape=(256, 256, 3))))\n",
    "    model_pruned.add(layers.MaxPooling2D((2, 2)))\n",
    "    model_pruned.add(layers.Flatten())\n",
    "    model_pruned.add(apply_pruning_to_conv(layers.Dense(256, activation='relu')))\n",
    "    model_pruned.add(apply_pruning_to_conv(layers.Dense(10, activation='softmax')))\n",
    "    \n",
    "    model_pruned.compile(optimizer='adam',\n",
    "                        loss='sparse_categorical_crossentropy',\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    # プルーニング訓練（簡略化）\n",
    "    model_pruned.fit(np.random.rand(50, 256, 256, 3).astype(np.float32), \n",
    "                    dummy_labels[:50], epochs=1, verbose=0)\n",
    "    \n",
    "    pruned_metrics = benchmark_model(model_pruned, test_data, \"Pruned\")\n",
    "    print(f\"推論時間: {pruned_metrics['inference_time']:.3f}s\")\n",
    "    print(f\"FPS: {pruned_metrics['fps']:.1f}\")\n",
    "    print(f\"モデルサイズ: {pruned_metrics['model_size_mb']:.2f}MB\")\n",
    "    \n",
    "    # 結果の比較\n",
    "    methods = ['Original', 'Dynamic Quant', 'Integer Quant', 'Pruned']\n",
    "    times = [original_metrics['inference_time'], \n",
    "            dynamic_metrics['inference_time'], \n",
    "            original_metrics['inference_time'],  # TFLiteは直接比較できないのでオリジナルを使用\n",
    "            pruned_metrics['inference_time']]\n",
    "    sizes = [original_metrics['model_size_mb'], \n",
    "             dynamic_metrics['model_size_mb'], \n",
    "             quant_size, \n",
    "             pruned_metrics['model_size_mb']]\n",
    "    \n",
    "    # 可視化\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 推論時間の比較\n",
    "    ax1.bar(methods, times, color=['blue', 'green', 'orange', 'red'])\n",
    "    ax1.set_ylabel('Inference Time (s)')\n",
    "    ax1.set_title('Inference Time Comparison')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # モデルサイズの比較\n",
    "    ax2.bar(methods, sizes, color=['blue', 'green', 'orange', 'red'])\n",
    "    ax2.set_ylabel('Model Size (MB)')\n",
    "    ax2.set_title('Model Size Comparison')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'original': original_metrics,\n",
    "        'dynamic_quant': dynamic_metrics,\n",
    "        'integer_quant': {'model_size_mb': quant_size},\n",
    "        'pruned': pruned_metrics\n",
    "    }\n",
    "\n",
    "# 量子化手法の比較を実行\n",
    "optimization_results = compare_quantization_methods()"
   ]
  },
  {
   "cell_type": "markdown",
    "metadata": {},
    "source": [
    "### 1.2 ONNX形式への変換"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "def convert_to_onnx(model, input_shape=(1, 256, 256, 3)):\n",
    "    \"\"\"KerasモデルをONNXに変換\"\"\"\n",
    "    try:\n",
    "        # onnx-kerasのインストールが必要\n",
    "        import onnxmltools as onnx\n",
    "        \n",
    "        # モデルをONNX形式に変換\n",
    "        onnx_model = onnx.convert_keras(model)\n",
    "        \n",
    "        # 変換したモデルを保存\n",
    "        onnx.save(onnx_model, \"model.onnx\")\n",
    "        print(\"ONNXモデルの保存完了\")\n",
    "        \n",
    "        # モデル情報の表示\n",
    "        print(\"\\nONNXモデル情報:\")\n",
    "        print(f\"入力形状: {onnx_model.graph.input[0].type.tensor_type.shape}\")\n",
    "        print(f\"出力形状: {onnx_model.graph.output[0].type.tensor_type.shape}\")\n",
    "        print(f\"ノード数: {len(onnx_model.graph.node)}\")\n",
    "        \n",
    "        return onnx_model\n",
    "    except ImportError:\n",
    "        print(\"onnxmltoolsがインストールされていません。\")\n",
    "        print(\"pip install onnxmltools でインストールしてください。\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ONNX変換中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def verify_onnx_model(onnx_model, test_data):\n",
    "    \"\"\"ONNXモデルの検証\"\"\"\n",
    "    try:\n",
    "        # ONNX Runtimeで推論\n",
    "        ort_session = ort.InferenceSession(onnx_model.SerializeToString())\n",
    "        \n",
    "        # 入力名の取得\n",
    "        input_name = ort_session.get_inputs()[0].name\n",
    "        output_name = ort_session.get_outputs()[0].name\n",
    "        \n",
    "        # 推論実行\n",
    "        start_time = time.time()\n",
    "        ort_outputs = ort_session.run([output_name], {input_name: test_data.astype(np.float32)})\n",
    "        ort_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"\\nONNX Runtimeでの推論時間: {ort_time:.3f}s\")\n",
    "        print(f\"FPS: {len(test_data) / ort_time:.1f}\")\n",
    "        \n",
    "        # 出力形状の確認\n",
    "        print(f\"出力形状: {ort_outputs[0].shape}\")\n",
    "        \n",
    "        # モデル情報の詳細表示\n",
    "        print(\"\\nONNXモデルの詳細:\")\n",
    "        print(f\"プロバイダ: {ort_session.get_providers()}\")\n",
    "        print(f\"入力名: {input_name}\")\n",
    "        print(f\"出力名: {output_name}\")\n",
    "        \n",
    "        return ort_session\n",
    "    except Exception as e:\n",
    "        print(f\"ONNXモデルの検証中にエラーが発生しました: {e}\")\n",
    "        return None\n",
    "\n",
    "def onnx_optimization_tips():\n",
    "    \"\"\"ONNXモデルの最適化方法のヒント\"\"\"\n",
    "    tips = [\n",
    "        {\n",
    "            'name': '形状の固定',\n",
    "            'description': 'モデルの入力形状を固定することで、最適化が効果的になります。',\n",
    "            'code': 'model = ...  # モデル定義\\n\\n# ONNXに変換する前に入力形状を固定\\ninput_shape = (1, 256, 256, 3)\\ntest_input = np.random.rand(*input_shape).astype(np.float32)\\n\\n# モデルを固定形状で変換\\nmodel.compile(...)\\nmodel.predict(test_input)  # このとき形状が固定される'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Opsetバージョンの指定',\n",
    "            'description': '最新のOpsetバージョンを使用することで、最適化を利用できます。',\n",
    "            'code': 'onnx_model = onnx.convert_keras(model, \\\\n                    initializers=True,\\\n                    target_opset={\"ai.onnx\": 14})  # 適切なOpsetバージョンを指定'\n",
    "        },\n",
    "        {\n",
    "            'name': '最適化の適用',\n",
    "            'description': 'ONNX Optimizeを使用してモデルを最適化します。',\n",
    "            'code': 'from onnxruntime.tools.optimizer import optimize\\n\\noptimized_model = optimize(model)\\noptimized_model.save(\"optimized_model.onnx\")'\n",
    "        },\n",
    "        {\n",
    "            'name': '量化',\n",
    "            'description': 'ONNX Quantizeを使用してモデルを量子化します。',\n",
    "            'code': 'from onnxruntime.quantization import quantize_static\\n\\nquantize_static(model, \"quantized_model.onnx\", \"calibration_data\")'\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"=== ONNXモデル最適化のヒント ===\")\n",
    "    for i, tip in enumerate(tips, 1):\n",
    "        print(f\"\\n{i}. {tip['name']}\")\n",
    "        print(f\"   {tip['description']}\")\n",
    "        print(\"\\nコード例:\")\n",
    "        print(f\"```python\\n{tip['code']}\\n```\")\n",
    "    \n",
    "    print(\"\\n=== ONNX RuntimeでのGPU使用 ===\")\n",
    "    print(\"ONNX RuntimeはGPUをサポートしています。\")\n",
    "    print(\"GPUを使用するには、インストール時にCUDAを有効にしてください。\")\n",
    "    print(\"\\nインストール方法:\")\n",
    "    print(\"```bash\")\n",
    "    print(\"pip install onnxruntime-gpu\")\n",
    "    print(\"```\")\n",
    "    \n",
    "    print(\"\\nGPUセッションの作成:\")\n",
    "    print(\"```python\")\n",
    "    print(\"ort_session = ort.InferenceSession(\\\"model.onnx\\\", providers=[\\\"CUDAExecutionProvider\\\"])\\n\")\n",
    "    print(\"```\")\n",
    "\n",
    "# ONNX変換のテスト\n",
    "print(\"ONNX形式への変換を試行...\")\n",
    "# create_simple_modelでモデルを作成\n",
    "model = create_simple_model()\n",
    "test_data = np.random.rand(1, 256, 256, 3).astype(np.float32)\n",
    "\n",
    "# ダミーで予測を実行（実際の学習は不要）\n",
    "model.predict(test_data, verbose=0)\n",
    "\n",
    "# ONNXへの変換",
    "onnx_model = convert_to_onnx(model)\n",
    "\n",
    "if onnx_model is not None:\n",
    "    # ONNXモデルの検証\n",
    "    ort_session = verify_onnx_model(onnx_model, test_data)\n",
    "    # 最適化のヒントを表示\n",
    "    onnx_optimization_tips()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Webアプリケーション展開"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 FlaskベースのWebアプリケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_code = '''\n",
    "# app.py - Flask Webアプリケーション\n",
    "from flask import Flask, request, jsonify, render_template, send_file\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import os\n",
    "from PIL import Image\n",
    "import json\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import time\n",
    "\n",
    "# アプリケーションの初期化\n",
    "app = Flask(__name__, \n",
    "            static_folder='static',\n",
    "            template_folder='templates')\n",
    "\n",
    "# グローバル変数\n",
    "MODEL_LOADED = False\n",
    "model = None\n",
    "input_shape = (256, 256)\n",
    "\n",
    "# メインページ\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "# モデルのロード\n",
    "@app.route('/api/load_model', methods=['POST'])\n",
    "def load_model():\n",
    "    global model, MODEL_LOADED\n",
    "    \n",
    "    try:\n",
    "        # ここで実際のモデルロード処理を実装\n",
    "        # 例: model = load_model('model.h5')\n",
    "        \n",
    "        MODEL_LOADED = True\n",
    "        return jsonify({'status': 'success', 'message': 'モデルが正常にロードされました'})\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# 画像処理エンドポイント\n",
    "@app.route('/api/process', methods=['POST'])\n",
    "def process_image():\n",
    "    if not MODEL_LOADED:\n",
    "        return jsonify({'status': 'error', 'message': 'モデルがロードされていません'}), 400\n",
    "    \n",
    "    try:\n",
    "        # リクエストから画像を取得\n",
    "        if 'image' not in request.files:\n",
    "            return jsonify({'status': 'error', 'message': '画像が送信されていません'}), 400\n",
    "        \n",
    "        file = request.files['image']\n",
    "        if file.filename == '':\n",
    "            return jsonify({'status': 'error', 'message': '画像が選択されていません'}), 400\n",
    "        \n",
    "        # 画像の読み込みと前処理\n",
    "        image = Image.open(file.stream)\n",
    "        image = image.convert('RGB')\n",
    "        \n",
    "        # 元画像の保存\n",
    "        original_image = np.array(image)\n",
    "        \n",
    "        # 画像のリサイズ\n",
    "        resized = image.resize(input_shape)\n",
    "        processed_image = np.array(resized) / 255.0\n",
    "        \n",
    "        # ここで実際のモデル推論を実装\n",
    "        # 例: prediction = model.predict(np.expand_dims(processed_image, axis=0))\n",
    "        \n",
    "        # ダミー処理（実際はモデルの予測結果）\n",
    "        start_time = time.time()\n",
    "        # 擬似的な処理遅延\n",
    "        time.sleep(0.1)\n",
    "        \n",
    "        # ダミー結果の生成\n",
    "        detection_results = []\n",
    "        num_detections = np.random.randint(1, 5)\n",
    "        \n",
    "        for i in range(num_detections):\n",
    "            x = np.random.randint(0, input_shape[0] - 50)\n",
    "            y = np.random.randint(0, input_shape[1] - 50)\n",
    "            w = np.random.randint(30, 100)\n",
    "            h = np.random.randint(30, 100)\n",
    "            confidence = np.random.uniform(0.7, 0.95)\n",
    "            class_id = np.random.randint(0, 10)\n",
    "            \n",
    "            detection_results.append({\n",
    "                'box': [x, y, w, h],\n",
    "                'confidence': confidence,\n",
    "                'class': f'object_{class_id}'\n",
    "            })\n",
    "        \n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # 結果画像の作成\n",
    "        result_image = original_image.copy()\n",
    "        \n",
    "        # バウンディングボックスの描画\n",
    "        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), \n",
    "                  (255, 255, 0), (255, 0, 255)]\n",
    "        \n",
    "        for det in detection_results:\n",
    "            x, y, w, h = det['box']\n",
    "            color = colors[len(detection_results) % len(colors)]\n",
    "            \n",
    "            # バウンディングボックス\n",
    "            cv2.rectangle(result_image, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "            # ラベル\n",
    "            label = f\"{det['class']}: {det['confidence']:.2f}\"\n",
    "            cv2.putText(result_image, label, (x, y - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        # 結果画像をバイトに変換\n",
    "        result_pil = Image.fromarray(result_image)\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        result_pil.save(img_byte_arr, format='JPEG')\n",
    "        img_byte_arr.seek(0)\n",
    "        \n",
    "        # レスポンスの作成\n",
    "        response = {\n",
    "            'status': 'success',\n",
    "            'processing_time': processing_time,\n",
    "            'detections': detection_results,\n",
    "            'image_base64': base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')\n",
    "        }\n",
    "        \n",
    "        return jsonify(response)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# バッチ処理エンドポイント\n",
    "@app.route('/api/batch_process', methods=['POST'])\n",
    "def batch_process():\n",
    "    if not MODEL_LOADED:\n",
    "        return jsonify({'status': 'error', 'message': 'モデルがロードされていません'}), 400\n",
    "    \n",
    "    try:\n",
    "        # ファイルの取得\n",
    "        files = request.files.getlist('images')\n",
    "        if not files:\n",
    "            return jsonify({'status': 'error', 'message': '画像が送信されていません'}), 400\n",
    "        \n",
    "        results = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for file in files:\n",
    "            # 各画像の処理\n",
    "            image = Image.open(file.stream)\n",
    "            image = image.convert('RGB')\n",
    "            \n",
    "            # ダミー処理\n",
    "            result = {\n",
    "                'filename': file.filename,\n",
    "                'detections': [{'class': 'sample', 'confidence': 0.85}],\n",
    "                'processing_time': np.random.uniform(0.05, 0.15)\n",
    "            }\n",
    "            \n",
    "            results.append(result)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'total_time': total_time,\n",
    "            'results': results\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# モデル情報の取得\n",
    "@app.route('/api/model_info', methods=['GET'])\n",
    "def model_info():\n",
    "    info = {\n",
    "        'loaded': MODEL_LOADED,\n",
    "        'input_shape': input_shape,\n",
    "        'version': '1.0.0'\n",
    "    }\n",
    "    return jsonify(info)\n",
    "\n",
    "# エラーハンドリング\n",
    "@app.errorhandler(404)\n",
    "def not_found(error):\n",
    "    return jsonify({'status': 'error', 'message': 'エンドポイントが見つかりません'}), 404\n",
    "\n",
    "@app.errorhandler(500)\n",
    "def internal_error(error):\n",
    "    return jsonify({'status': 'error', 'message': '内部サーバーエラー'}), 500\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=5000)\n",
    "'''\n",
    "\n",
    "# テンプレートファイルの作成\n",
    "template_code = '''\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"ja\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>物体検出Webアプリ</title>\n",
    "    <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css\" rel=\"stylesheet\">\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #f8f9fa;\n",
    "        }\n",
    "        .card {\n",
    "            margin-top: 20px;\n",
    "            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .preview-container {\n",
    "            position: relative;\n",
    "            max-width: 100%;\n",
    "            margin: 20px 0;\n",
    "        }\n",
    "        .preview-image {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            border: 2px solid #dee2e6;\n",
    "            border-radius: 4px;\n",
    "        }\n",
    "        .loading {\n",
    "            display: none;\n",
    "            position: absolute;\n",
    "            top: 0;\n",
    "            left: 0;\n",
    "            right: 0;\n",
    "            bottom: 0;\n",
    "            background: rgba(255, 255, 255, 0.8);\n",
    "            justify-content: center;\n",
    "            align-items: center;\n",
    "        }\n",
    "        .detection-item {\n",
    "            padding: 10px;\n",
    "            margin: 5px 0;\n",
    "            background: #e9ecef;\n",
    "            border-radius: 4px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"container mt-4\">\n",
    "        <div class=\"row\">\n",
    "            <div class=\"col-md-12\">\n",
    "                <div class=\"card\">\n",
    "                    <div class=\"card-header bg-primary text-white\">\n",
    "                        <h1 class=\"mb-0\">物体検出Webアプリ</h1>\n",
    "                    </div>\n",
    "                    <div class=\"card-body\">\n",
    "                        <!-- モデルロードボタン -->\n",
    "                        <div class=\"mb-3\">\n",
    "                            <button id=\"loadModelBtn\" class=\"btn btn-success\">モデルをロード</button>\n",
    "                            <span id=\"modelStatus\" class=\"ms-2\"></span>\n",
    "                        </div>\n",
    "                        \n",
    "                        <!-- 画像アップロード -->\n",
    "                        <div class=\"mb-3\">\n",
    "                            <h5>画像アップロード</h5>\n",
    "                            <input type=\"file\" id=\"imageInput\" accept=\"image/*\" class=\"form-control\">\n",
    "                        </div>\n",
    "                        \n",
    "                        <!-- 処理ボタン -->\n",
    "                        <div class=\"mb-3\">\n",
    "                            <button id=\"processBtn\" class=\"btn btn-primary\" disabled>画像を処理</button>\n",
    "                        </div>\n",
    "                        \n",
    "                        <!-- プレビュー領域 -->\n",
    "                        <div class=\"row\">\n",
    "                            <div class=\"col-md-6\">\n",
    "                                <h5>元の画像</h5>\n",
    "                                <div class=\"preview-container\">\n",
    "                                    <img id=\"originalImage\" class=\"preview-image\" style=\"display: none;\">\n",
    "                                    <div id=\"loadingOriginal\" class=\"loading\">\n",
    "                                        <div class=\"spinner-border text-primary\" role=\"status\">\n",
    "                                            <span class=\"visually-hidden\">Loading...</span>\n",
    "                                        </div>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                            <div class=\"col-md-6\">\n",
    "                                <h5>検出結果</h5>\n",
    "                                <div class=\"preview-container\">\n",
    "                                    <img id=\"resultImage\" class=\"preview-image\" style=\"display: none;\">\n",
    "                                    <div id=\"loadingResult\" class=\"loading\">\n",
    "                                        <div class=\"spinner-border text-success\" role=\"status\">\n",
    "                                            <span class=\"visually-hidden\">Processing...</span>\n",
    "                                        </div>\n",
    "                                    </div>\n",
    "                                </div>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                        \n",
    "                        <!-- 結果表示 -->\n",
    "                        <div id=\"resultsSection\" class=\"mt-4\" style=\"display: none;\">\n",
    "                            <h5>検出結果</h5>\n",
    "                            <div id=\"detectionResults\"></div>\n",
    "                            <div class=\"mt-3\">\n",
    "                                <small class=\"text-muted\">処理時間: <span id=\"processingTime\">0</span> ms</small>\n",
    "                            </div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    </div>\n",
    "    \n",
    "    <script src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js\"></script>\n",
    "    <script>\n",
    "        // DOM要素\n",
    "        const loadImageBtn = document.getElementById('loadModelBtn');\n",
    "        const modelStatus = document.getElementById('modelStatus');\n",
    "        const imageInput = document.getElementById('imageInput');\n",
    "        const processBtn = document.getElementById('processBtn');\n",
    "        const originalImage = document.getElementById('originalImage');\n",
    "        const resultImage = document.getElementById('resultImage');\n",
    "        const resultsSection = document.getElementById('resultsSection');\n",
    "        const detectionResults = document.getElementById('detectionResults');\n",
    "        const processingTime = document.getElementById('processingTime');\n",
    "        \n",
    "        let modelLoaded = false;\n",
    "        \n",
    "        // モデルロード\n",
    "        loadImageBtn.addEventListener('click', async () => {\n",
    "            loadImageBtn.disabled = true;\n",
    "            loadImageBtn.innerHTML = '<span class=\"spinner-border spinner-border-sm\" role=\"status\" aria-hidden=\"true\"></span> Loading...';\n",
    "            \n",
    "            try {\n",
    "                const response = await fetch('/api/load_model', { method: 'POST' });\n",
    "                const data = await response.json();\n",
    "                \n",
    "                if (data.status === 'success') {\n",
    "                    modelLoaded = true;\n",
    "                    modelStatus.textContent = 'モデルがロードされました';\n",
    "                    modelStatus.className = 'ms-2 text-success';\n",
    "                    processBtn.disabled = false;\n",
    "                } else {\n",
    "                    throw new Error(data.message);\n",
    "                }\n",
    "            } catch (error) {\n",
    "                modelStatus.textContent = 'エラー: ' + error.message;\n",
    "                modelStatus.className = 'ms-2 text-danger';\n",
    "            } finally {\n",
    "                loadImageBtn.disabled = false;\n",
    "                loadImageBtn.innerHTML = 'モデルをロード';\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // 画像プレビュー\n",
    "        imageInput.addEventListener('change', (e) => {\n",
    "            const file = e.target.files[0];\n",
    "            if (file) {\n",
    "                const reader = new FileReader();\n",
    "                reader.onload = (e) => {\n",
    "                    originalImage.src = e.target.result;\n",
    "                    originalImage.style.display = 'block';\n",
    "                    processBtn.disabled = !modelLoaded;\n",
    "                };\n",
    "                reader.readAsDataURL(file);\n",
    "            }\n",
    "        });\n",
    "        \n",
    "        // 画像処理\n",
    "        processBtn.addEventListener('click', async () => {\n",
    "            if (!modelLoaded || !imageInput.files[0]) {\n",
    "                return;\n",
    "            }\n",
    "            \n",
    "            processBtn.disabled = true;\n",
    "            processBtn.innerHTML = '<span class=\"spinner-border spinner-border-sm\" role=\"status\" aria-hidden=\"true\"></span> Processing...';\n",
    "            \n",
    "            // ローディング表示\n",
    "            document.getElementById('loadingOriginal').style.display = 'flex';\n",
    "            document.getElementById('loadingResult').style.display = 'flex';\n",
    "            \n",
    "            const formData = new FormData();\n",
    "            formData.append('image', imageInput.files[0]);\n",
    "            \n",
    "            try {\n",
    "                const startTime = performance.now();\n",
    "                const response = await fetch('/api/process', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                });\n",
    "                const data = await response.json();\n",
    "                const endTime = performance.now();\n",
    "                \n",
    "                if (data.status === 'success') {\n",
    "                    // 結果画像の表示\n",
    "                    resultImage.src = 'data:image/jpeg;base64,' + data.image_base64;\n",
    "                    resultImage.style.display = 'block';\n",
    "                    \n",
    "                    // 検出結果の表示\n",
    "                    detectionResults.innerHTML = '';\n",
    "                    data.detections.forEach(det => {\n",
    "                        const item = document.createElement('div');\n",
    "                        item.className = 'detection-item';\n",
    "                        item.innerHTML = `\n",
    "                            <strong>${det.class}</strong><br>\n",
    "                            確信度: ${(det.confidence * 100).toFixed(1)}%<br>\n",
    "                            位置: [${det.box[0]}, ${det.box[1]}] サイズ: ${det.box[2]}x${det.box[3]}\n",
    "                        `;\n",
    "                        detectionResults.appendChild(item);\n",
    "                    });\n",
    "                    \n",
    "                    // 結果セクションの表示\n",
    "                    resultsSection.style.display = 'block';\n",
    "                    processingTime.textContent = data.processing_time.toFixed(2);\n",
    "                    \n",
    "                } else {\n",
    "                    throw new Error(data.message);\n",
    "                }\n",
    "            } catch (error) {\n",
    "                alert('処理中にエラーが発生しました: ' + error.message);\n",
    "            } finally {\n",
    "                // ローディング非表示\n",
    "                document.getElementById('loadingOriginal').style.display = 'none';\n",
    "                document.getElementById('loadingResult').style.display = 'none';\n",
    "                \n",
    "                processBtn.disabled = false;\n",
    "                processBtn.innerHTML = '画像を処理';\n",
    "            }\n",
    "        });\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "# ディレクトリ構造の作成\n",
    "def create_web_app_structure():\n",
    "    \"\"\"Webアプリのディレクトリ構造を作成\"\"\"\n",
    "    dirs = ['app', 'app/static', 'app/templates', 'app/uploads', 'app/results']\n",
    "    \n",
    "    for dir_name in dirs:\n",
    "        os.makedirs(dir_name, exist_ok=True)\n",
    "    \n",
    "    # アプリケーションファイルの作成\n",
    "    with open('app/app.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(app_code)\n",
    "    \n",
    "    # テンプレートファイルの作成\n",
    "    with open('app/templates/index.html', 'w', encoding='utf-8') as f:\n",
    "        f.write(template_code)\n",
    "    \n",
    "    # requirements.txtの作成\n",
    "    requirements = '''\n",
    "flask==2.0.1\n",
    "numpy==1.21.0\n",
    "Pillow==8.3.1\n",
    "opencv-python==4.5.3.56\n",
    "'''\n",
    "    \n",
    "    with open('app/requirements.txt', 'w') as f:\n",
    "        f.write(requirements)\n",
    "    \n",
    "    # READMEの作成\n",
    "    readme = '''\n",
    "# 物体検出Webアプリ\n",
    "\n",
    "Flaskベースの物体検出Webアプリケーションです。\n",
    "\n",
    "## 機能\n",
    "- 画像のアップロード\n",
    "- 物体検出\n",
    "- 結果の可視化\n",
    "- バッチ処理サポート\n",
    "\n",
    "## 実行方法\n",
    "\n",
    "### 1. 依存関係のインストール\n",
    "```bash\n",
    "cd app\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### 2. アプリケーションの実行\n",
    "```bash\n",
    "python app.py\n",
    "```\n",
    "\n",
    "### 3. アクセス\n",
    "ブラウザで http://localhost:5000 にアクセス\n",
    "\n",
    "## ディレクトリ構造\n",
    "```\n",
    "app/\n",
    "├── app.py              # メインアプリケーション\n",
    "├── requirements.txt     # 依存関係\n",
    "├── static/             # 静的ファイル\n",
    "├── templates/          # HTMLテンプレート\n",
    "│   └── index.html\n",
    "├── uploads/            # アップロードされたファイル\n",
    "└── results/            # 処理結果\n",
    "```\n",
    "'''\n",
    "    \n",
    "    with open('app/README.md', 'w', encoding='utf-8') as f:\n",
    "        f.write(readme)\n",
    "    \n",
    "    print(\"Webアプリケーションの構造を作成しました\")\n",
    "    print(\"場所: app/ ディレクトリ\")\n",
    "    print(\"\\n実行手順:\")\n",
    "    print(\"1. cd app\")\n",
    "    print(\"2. pip install -r requirements.txt\")\n",
    "    print(\"3. python app.py\")\n",
    "\n",
    "# Webアプリ構造の作成\n",
    "create_web_app_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Dockerコンテナ化"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# Dockerfileの作成\n",
    "dockerfile_content = '''\n",
    "# Dockerfile\n",
    "FROM python:3.9-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# 依存関係のインストール",
    "RUN apt-get update && apt-get install -y \n",
    "    libgl1-mesa-glx \\\\\n",
    "    libglib2.0-0 \\\\\n",
    "    libsm6 \\\\\n",
    "    libxext6 \\\\\n",
    "    libxrender-dev \\\\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "COPY . .\n",
    "\n",
    "# ポートの公開\n",
    "EXPOSE 5000\n",
    "\n",
    "# 環境変数の設定\n",
    "ENV FLASK_ENV=production\n",
    "\n",
    "# アプリケーションの実行\n",
    "CMD [\"python\", \"app.py\"]\n",
    "'''\n",
    "\n",
    "# docker-compose.ymlの作成\n",
    "compose_content = '''\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  webapp:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"5000:5000\"\n",
    "    volumes:\n",
    "      - ./app:/app\n",
    "      - ./data:/app/data\n",
    "      - ./models:/app/models\n",
    "    environment:\n",
    "      - FLASK_ENV=production\n",
    "    restart: unless-stopped\n",
    "\n",
    "  nginx:\n",
    "    image: nginx:alpine\n",
    "    ports:\n",
    "      - \"80:80\"\n",
    "    volumes:\n",
    "      - ./nginx.conf:/etc/nginx/nginx.conf\n",
    "      - ./app:/usr/share/nginx/html\n",
    "    depends_on:\n",
    "      - webapp\n",
    "    restart: unless-stopped\n",
    "'''\n",
    "\n",
    "# nginx.confの作成\n",
    "nginx_conf = '''\n",
    "events {\n",
    "    worker_connections 1024;\n",
    "}\n",
    "\n",
    "http {\n",
    "    upstream webapp {\n",
    "        server webapp:5000;\n",
    "    }\n",
    "\n",
    "    server {\n",
    "        listen 80;\n",
    "        server_name localhost;\n",
    "\n",
    "        location / {\n",
    "            proxy_pass http://webapp;\n",
    "            proxy_set_header Host $host;\n",
    "            proxy_set_header X-Real-IP $remote_addr;\n",
    "            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
    "            proxy_set_header X-Forwarded-Proto $scheme;\n",
    "        }\n",
    "\n",
    "        # 静的ファイルの直接提供\n",
    "        location /static/ {\n",
    "            alias /usr/share/nginx/html/static/;\n",
    "            expires 1y;\n",
    "            add_header Cache-Control \"public, immutable\";\n",
    "        }\n",
    "\n",
    "        # 動的コンテンツのキャッシュ設定\n",
    "        location ~* \\.(jpg|jpeg|png|gif|ico|css|js)$ {\n",
    "            proxy_pass http://webapp;\n",
    "            expires 1d;\n",
    "            add_header Cache-Control \"public\";\n",
    "        }\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Docker関連ファイルの作成\n",
    "with open('app/Dockerfile', 'w') as f:\n",
    "    f.write(dockerfile_content)\n",
    "\n",
    "with open('app/docker-compose.yml', 'w') as f:\n",
    "    f.write(compose_content)\n",
    "\n",
    "with open('app/nginx.conf', 'w') as f:\n",
    "    f.write(nginx_conf)\n",
    "\n",
    "# Docker実行スクリプトの作成\n",
    "docker_run_script = '''\n",
    "#!/bin/bash\n",
    "\n",
    "# Dockerビルド\n",
    "echo \"Dockerイメージをビルド中...\"\n",
    "docker build -t object-detection-webapp .\n",
    "\n",
    "# コンテナの実行\n",
    "echo \"コンテナを実行中...\"\n",
    "docker run -d \\\\\n",
    "    --name object-detection \\\\\n",
    "    -p 5000:5000 \\\\\n",
    "    -v $(pwd)/app:/app \\\\\n",
    "    -v $(pwd)/data:/app/data \\\\\n",
    "    -v $(pwd)/models:/app/models \\\\\n",
    "    object-detection-webapp\n",
    "\n",
    "# 実行状態の確認\n",
    "echo \"コンテナの状態:\"\n",
    "docker ps | grep object-detection\n",
    "\n",
    "echo \"アプリケーションは http://localhost:5000 でアクセスできます\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 2.3 FastAPIでの高性能展開\n"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# FastAPIアプリケーションの例\n",
    "fastapi_code = '''\n",
    "# main.py - FastAPIアプリケーション\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse, HTMLResponse\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.staticfiles import StaticFiles\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import base64\n",
    "import time\n",
    "import uvicorn\n",
    "from typing import List\n",
    "\n",
    "# アプリケーションの初期化\n",
    "app = FastAPI(\n",
    "    title=\"物体検出API\",\n",
    "    description=\"高性能物体検出API\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# CORSの設定\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# 静的ファイルのマウント\n",
    "app.mount(\"/static\", StaticFiles(directory=\"static\"), name=\"static\")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "    return {\"message\": \"物体検出APIへようこそ\"}\n",
    "\n",
    "@app.get(\"/docs\")\n",
    "async def docs():\n",
    "    return HTMLResponse(\"",
    "<html>\n",
    "    <head>\n",
    "        <title>物体検出API</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>物体検出API</h1>\n",
    "        <p>/docs でAPIドキュメントを確認できます</p>\n",
    "    </body>\n",
    "</html>",
    ")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    return {\"status\": \"healthy\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict_image(file: UploadFile = File(...)):\n",
    "    \"\"\"単一画像の物体検出\"\"\"\n",
    "    try:\n",
    "        # 画像の読み込み\n",
    "        contents = await file.read()\n",
    "        nparr = np.frombuffer(contents, np.uint8)\n",
    "        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        if image is None:\n",
    "            raise HTTPException(status_code=400, detail=\"画像の読み込みに失敗しました\")\n",
    "        \n",
    "        # 画像のリサイズ\n",
    "        resized = cv2.resize(image, (256, 256))\n",
    "        \n",
    "        # ダミー処理（実際はモデル推論）\n",
    "        start_time = time.time()\n",
    "        time.sleep(0.05)  # 擬似的な処理時間\n",
    "        \n",
    "        # ダミー検出結果\n",
    "        detections = []\n",
    "        for i in range(np.random.randint(1, 4)):\n",
    "            x = np.random.randint(0, 200)\n",
    "            y = np.random.randint(0, 200)\n",
    "            w = np.random.randint(30, 80)\n",
    "            h = np.random.randint(30, 80)\n",
    "            conf = np.random.uniform(0.7, 0.95)\n",
    "            cls = f\"object_{np.random.randint(0, 10)}\"\n",
    "            \n",
    "            detections.append({\n",
    "                \"box\": [x, y, w, h],\n",
    "                \"confidence\": conf,\n",
    "                \"class\": cls\n",
    "            })\n",
    "        \n",
    "        # 処理時間\n",
    "        processing_time = time.time() - start_time\n",
    "        \n",
    "        # 結果画像の作成\n",
    "        result_image = image.copy()\n",
    "        colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "        \n",
    "        for det in detections:\n",
    "            x, y, w, h = det[\"box\"]\n",
    "            color = colors[len(detections) % len(colors)]\n",
    "            cv2.rectangle(result_image, (x, y), (x + w, y + h), color, 2)\n",
    "            label = f\"{det['class']}: {det['confidence']:.2f}\"\n",
    "            cv2.putText(result_image, label, (x, y - 10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        # 結果画像をBase64に変換\n",
    "        _, buffer = cv2.imencode('.jpg', result_image)\n",
    "        result_base64 = base64.b64encode(buffer).decode('utf-8')\n",
    "        \n",
    "        return JSONResponse({\n",
    "            \"success\": True,\n",
    "            \"processing_time\": processing_time,\n",
    "            \"detections\": detections,\n",
    "            \"result_image\": result_base64\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/batch_predict\")\n",
    "async def batch_predict(files: List[UploadFile] = File(...)):\n",
    "    \"\"\"複数画像の一括処理\"\"\"\n",
    "    if len(files) > 10:\n",
    "        raise HTTPException(status_code=400, detail=\"一度に処理できる画像は10枚までです\")\n",
    "    \n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for file in files:\n",
    "        try:\n",
    "            # 画像の読み込み\n",
    "            contents = await file.read()\n",
    "            nparr = np.frombuffer(contents, np.uint8)\n",
    "            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "            \n",
    "            if image is None:\n",
    "                results.append({\n",
    "                    \"filename\": file.filename,\n",
    "                    \"error\": \"画像の読み込みに失敗しました\"\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # ダミー処理\n",
    "            time.sleep(0.03)  # 擬似的な処理時間\n",
    "            \n",
    "            results.append({\n",
    "                \"filename\": file.filename,\n",
    "                \"detections\": [{\"class\": \"sample\", \"confidence\": 0.85}],\n",
    "                \"processing_time\": 0.03\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                \"filename\": file.filename,\n",
    "                \"error\": str(e)\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    return JSONResponse({\n",
    "        \"success\": True,\n",
    "        \"total_time\": total_time,\n",
    "        \"results\": results\n",
    "    })\n",
    "\n",
    "@app.get(\"/model/info\")\n",
    "async def model_info():\n",
    "    \"\"\"モデル情報の取得\"\"\"\n",
    "    return {\n",
    "        \"model_name\": \"物体検出モデル\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"input_size\": (256, 256),\n",
    "        \"classes\": 10\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "\n",
    "# FastAPI関連ファイルの作成\n",
    "with open('app/fastapi_main.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(fastapi_code)\n",
    "\n",
    "# FastAPI用のrequirements.txt\n",
    "fastapi_requirements = '''\n",
    "fastapi==0.68.0\n",
    "uvicorn==0.15.0\n",
    "python-multipart==0.0.5\n",
    "numpy==1.21.0\n",
    "opencv-python==4.5.3.56\n",
    "Pillow==8.3.1\n",
    "'''\n",
    "\n",
    "with open('app/fastapi_requirements.txt', 'w') as f:\n",
    "    f.write(fastapi_requirements)\n",
    "\n",
    "print(\"\\n=== FastAPIアプリケーションを作成しました ===\")\n",
    "print(\"場所: app/fastapi_main.py\")\n",
    "print(\"\\n実行手順:\")\n",
    "print(\"1. cd app\")\n",
    "print(\"2. pip install -r fastapi_requirements.txt\")\n",
    "print(\"3. python fastapi_main.py\")\n",
    "print(\"4. http://localhost:8000/docs でAPIドキュメントを確認\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## 3. デプロイ戦略"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
    "# デプロイ戦略のまとめ\n",
    "deployment_strategies = {\n",
    "    \"local_deployment\": {\n",
    "        \"title\": \"ローカルデプロイ\",\n",
    "        \"description\": \"開発環境でのテスト\",\n",
    "        \"pros\": [\"手軽\", \"すぐに実行可能\", \"デバッグしやすい\"],\n",
    "        \"cons\": [\"スケーラビリティなし\", \"可用性低い\", \"本番環境非対応\"],\n",
    "        \"setup\": \"\n",
    "1. pip install -r requirements.txt\n",
    "2. python app.py または fastapi_main.py\n",
    "3. ブラウザでアクセス\n",
    "        \"\"\n",
    "    },\n",
    "    \"docker_deployment\": {\n",
    "        \"title\": \"Dockerコンテナ\",\n",
    "        \"description\": \"環境の再現性が高い\", \n",
    "        \"pros\": [\"環境の再現性\", \"移植性が高い\", \"リソース効率が良い\"],\n",
    "        \"cons\": [\"イメージサイズが大きい\", \"コンテナ管理が必要\", \"学習曲線\"],\n",
    "        \"setup\": \"\n",
    "1. Dockerfileの作成\n",
    "2. docker build -t app .\n",
    "3. docker run -p 5000:5000 app\n",
    "        \"\"\n",
    "    },\n",
    "    \"cloud_deployment\": {\n",
    "        \"title\": \"クラウドサービス\",\n",
    "        \"description\": \"本番環境向け\", \n",
    "        \"pros\": [\"スケーラビリティ\", \"高可用性\", \"管理しやすい\"],\n",
    "        \"cons\": [\"コスト\", \"設定が複雑\", \"依存関係\"],\n",
    "        \"setup\": \"\n",
    "AWS:\n",
    "1. ECRにイメージをプッシュ\n",
    "2. ECS/EKSでデプロイ\n",
    "3. ALBでロードバランシング\n",
    "\n",
    "GCP:\n",
    "1. Container Registryにプッシュ\n",
    "2. GKEでデプロイ\n",
    "3. Cloud Load Balancing\n",
    "\n",
    "Azure:\n",
    "1. Container Registryにプッシュ\n",
    "2. AKSでデプロイ\n",
    "3. Application Gateway\n",
    "        \"\"\n",
    "    },\n",
    "    \"serverless_deployment\": {\n",
    "        \"title\": \"サーバーレス\", \n",
    "        \"description\": \"イベント駆動\", \n",
    "        \"pros\": [\"コスト効率が良い\", \"スケール容易\", \"管理不要\"],\n",
    "        \"cons\": [\"実行時間制限\", \"コールドスタート\", \"デバッグが難しい\"],\n",
    "        \"setup\": \"\n",
    "AWS Lambda:\n",
    "1. Lambda関数を作成\n",
    "2. S3トリガーを設定\n",
    "3. API Gatewayで公開\n",
    "\n",
    "Google Cloud Functions:\n",
    "1. 関数を作成\n",
    "2. Cloud Storageトリガー\n",
    "3. Cloud Functions API\n",
    "        \"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# デプロイ戦略の表示\n",
    "print(\"=== デプロイ戦略の比較 ===\")\n",
    "for strategy, info in deployment_strategies.items():\n",
    "    print(f\"\\n{strategy.upper()}: {info['title']}\")\n",
    "    print(f\"説明: {info['description']}\")\n",
    "    print(\"\\nメリット:\")\n",
    "    for pro in info['pros']:\n",
    "        print(f\"  - {pro}\")\n",
    "    print(\"\\nデメリット:\")\n",
    "    for con in info['cons']:\n",
    "        print(f\"  - {con}\")\n",
    "    print(\"\\nセットアップ:\")\n",
    "    print(info['setup'])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# プロダクションチェックリスト\n",
    "production_checklist = [\n",
    "    {\n",
    "        \"category\": \"セキュリティ\",\n",
    "        \"items\": [\n",
    "            \"HTTPSの使用\",\n",
    "            \"認証と認可の実装\",\n",
    "            \"入力バリデーション\",\n",
    "            \"リクエストサイズ制限\",\n",
    "            \"APIキーの管理\",\n",
    "            \"セキュアなヘッダーの設定\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"パフォーマンス\",\n",
    "        \"items\": [\n",
    "            \"モデルの最適化\",\n",
    "            \"キャッシュ戦略の実装\",\n",
    "            \"非同期処理の使用\",\n",
    "            \"接続プールの設定\",\n",
    "            \"CDNの利用\",\n",
    "            \"圧縮の有効化\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"監視とログ\",\n",
    "        \"items\": [\n",
    "            \"エラーロギング\",\n",
    "            \"パフォーマンスモニタリング\",\n",
    "            \"アラート設定\",\n",
    "            \"リソース使用量の監視\",\n",
    "            \"ビジネス指標の追跡\",\n",
    "            \"ログの集約と分析\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"バックアップとリカバリ\",\n",
    "        \"items\": [\n",
    "            \"定期的なバックアップ\",\n",
    "            \"バージョン管理\",\n",
    "            \"災害復旧計画\",\n",
    "            \"データ復元のテスト\",\n",
    "            \"マルチリージョン配置\",\n",
    "            \"自動スケーリングの設定\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"=== プロダクション展開チェックリスト ===\")\n",
    "for section in production_checklist:\n",
    "    print(f\"\\n[{section['category']}]\")\n",
    "    for item in section['items']:\n",
    "        print(f\"  [ ] {item}\")\n",
    "    print()\n",
    "\n",
    "# CI/CDパイプラインの例\n",
    "cicd_pipeline = '''\n",
    "# .gitlab-ci.yml - CI/CDパイプラインの例\n",
    "stages:\n",
    "  - test\n",
    "  - build\n",
    "  - deploy\n",
    "\n",
    "variables:\n",
    "  DOCKER_DRIVER: overlay2\n",
    "  DOCKER_TLS_CERTDIR: \"/certs\"\n",
    "\n",
    "cache:\n",
    "  paths:\n",
    "    - .venv/\n",
    "    - node_modules/\n",
    "\n",
    "# テストステージ\n",
    "unit_test:\n",
    "  stage: test\n",
    "  image: python:3.9\n",
    "  before_script:\n",
    "    - python -m venv .venv\n",
    "    - source .venv/bin/activate\n",
    "    - pip install -r requirements.txt\n",
    "  script:\n",
    "    - pytest tests/ -v\n",
    "    - flake8 app/\n",
    "    - black --check app/\n",
    "\n",
    "# ビルドステージ\n",
    "build_docker:\n",
    "  stage: build\n",
    "  image: docker:latest\n",
    "  services:\n",
    "    - docker:dind\n",
    "  script:\n",
    "    - docker build -t object-detection:$CI_COMMIT_SHA .\n",
    "    - docker push $CI_REGISTRY/object-detection:$CI_COMMIT_SHA\n",
    "  only:\n",
    "    - main\n",
    "\n",
    "# デプロイステージ\n",
    "deploy_staging:\n",
    "  stage: deploy\n",
    "  image: alpine/k8s:latest\n",
    "  script:\n",
    "    - kubectl config use-context staging\n",
    "    - kubectl set image deployment/object-detection app=object-detection:$CI_COMMIT_SHA\n",
    "    - kubectl rollout status deployment/object-detection\n",
    "  only:\n",
    "    - main\n",
    "\n",
    "deploy_production:\n",
    "  stage: deploy\n",
    "  image: alpine/k8s:latest\n",
    "  script:\n",
    "    - kubectl config use-context production\n",
    "    - kubectl set image deployment/object-detection app=object-detection:$CI_COMMIT_SHA\n",
    "    - kubectl rollout status deployment/object-detection\n",
    "    - kubectl rollout restart deployment/monitoring\n",
    "  when: manual\n",
    "  only:\n",
    "    - main\n",
    "'''\n",
    "\n",
    "print(\"\\n=== CI/CDパイプライン例 ===\")\n",
    "print(cicd_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "## Week 6 振り返り"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
    "source": [
    "### 習得したスキル:\n",
    "- [x] モデル量子化の方法を理解した\n",
    "- [x] ONNX形式への変換を実装した\n",
    "- [x] FlaskベースのWebアプリを作成した\n",
    "- [x] Dockerコンテナ化を実装した\n",
    "- [x] FastAPIでの高性能展開を理解した\n",
    "- [x] デプロイ戦略を学んだ\n",
    "- [x] CI/CDパイプラインの概念を理解した\n",
    "\n",
    "**お疲れ様でした！** 全プロジェクトの完成です！\n",
    "\n",
    "### 今後の発展方向:\n",
    "- さらに大規模なモデルの最適化\n",
    "- エッジデバイスへの展開\n",
    "- リアルタイム処理の高速化\n",
    "- マルチモーダルなモデル\n",
    "- フェデレーテッドラーニング\n",
    "- MLOpsの自動化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}