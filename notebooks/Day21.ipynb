{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 21: 動き検出\n",
    "\n",
    "## Learning Objectives\n",
    "- 動き検出の原理を理解する\n",
    "- フレーム間差分法を実装する\n",
    "- 光流法を理解する\n",
    "- 背景差分法を実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory (2 hours)\n",
    "\n",
    "## 1.1 動き検出とは？\n",
    "\n",
    "動き検出は、動画シーケンスから移動しているオブジェクトや変化を検出する技術です。コンピュータビジョンの基本的なタスクの一つであり、多くの応用で使用されます。\n",
    "\n",
    "**主な用途**:\n",
    "- セキュリティ監視\n",
    "- 交通監視\n",
    "- ビデオ会議の背景ぼかし\n",
    "- 動きベースのトリガー\n",
    "- 動体検知カメラ\n",
    "\n",
    "**基本的な考え方**:\n",
    "1. 現在のフレームと過去のフレームを比較\n",
    "2. 画素値の変化を検出\n",
    "3. 閾値処理で動き領域を抽出\n",
    "4. ノイズ除去とオブジェクト検出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 フレーム間差分法 (Frame Differencing)\n",
    "\n",
    "最も基本的な動き検出手法です。連続するフレーム間の差を計算して動きを検出します。\n",
    "\n",
    "**アルゴリズム**:\n",
    "1. 現在フレーム `I(t)` と前フレーム `I(t-1)` を読み込む\n",
    "2. 絶対差を計算: `D(x,y) = |I(t)(x,y) - I(t-1)(x,y)|`\n",
    "3. しきい値処理: `M(x,y) = 1 if D(x,y) > T else 0`\n",
    "4. ノイズ除去（オープニング・クロージング）\n",
    "\n",
    "**特徴**:\n",
    "- メリット: 簡単で高速、背景の変化には頑健\n",
    "- デメリット: 動きの方向情報なし、照明変化に敏感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_difference(frame1, frame2, threshold=30):\n",
    "    \"\"\"フレーム間差分を計算\"\"\"\n",
    "    # 絶対差を計算\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    \n",
    "    # グレースケール化（もしされていなければ）\n",
    "    if len(diff.shape) > 2:\n",
    "        diff = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2値化\n",
    "    _, binary = cv2.threshold(diff, threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # ノイズ除去（モルフォロジー演算）\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "def create_test_sequence(height=100, width=100, num_frames=30):\n",
    "    \"\"\"テスト用の動画シーケンスを作成\"\"\"\n",
    "    frames = []\n",
    "    \n",
    "    # 静的な背景\n",
    "    background = np.random.randint(50, 150, (height, width), dtype=np.uint8)\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        frame = background.copy()\n",
    "        \n",
    "        # 移動する物体（円形）\n",
    "        center_x = 30 + i * 2  # 右に移動\n",
    "        center_y = 50 + 20 * np.sin(i * 0.3)  # 上下に正弦波運動\n",
    "        \n",
    "        # 円を描画\n",
    "        y_coords, x_coords = np.ogrid[:height, :width]\n",
    "        mask = (x_coords - center_x)**2 + (y_coords - center_y)**2 <= 20**2\n",
    "        frame[mask] = 255  # 白い物体\n",
    "        \n",
    "        frames.append(frame)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "# テストシーケンスの作成\n",
    "frames = create_test_sequence()\n",
    "print(f\"{len(frames)}フレームのシーケンスを作成\")\n",
    "print(f\"画像サイズ: {frames[0].shape}\")\n",
    "\n",
    "# 最初のフレームを表示\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(frames[0], cmap='gray')\n",
    "plt.title(\"フレーム 1\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(frames[15], cmap='gray')\n",
    "plt.title(\"フレーム 15\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(frames[29], cmap='gray')\n",
    "plt.title(\"フレーム 30\")\n",
    "plt.axis('off')\n",
    "\n",
    "# フレーム間差分\n",
    "diff1 = frame_difference(frames[0], frames[1])\n",
    "diff15 = frame_difference(frames[14], frames[15])\n",
    "diff29 = frame_difference(frames[28], frames[29])\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(diff1, cmap='gray')\n",
    "plt.title(\"フレーム差分 (1-2)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.imshow(diff15, cmap='gray')\n",
    "plt.title(\"フレーム差分 (15-16)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.imshow(diff29, cmap='gray')\n",
    "plt.title(\"フレーム差分 (29-30)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 背景差分法 (Background Subtraction)\n",
    "\n",
    "背景モデルを維持し、現在のフレームから背景を差し引いて前景（動き）を検出します。\n",
    "\n",
    "**アルゴリズム**:\n",
    "1. 背景モデル `B(x,y)` を作成\n",
    "2. フレーム `I(t)` から背景を差し引く: `D(x,y) = |I(t)(x,y) - B(x,y)|`\n",
    "3. しきい値処理で前景を抽出\n",
    "4. 背景モデルの更新（オプション）\n",
    "\n",
    "**背景モデルの更新方法**:\n",
    "- 単純平均: `B_new = α × B_old + (1-α) × I(t)`\n",
    "- 中値フィルタ\n",
    "- ガウシアン混合モデル (GMM)\n",
    "\n",
    "**特徴**:\n",
    "- メリット: 静止したオブジェクトを除去可能、照明変化に頑健\n",
    "- デメリット: 背景の変化に弱い、計算コストが高い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleBackgroundSubtractor:\n",
    "    \"\"\"単純な背景差分器\"\"\"\n",
    "    def __init__(self, alpha=0.95, threshold=30):\n",
    "        self.background = None\n",
    "        self.alpha = alpha  # 背景更新率（大きいほど遅く更新）\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def update_background(self, frame):\n",
    "        \"\"\"背景モデルを更新\"\"\"\n",
    "        if self.background is None:\n",
    "            self.background = frame.copy()\n",
    "        else:\n",
    "            # 移動平均で背景を更新\n",
    "            self.background = self.alpha * self.background + (1 - self.alpha) * frame\n",
    "    \n",
    "    def subtract(self, frame):\n",
    "        \"\"\"背景差分を計算\"\"\"\n",
    "        # 絶対差を計算\n",
    "        diff = cv2.absdiff(frame, self.background.astype(np.uint8))\n",
    "        \n",
    "        # 2値化\n",
    "        _, binary = cv2.threshold(diff, self.threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # ノイズ除去\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return cleaned\n",
    "\n",
    "# 背景差分のテスト\n",
    "bg_subtractor = SimpleBackgroundSubtractor(alpha=0.95)\n",
    "\n",
    "backgrounds = []\n",
    "foregrounds = []\n",
    "\n",
    "for i in range(30):\n",
    "    if i == 0:\n",
    "        # 最初のフレームで背景を初期化\n",
    "        bg_subtractor.update_background(frames[i])\n",
    "    else:\n",
    "        # 背景を更新\n",
    "        bg_subtractor.update_background(frames[i])\n",
    "        # フォアグラウンドを取得\n",
    "        fg = bg_subtractor.subtract(frames[i])\n",
    "        foregrounds.append(fg)\n",
    "\n",
    "print(f\"背景モデルの平均値: {np.mean(bg_subtractor.background):.2f}\")\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 初期背景\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.imshow(bg_subtractor.background, cmap='gray')\n",
    "plt.title(\"初期背景モデル\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 結果を表示\n",
    "for idx, frame_num in enumerate([5, 10, 15, 20, 25, 29]):\n",
    "    plt.subplot(3, 3, idx + 2)\n",
    "    plt.imshow(foregrounds[frame_num-1], cmap='gray')\n",
    "    plt.title(f\"フレーム {frame_num} の前景\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 光流法 (Optical Flow)\n",
    "\n",
    "各ピクセルの動きベクトルを計算する手法です。動きの方向と速度を検出できます。\n",
    "\n",
    "**Lucas-Kradek法**（最も一般的）:\n",
    "1. 隣接ピクセルの輝度が時間とともに一定であると仮定\n",
    "2. 動きベクトル `(u,v)` を計算する方程式を導出\n",
    "3. 最小二乗法でベクトルを求める\n",
    "\n",
    "**光流方程式**:\n",
    "\n",
    "```\n",
    "I(x+u, y+v, t+1) ≈ I(x,y,t)\n",
    "\n",
    "テイラー展開して整理:\n",
    "\n",
    "I_x × u + I_y × v + I_t = 0\n",
    "\n",
    "ここで：\n",
    "- I_x, I_y: 空間勾配\n",
    "- I_t: 時間的変化\n",
    "- u, v: 動きベクトル\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_optical_flow(frame1, frame2, window_size=3):\n",
    "    \"\"\"簡易的な光流計算（Lucas-Kradek法の概念）\"\"\"\n",
    "    # グレースケール化\n",
    "    if len(frame1.shape) > 2:\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 画像サイズ\n",
    "    height, width = frame1.shape\n",
    "    \n",
    "    # 勾配を計算\n",
    "    I_x = cv2.Sobel(frame1, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    I_y = cv2.Sobel(frame1, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    I_t = frame2.astype(np.float64) - frame1.astype(np.float64)\n",
    "    \n",
    "    # 光流ベクトルを計算\n",
    "    flow = np.zeros((height, width, 2), dtype=np.float32)\n",
    "    \n",
    "    # ウィンドウサイズ内で計算\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    for i in range(pad, height - pad):\n",
    "        for j in range(pad, width - pad):\n",
    "            # ウィンド領域を抽出\n",
    "            win_Ix = I_x[i-pad:i+pad+1, j-pad:j+pad+1].flatten()\n",
    "            win_Iy = I_y[i-pad:i+pad+1, j-pad:j+pad+1].flatten()\n",
    "            win_It = I_t[i-pad:i+pad+1, j-pad:j+pad+1].flatten()\n",
    "            \n",
    "            # 行列Aとベクトルbを作成\n",
    "            A = np.column_stack([win_Ix, win_Iy])\n",
    "            b = -win_It\n",
    "            \n",
    "            # 最小二乗解を求める\n",
    "            if np.linalg.matrix_rank(A) == 2:\n",
    "                u, v = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "                flow[i, j] = [u, v]\n",
    "            else:\n",
    "                flow[i, j] = [0, 0]\n",
    "    \n",
    "    return flow\n",
    "\n",
    "def visualize_flow(flow, step=10):\n",
    "    \"\"\"光流を可視化\"\"\"\n",
    "    height, width = flow.shape[:2]\n",
    "    \n",
    "    # 動きベクトルをサンプリング\n",
    "    h, w = np.mgrid[0:height:step, 0:width:step]\n",
    "    u = flow[::step, ::step, 0]\n",
    "    v = flow[::step, ::step, 1]\n",
    "    \n",
    "    # ベクトルの強度（速度）\n",
    "    magnitude = np.sqrt(u**2 + v**2)\n",
    "    \n",
    "    # 色相マップで可視化\n",
    "    hsv = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    hsv[..., 1] = 255\n",
    "    hsv[..., 0] = (magnitude / (magnitude.max() + 1e-6) * 180).astype(np.uint8)\n",
    "    hsv[..., 2] = 255\n",
    "    \n",
    "    # HSVからBGRに変換\n",
    "    flow_color = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # ベクトルを描画\n",
    "    flow_img = flow_color.copy()\n",
    "    \n",
    "    for i in range(0, u.shape[0]):\n",
    "        for j in range(0, u.shape[1]):\n",
    "            if magnitude[i, j] > 1:  # しきい値以上の動きのみ表示\n",
    "                start = (j * step, i * step)\n",
    "                end = (int(j * step + u[i, j]), int(i * step + v[i, j]))\n",
    "                cv2.arrowLine(flow_img, start, end, (0, 255, 0), 2)\n",
    "    \n",
    "    return flow_img\n",
    "\n",
    "# 光流の計算\n",
    "flow = calculate_optical_flow(frames[15], frames[16])\n",
    "\n",
    "print(f\"光流ベクトルの形状: {flow.shape}\")\n",
    "print(f\"動きの最大速度: {np.sqrt(flow[:,:,0]**2 + flow[:,:,1]**2).max():.2f}\")\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(frames[15], cmap='gray')\n",
    "plt.title(\"フレーム 15\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(frames[16], cmap='gray')\n",
    "plt.title(\"フレーム 16\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "flow_color = visualize_flow(flow, step=8)\n",
    "plt.imshow(flow_color)\n",
    "plt.title(\"光流（緑色の矢印）\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Practice (2 hours)\n",
    "\n",
    "それでは、学んだ知識を実際に使ってみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 21.1: フレーム間差分法の実装\n",
    "\n",
    "フレーム間差分法を自前で実装し、動きを検出してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_frame_diff(frame1, frame2, threshold=30, morphology=True):\n",
    "    \"\"\"自作のフレーム間差分\"\"\"\n",
    "    # グレースケール化\n",
    "    if len(frame1.shape) > 2:\n",
    "        frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "        frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 1. 絶対差を計算\n",
    "    diff = np.abs(frame1.astype(float) - frame2.astype(float))\n",
    "    \n",
    "    # 2. 2値化\n",
    "    binary = (diff > threshold).astype(np.uint8) * 255\n",
    "    \n",
    "    # 3. モルフォロジー処理（オプション）\n",
    "    if morphology:\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "# テスト\n",
    "my_diff1 = my_frame_diff(frames[10], frames[11], threshold=20)\n",
    "cv_diff1 = frame_difference(frames[10], frames[11], threshold=20)\n",
    "\n",
    "# 結果の比較\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(my_diff1, cmap='gray')\n",
    "plt.title(\"自作フレーム差分\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cv_diff1, cmap='gray')\n",
    "plt.title(\"OpenCVフレーム差分\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "diff_map = my_diff1 != cv_diff1\n",
    "plt.imshow(diff_map, cmap='Reds')\n",
    "plt.title(\"違い（赤）\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 一致度の確認\n",
    "diff_pixels = np.sum(diff_map)\n",
    "total_pixels = frames[0].shape[0] * frames[0].shape[1]\n",
    "accuracy = (1 - diff_pixels / total_pixels) * 100\n",
    "print(f\"一致度: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 21.2: 背景モデルの更新戦略\n",
    "\n",
    "異なる更新戦略で背景モデルを比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedianBackgroundSubtractor:\n",
    "    \"\"\"中値フィルタによる背景差分器\"\"\"\n",
    "    def __init__(self, history=5, threshold=30):\n",
    "        self.history_frames = []\n",
    "        self.history_size = history\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def update(self, frame):\n",
    "        \"\"\"フレーム履歴を更新\"\"\"\n",
    "        self.history_frames.append(frame)\n",
    "        if len(self.history_frames) > self.history_size:\n",
    "            self.history_frames.pop(0)\n",
    "    \n",
    "    def get_background(self):\n",
    "        \"\"\"中値を背景として取得\"\"\"\n",
    "        if len(self.history_frames) == 0:\n",
    "            return None\n",
    "        \n",
    "        # スタックして中値を計算\n",
    "        stack = np.stack(self.history_frames, axis=2)\n",
    "        background = np.median(stack, axis=2).astype(np.uint8)\n",
    "        return background\n",
    "    \n",
    "    def subtract(self, frame):\n",
    "        \"\"\"背景差分\"\"\"\n",
    "        if len(self.history_frames) == 0:\n",
    "            return np.zeros_like(frame)\n",
    "        \n",
    "        background = self.get_background()\n",
    "        diff = cv2.absdiff(frame, background)\n",
    "        _, binary = cv2.threshold(diff, self.threshold, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # モルフォロジー処理\n",
    "        kernel = np.ones((3,3), np.uint8)\n",
    "        cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n",
    "        \n",
    "        return cleaned\n",
    "\n",
    "# 中値フィルタ背景差分器のテスト\n",
    "median_bg_sub = MedianBackgroundSubtractor(history=5)\n",
    "median_foregrounds = []\n",
    "\n",
    "for i in range(30):\n",
    "    median_bg_sub.update(frames[i])\n",
    "    if i >= 4:  # 5フレーム目から開始\n",
    "        fg = median_bg_sub.subtract(frames[i])\n",
    "        median_foregrounds.append(fg)\n",
    "\n",
    "# 結果の比較\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# シンプルな平均と中値の比較\n",
    "simple_fg = bg_subtractor.subtract(frames[29])\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.imshow(frames[0], cmap='gray')\n",
    "plt.title(\"フレーム 1\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.imshow(simple_fg, cmap='gray')\n",
    "plt.title(\"平均背景差分\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.imshow(median_foregrounds[-1], cmap='gray')\n",
    "plt.title(\"中値背景差分\")\n",
    "plt.axis('off')\n",
    "\n",
    "# 中間フレームの比較\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.imshow(frames[15], cmap='gray')\n",
    "plt.title(\"フレーム 15\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "current_simple = bg_subtractor.subtract(frames[15])\n",
    "plt.imshow(current_simple, cmap='gray')\n",
    "plt.title(\"平均背景差分 (15)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "median_fg = median_foregrounds[15-4] if 15-4 < len(median_foregrounds) else median_foregrounds[-1]\n",
    "plt.imshow(median_fg, cmap='gray')\n",
    "plt.title(\"中値背景差分 (15)\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 21.3: 光流法の実践\n",
    "\n",
    "光流法を使って物体の軌跡を追跡してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_object_with_optical_flow(frames, start_pos, max_frames=10):\n",
    "    \"\"\"光流法による物体追跡\"\"\"\n",
    "    # 追跡結果のリスト\n",
    "    positions = [start_pos]\n",
    "    \n",
    "    # 前フレームを取得\n",
    "    prev_frame = frames[0]\n",
    "    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 追跡開始位置の近傍に特徴点を選択\n",
    "    x, y = start_pos\n",
    "    neighborhood_size = 20\n",
    "    \n",
    "    for i in range(1, min(len(frames), max_frames)):\n",
    "        # 現在のフレーム\n",
    "        curr_frame = frames[i]\n",
    "        curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 特徴点を検出（追跡開始位置の近傍）\n",
    "        y_min = max(0, y - neighborhood_size)\n",
    "        y_max = min(curr_gray.shape[0], y + neighborhood_size)\n",
    "        x_min = max(0, x - neighborhood_size)\n",
    "        x_max = min(curr_gray.shape[1], x + neighborhood_size)\n",
    "        \n",
    "        # 領域内で角点を検出\n",
    "        region = curr_gray[y_min:y_max, x_min:x_max]\n",
    "        corners = cv2.goodFeaturesToTrack(\n",
    "            region, 1, 0.01, 10\n",
    "        )\n",
    "        \n",
    "        if corners is not None:\n",
    "            # 角点を画像座標に変換\n",
    "            corner = corners[0].ravel()\n",
    "            new_x = int(x_min + corner[0])\n",
    "            new_y = int(y_min + corner[1])\n",
    "            \n",
    "            # 位置を更新\n",
    "            x, y = new_x, new_y\n",
    "            positions.append((x, y))\n",
    "        \n",
    "        # 現在のフレームを次のイテレーション用に保存\n",
    "        prev_gray = curr_gray\n",
    "    \n",
    "    return positions\n",
    "\n",
    "# 物体追跡のテスト\n",
    "# 物体の初期位置（フレーム10での円の中心）\n",
    "start_x, start_y = 50, 50  # おおよその初期位置\n",
    "positions = track_object_with_optical_flow(frames, (start_x, start_y), max_frames=20)\n",
    "\n",
    "print(f\"追跡した位置: {positions}\")\n",
    "\n",
    "# 軌跡の可視化\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 軌跡をフレーム上に描画\n",
    "for idx, frame_num in enumerate([0, 10, 20]):\n",
    "    plt.subplot(2, 3, idx + 1)\n",
    "    plt.imshow(frames[frame_num], cmap='gray')\n",
    "    \n",
    "    # 位置を描画\n",
    "    pos_idx = min(frame_num, len(positions) - 1)\n",
    "    if pos_idx < len(positions):\n",
    "        x, y = positions[pos_idx]\n",
    "        plt.plot(x, y, 'ro', markersize=10)\n",
    "        plt.plot(positions[:pos_idx+1], 'g-', alpha=0.5)\n",
    "    \n",
    "    plt.title(f\"フレーム {frame_num}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# 軌跡のグラフ\n",
    "x_positions = [pos[0] for pos in positions]\n",
    "y_positions = [pos[1] for pos in positions]\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(x_positions, label='X座標')\n",
    "plt.plot(y_positions, label='Y座標')\n",
    "plt.xlabel('フレーム番号')\n",
    "plt.ylabel('位置')\n",
    "plt.title('物体の軌跡')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(x_positions)\n",
    "plt.title('X方向の移動')\n",
    "plt.xlabel('フレーム')\n",
    "plt.ylabel('X座標')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(y_positions)\n",
    "plt.title('Y方向の移動')\n",
    "plt.xlabel('フレーム')\n",
    "plt.ylabel('Y座標')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: 連続的な動き検出\n",
    "\n",
    "以下の要件を満たす動き検出システムを実装してください：\n",
    "\n",
    "1. フレーム間差分法と背景差分法を組み合わせたハイブリッド手法\n",
    "2. 動きが検出された場合、その領域を四角で囲む\n",
    "3. 動きの速度に応じて色を変更（遅い=青、早い=赤）\n",
    "4. 動きが一定時間以上続いている場合、アラートを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridMotionDetector:\n",
    "    \"\"\"ハイブリッド動き検出器\"\"\"\n",
    "    def __init__(self, frame_diff_threshold=30, bg_diff_threshold=30, min_area=100):\n",
    "        self.frame_diff_threshold = frame_diff_threshold\n",
    "        self.bg_diff_threshold = bg_diff_threshold\n",
    "        self.min_area = min_area\n",
    "        \n",
    "        # 背景差分器\n",
    "        self.bg_subtractor = SimpleBackgroundSubtractor(\n",
    "            alpha=0.95, threshold=bg_diff_threshold\n",
    "        )\n",
    "        \n",
    "        # 動き履歴\n",
    "        self.motion_history = []\n",
    "        self.max_history = 30\n",
    "    \n",
    "    def detect(self, frame):\n",
    "        \"\"\"動きを検出し、結果を返す\"\"\"\n",
    "        # 1. フレーム間差分\n",
    "        if hasattr(self, 'prev_frame'):\n",
    "            frame_diff = frame_difference(\n",
    "                self.prev_frame, frame, self.frame_diff_threshold\n",
    "            )\n",
    "        else:\n",
    "            frame_diff = np.zeros_like(frame)\n",
    "        \n",
    "        # 2. 背景差分\n",
    "        self.bg_subtractor.update_background(frame)\n",
    "        bg_diff = self.bg_subtractor.subtract(frame)\n",
    "        \n",
    "        # 3. 論理和（どちらかで検出された領域）\n",
    "        combined = cv2.bitwise_or(frame_diff, bg_diff)\n",
    "        \n",
    "        # 4. 輪郭検出\n",
    "        contours, _ = cv2.findContours(\n",
    "            combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "        \n",
    "        # 5. 面積フィルタリング\n",
    "        large_contours = [\n",
    "            cnt for cnt in contours \n",
    "            if cv2.contourArea(cnt) > self.min_area\n",
    "        ]\n",
    "        \n",
    "        # 動き領域を計算\n",
    "        total_area = sum(cv2.contourArea(cnt) for cnt in large_contours)\n",
    "        max_speed = min(255, total_area // 10)  # 速度の見積もり\n",
    "        \n",
    "        # 結果の画像を作成\n",
    "        result = frame.copy()\n",
    "        if len(frame.shape) == 2:\n",
    "            result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "        \n",
    "        # 動き領域を描画\n",
    "        for cnt in large_contours:\n",
    "            # 色を速度に応じて変更\n",
    "            color_intensity = min(255, max_speed * 2)\n",
    "            color = (color_intensity, 0, 255 - color_intensity)  # 青から赤へ\n",
    "            \n",
    "            # 輪郭を描画\n",
    "            cv2.drawContours(result, [cnt], 0, color, 2)\n",
    "            \n",
    "            # バウンディングボックスを描画\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(result, (x, y), (x+w, y+h), color, 2)\n",
    "        \n",
    "        # 動き履歴を更新\n",
    "        self.motion_history.append(total_area)\n",
    "        if len(self.motion_history) > self.max_history:\n",
    "            self.motion_history.pop(0)\n",
    "        \n",
    "        # アラートチェック（5フレーム以上継続）\n",
    "        alert = False\n",
    "        if len(self.motion_history) >= 5:\n",
    "            if all(area > 0 for area in self.motion_history[-5:]):\n",
    "                alert = True\n",
    "                cv2.putText(result, \"ALERT!\", (10, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        \n",
    "        # 前フレームを保存\n",
    "        self.prev_frame = frame.copy()\n",
    "        \n",
    "        return result, {\n",
    "            'total_area': total_area,\n",
    "            'max_speed': max_speed,\n",
    "            'alert': alert\n",
    "        }\n",
    "\n",
    "# テスト\n",
    "detector = HybridMotionDetector()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for idx, frame_num in enumerate([0, 5, 10, 15, 20, 25]):\n",
    "    if frame_num < len(frames):\n",
    "        result, info = detector.detect(frames[frame_num])\n",
    "        \n",
    "        plt.subplot(2, 3, idx + 1)\n",
    "        plt.imshow(result, cmap='gray' if len(result.shape) == 2 else None)\n",
    "        plt.title(f\"フレーム {frame_num}\\n面積: {info['total_area']}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Self-Check (理解度確認)\n",
    "\n",
    "本日の学習内容を確認しましょう：\n",
    "\n",
    "## 基礎知識\n",
    "- [ ] 動き検出の基本的な概念と応用を理解した\n",
    "- [ ] フレーム間差分法の原理と実装方法を理解した\n",
    "- [ ] 背景差分法の原理と背景モデルの更新方法を理解した\n",
    "- [ ] 光流法の基本的な考え方と動きベクトルを理解した\n",
    "\n",
    "## 実践力\n",
    "- [ ] フレーム間差分法を自前で実装できた\n",
    "- [ ] 背景モデルを更新する複数の手法を比較できた\n",
    "- [ ] 光流法を使った物体追跡を実装できた\n",
    "- [ ] ハイブリッド動き検出システムを構築できた\n",
    "\n",
    "## 深層理解\n",
    "- [ ] 各手法の長所と短所を比較できた\n",
    "- [ ] ノイズ除去の重要性を理解した\n",
    "- [ ] 計算効率と精度のトレードオフを理解した\n",
    "- [ ] 実際のアプリケーションへの応用方法を考えた\n",
    "\n",
    "---\n",
    "\n",
    "**お疲れ様でした！** Day 21はこれで終了です。\n",
    "\n",
    "次回（Day 22）は「ニューラルネットワーク基礎」を学び、深層学習の基礎から始めます。\n",
    "\n",
    "復習課題：\n",
    "1. 自分のスマートフォンやウェブカメラからリアルタイムに動き検出を実装してみる\n",
    "2. 異なる閾値値での動き検出性能を比較する\n",
    "3. 背景の照明変化に対応するための改良方法を考える"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
