{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 26: 物体検出入門\n",
    "\n",
    "## Learning Objectives\n",
    "- 物体検出の概念を理解する\n",
    "- 2段階検出（Two-stage Detection）を理解する\n",
    "- 一段階検出（One-stage Detection）を理解する\n",
    "- YOLOの基本原理を理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory (2 hours)\n",
    "\n",
    "## 1.1 物体検出とは？\n",
    "\n",
    "物体検出（Object Detection）は、画像内に存在する物体を検出し、その位置とクラスを特定するタスクです。物体検出は以下の情報を出力します：\n",
    "\n",
    "1. **Bounding Box（バウンディングボックス）**: 物体を囲む矩形\n",
    "2. **Class Label（クラスラベル）**: 物体の種類（人、車、猫など）\n",
    "3. **Confidence Score（信頼度スコア）**: 検出の確信度\n",
    "\n",
    "**物体検出の応用**:\n",
    "- 自動運転\n",
    "- 監視カメラ\n",
    "- 医療診断\n",
    "- 動物検出\n",
    "- 欠陥検出\n",
    "\n",
    "**画像分類 vs 物体検出**:\n",
    "- 画像分類：画像全体が何かを分類\n",
    "- 物体検出：画像内の複数の物体を個別に検出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 物体検出のアーキテクチャ\n",
    "\n",
    "物体検出のアーキテクチャは大きく2つのカテゴリに分けられます：\n",
    "\n",
    "### 1. 2段階検出（Two-stage Detection）\n",
    "\n",
    "**特徴**:\n",
    "- 高精度\n",
    "- 計算コストが高い\n",
    "- R-CNN系列（R-CNN, Fast R-CNN, Faster R-CNN）\n",
    "\n",
    "**処理フロー**:\n",
    "1. Region Proposal（領域提案）- 候補領域を生成\n",
    "2. Classification & Bounding Box Regression - 各領域を分類と回帰\n",
    "\n",
    "**代表的なモデル**:\n",
    "- Faster R-CNN\n",
    "- Mask R-CNN（セグメンテーションも追加）\n",
    "### 2. 一段階検出（One-stage Detection）\n",
    "\n",
    "**特徴**:\n",
    "- 高速\n",
    "- 精度はやや低い\n",
    "- YOLO, SSDなど\n",
    "\n",
    "**処理フロー**:\n",
    "1. グリッドを画像に分割\n",
    "2. 各グリッドセルが物体を検出\n",
    "\n",
    "**代表的なモデル**:\n",
    "- YOLO (You Only Look Once)\n",
    "- SSD (Single Shot MultiBox Detector)\n",
    "- RetinaNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 YOLOの基本原理\n",
    "\n",
    "YOLO（You Only Look Once）は最も人気のある一段階検出アルゴリズムです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLOの特徴\n",
    "\n",
    "**特徴**:\n",
    "- 画像を一度だけ見て（Look Once）検出を実行\n",
    "- エンドツーエンドで学習可能\n",
    "- 実時間処理に適している\n",
    "\n",
    "**基本アイデア**:\n",
    "1. 画像をS×Sのグリッドに分割\n",
    "2. 各グリッドセルはB個のバウンディングボックスを予測\n",
    "3. 各ボックスには以下を予測：\n",
    "   - 中心座標 (x, y)\n",
    "   - 幅と高さ (w, h)\n",
    "   - 信頼度スコア\n",
    "   - クラス確率分布\n",
    "\n",
    "**出力形式**:\n",
    "   - 各グリッドセルは(B×5 + C)個の出力を持つ\n",
    "   - 5 = (x, y, w, h, confidence)\n",
    "   - C = クラス数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_grid_demo(S=7, B=2, C=20):\n",
    "    \"\"\"YOLOグリッドのデモンストレーション\"\"\"\n",
    "    # グリッドの作成\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # 左：グリッドの表示\n",
    "    ax1.set_xlim(0, S)\n",
    "    ax1.set_ylim(0, S)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_title(f'S×S = {S}×{S} グリッド')\n",
    "    ax1.set_xlabel('X')\n",
    "    ax1.set_ylabel('Y')\n",
    "    \n",
    "    # グリッドの境界線を描画\n",
    "    for i in range(S + 1):\n",
    "        ax1.axhline(y=i, color='black', linewidth=1)\n",
    "        ax1.axvline(x=i, color='black', linewidth=1)\n",
    "    \n",
    "    # グリッドセル番号を表示\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            cell_id = i * S + j\n",
    "            ax1.text(j + 0.5, S - i - 0.5, f'{cell_id}', \n",
    "                    ha='center', va='center', fontsize=8)\n",
    "    \n",
    "    # 右：各セルの出力の説明\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('各グリッドセルの出力形式')\n",
    "    \n",
    "    # 出力形式の説明\n",
    "    output_text = f\"各セルの出力形式:\\n\\n\"\n",
    "    output_text += f\"- バウンディングボックス数: {B}\\n\"\n",
    "    output_text += f\"- 各ボックスのパラメータ: 5個\\n\"\n",
    "    output_text += f\"  (x, y, w, h, confidence)\\n\"\n",
    "    output_text += f\"- クラス数: {C}\\n\\n\"\n",
    "    output_text += f\"総出力サイズ = {S} × {S} × ({B} × 5 + {C})\\n\\n\"\n",
    "    output_text += f\"= {S*S} × ({B*5 + C)} = {S*S*(B*5 + C)} 個の予測値\\n\\n\"\n",
    "    output_text += f\"例: S=7, B=2, C=20:\\n\"\n",
    "    output_text += f\"= 7×7×(2×5 + 20) = 49 × 30 = 1470 個の予測値\"\n",
    "    \n",
    "    ax2.text(0.1, 0.5, output_text, transform=ax2.transAxes,\n",
    "             fontsize=12, verticalalignment='center',\n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\"))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# YOLOグリッドデモの表示\n",
    "create_yolo_grid_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 バウンディングボックスの予測\n",
    "\n",
    "YOLOは相対座標でバウンディングボックスを予測します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_yolo_bbox_prediction(S=7, img_size=448):\n",
    "    \"\"\"YOLOのバウンディングボックス予測を可視化\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # グリッドサイズ\n",
    "    cell_size = img_size // S\n",
    "    \n",
    "    # 1. グリッドとセルの中心\n",
    "    ax = axes[0, 0]\n",
    "    ax.set_xlim(0, img_size)\n",
    "    ax.set_ylim(0, img_size)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('グリッドとセル中心')\n",
    "    \n",
    "    # グリッド描画\n",
    "    for i in range(S + 1):\n",
    "        ax.axhline(y=i * cell_size, color='gray', linewidth=1)\n",
    "        ax.axvline(x=i * cell_size, color='gray', linewidth=1)\n",
    "    \n",
    "    # セル中心を表示\n",
    "    centers = []\n",
    "    for i in range(S):\n",
    "        for j in range(S):\n",
    "            cx = j * cell_size + cell_size // 2\n",
    "            cy = i * cell_size + cell_size // 2\n",
    "            ax.plot(cx, cy, 'bo', markersize=5)\n",
    "            centers.append((cx, cy))\n",
    "    \n",
    "    # 2. 物体のあるセル\n",
    "    ax = axes[0, 1]\n",
    "    ax.set_xlim(0, img_size)\n",
    "    ax.set_ylim(0, img_size)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('物体のあるセル（セル相対座標）')\n",
    "    \n",
    "    # グリッド描画\n",
    "    for i in range(S + 1):\n",
    "        ax.axhline(y=i * cell_size, color='gray', linewidth=1)\n",
    "        ax.axvline(x=i * cell_size, color='gray', linewidth=1)\n",
    "    \n",
    "    # 物体のあるセル（例: 中心に一つ）\n",
    "    obj_cell_i, obj_cell_j = 3, 2  # 中央付近のセル\n",
    "    obj_cx = obj_cell_j * cell_size + cell_size // 2\n",
    "    obj_cy = obj_cell_i * cell_size + cell_size // 2\n",
    "    \n",
    "    # 物体の真の中心（グリッド相対）\n",
    "    true_x_in_cell = 0.7  # セル内でのx位置（0-1）\n",
    "    true_y_in_cell = 0.3  # セル内でのy位置（0-1）\n",
    "    true_w_in_cell = 0.6  # セルに対する幅の割合\n",
    "    true_h_in_cell = 0.8  # セルに対する高さの割合\n",
    "    \n",
    "    # セル相対座標でボックスを描画\n",
    "    bbox_x = true_x_in_cell * cell_size\n",
    "    bbox_y = true_y_in_cell * cell_size\n",
    "    bbox_w = true_w_in_cell * cell_size\n",
    "    bbox_h = true_h_in_cell * cell_size\n",
    "    \n",
    "    rect = plt.Rectangle((bbox_x, bbox_y), bbox_w, bbox_h,\n",
    "                         linewidth=2, edgecolor='red', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # セル中心を表示\n",
    "    ax.plot(obj_cx, obj_cy, 'go', markersize=8)\n",
    "    \n",
    "    # ラベル\n",
    "    ax.text(10, img_size-20, f\"セル相対座標: ({true_x_in_cell:.2f}, {true_y_in_cell:.2f}, {true_w_in_cell:.2f}, {true_h_in_cell:.2f})\",\n",
    "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    \n",
    "    # 3. 絶対座標でのバウンディングボックス\n",
    "    ax = axes[1, 0]\n",
    "    ax.set_xlim(0, img_size)\n",
    "    ax.set_ylim(0, img_size)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('絶対座標でのバウンディングボックス')\n",
    "    \n",
    "    # グリッド描画\n",
    "    for i in range(S + 1):\n",
    "        ax.axhline(y=i * cell_size, color='gray', linewidth=1)\n",
    "        ax.axvline(x=i * cell_size, color='gray', linewidth=1)\n",
    "    \n",
    "    # 絶対座標を計算\n",
    "    abs_x = obj_cx + bbox_x - cell_size // 2\n",
    "    abs_y = obj_cy + bbox_y - cell_size // 2\n",
    "    abs_w = bbox_w\n",
    "    abs_h = bbox_h\n",
    "    \n",
    "    # 絶対座標のボックスを描画\n",
    "    rect_abs = plt.Rectangle((abs_x, abs_y), abs_w, abs_h,\n",
    "                            linewidth=3, edgecolor='blue', facecolor='none')\n",
    "    ax.add_patch(rect_abs)\n",
    "    \n",
    "    # 中心点を表示\n",
    "    center_x = abs_x + abs_w / 2\n",
    "    center_y = abs_y + abs_h / 2\n",
    "    ax.plot(center_x, center_y, 'ro', markersize=8)\n",
    "    \n",
    "    # 4. 変換式\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    ax.set_title('YOLOの変換式')\n",
    "    \n",
    "    formula_text = \"\"\"YOLOの座標変換:\n",
    "\n",
    "# 相対座標 → 絶対座標\n",
    "t_x = cell_x / S\n",
    "t_y = cell_y / S\n",
    "t_w = log(w / cell_w) / S\n",
    "t_h = log(h / cell_h) / S\n",
    "\n",
    "# 絶対座標 → 相対座標\n",
    "cell_x = S * t_x\n",
    "cell_y = S * t_y\n",
    "w = exp(t_w * S) * cell_w\n",
    "h = exp(t_h * S) * cell_h\n",
    "\n",
    "# セル中心を考慮した最終的なバウンディングボックス\n",
    "bx = S * t_x + cell_j\n",
    "by = S * t_y + cell_i\n",
    "bw = exp(t_w * S)\n",
    "bh = exp(t_h * S)\n",
    "\"\"\"\n",
    "    \n",
    "    ax.text(0.1, 0.5, formula_text, transform=ax.transAxes,\n",
    "            fontsize=11, verticalalignment='center',\n",
    "            fontfamily='monospace',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\"))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# YOLOのバウンディングボックス予測を可視化\n",
    "visualize_yolo_bbox_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 損失関数\n",
    "\n",
    "YOLOの損失関数は3つの部分から構成されます："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def plot_yolo_loss_components():\n",
    "    \"\"\"YOLOの損失関数の構成要素を可視化\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # 1. 位置損失\n",
    "    ax = axes[0, 0]\n",
    "    x = np.linspace(0, 1, 100)\n",
    "    y1 = x**2  # (x_pred - x_true)^2\n",
    "    y2 = np.sqrt(x)  # sqrt(|x_pred - x_true|)\n",
    "    \n",
    "    ax.plot(x, y1, 'b-', label='x^2', linewidth=2)\n",
    "    ax.plot(x, y2, 'r--', label='sqrt(|x|)', linewidth=2)\n",
    "    ax.set_xlabel('誤差の大きさ')\n",
    "    ax.set_ylabel('損失')\n",
    "    ax.set_title('位置損失関数')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 予測誤差と重み\n",
    "    ax = axes[0, 1]\n",
    "    errors = np.linspace(0, 1, 100)\n",
    "    no_weight = errors**2\n",
    "    with_weight = 5 * errors**2  # 予測がないセルの重み\n",
    "    \n",
    "    ax.plot(errors, no_weight, 'b-', label='通常のセル', linewidth=2)\n",
    "    ax.plot(errors, with_weight, 'r--', label='予測がないセル', linewidth=2)\n",
    "    ax.set_xlabel('誤差の大きさ')\n",
    "    ax.set_ylabel('損失')\n",
    "    ax.set_title('重み付き損失')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. クラス損失\n",
    "    ax = axes[1, 0]\n",
    "    # 交差エントロピー\n",
    "    true_probs = [0.9, 0.05, 0.05]  # 真のクラス分布\n",
    "    pred_probs_1 = [0.9, 0.05, 0.05]  # 完全に正解\n",
    "    pred_probs_2 = [0.1, 0.45, 0.45]  # 異なるクラスに予測\n",
    "    \n",
    "    # 交差エントロピー計算\n",
    "    def cross_entropy(true, pred):\n",
    "        return -sum(t * np.log(p + 1e-10) for t, p in zip(true, pred))\n",
    "    \n",
    "    ce_1 = cross_entropy(true_probs, pred_probs_1)\n",
    "    ce_2 = cross_entropy(true_probs, pred_probs_2)\n",
    "    \n",
    "    # バーの描画\n",
    "    bars = ax.bar(['正確な予測', \"不正確な予測\"], [ce_1, ce_2], \n",
    "                 color=['green', 'red'])\n",
    "    ax.set_ylabel('交差エントロピー損失')\n",
    "    ax.set_title('クラス損失の例')\n",
    "    ax.set_ylim(0, 2.5)\n",
    "    \n",
    "    # 数値を表示\n",
    "    for bar, value in zip(bars, [ce_1, ce_2]):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 4. 全体の損失構成\n",
    "    ax = axes[1, 1]\n",
    "    ax.axis('off')\n",
    "    ax.set_title('YOLOの総損失関数')\n",
    "    \n",
    "    loss_text = \"\"\"総損失 = λ_coord × L_coord + λ_noobj × L_noobj + L_class\n",
    "\n",
    "1. 位置損失 L_coord:\n",
    "   - 中心座標の誤差 (x, y)\n",
    "   - 大きさの誤差 (w, h)\n",
    "   - 重み λ_coord = 5\n",
    "\n",
    "2. 予測なし損失 L_noobj:\n",
    "   - 物体のないセルでの予測誤差\n",
    "   - 重み λ_noobj = 0.5\n",
    "\n",
    "3. クラス損失 L_class:\n",
    "   - クラス予測の交差エントロピー\n",
    "   - 全セルで計算\n",
    "\n",
    "特徴:\n",
    "- 位置と大きさには大きな重みを設定\n",
    "- 物体のないセルでの予測をペナルティ\n",
    "- クラス分離に大きく影響\"\"\"\n",
    "    \n",
    "    ax.text(0.05, 0.95, loss_text, transform=ax.transAxes,\n",
    "            fontsize=11, verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightyellow\"))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# YOLOの損失関数を可視化\n",
    "plot_yolo_loss_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Practice (2 hours)\n",
    "\n",
    "それでは、学んだ知識を実際に使ってみましょう！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 26.1: YOLOの基本的な実装\n",
    "\n",
    "簡易版YOLOを実装し、バウンディングボックスの予測を行いましょう。"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_yolo_detector(grid_size=7, num_boxes=2, num_classes=20):\n",
    "    \"\"\"簡易YOLO検出器の作成\"\"\"\n",
    "    # モデルの入力\n",
    "    inputs = keras.Input(shape=(448, 448, 3))\n",
    "    \n",
    "    # 特徴抽出（簡略化）\n",
    "    x = layers.Conv2D(64, 7, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(192, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(384, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(2)(x)\n",
    "    \n",
    "    x = layers.Conv2D(512, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # 最終的な特徴マップ\n",
    "    feature_map = layers.Conv2D(1024, 3, padding='same', activation='relu')(x)\n",
    "    \n",
    "    # YOLO出力層\n",
    "    output = layers.Conv2D(\n",
    "        grid_size * grid_size * (num_boxes * 5 + num_classes),\n",
    "        1,\n",
    "        activation='sigmoid'\n",
    "    )(feature_map)\n",
    "    \n",
    "    # 出力をreshape\n",
    "    output = layers.Reshape((\n",
    "        grid_size, grid_size, num_boxes, 5 + num_classes\n",
    "    ))(output)\n",
    "    \n",
    "    # モデルの作成\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 簡易YOLOモデルの作成\n",
    "model = create_simple_yolo_detector(grid_size=7, num_boxes=2, num_classes=20)\n",
    "model.summary()\n",
    "\n",
    "# モデルの図\n",
    "keras.utils.plot_model(\n",
    "    model, \n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB',\n",
    "    dpi=96\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_decode_predictions(predictions, grid_size=7, num_boxes=2, num_classes=20):\n",
    "    \"\"\"YOLOの出力をデコードする\"\"\"\n",
    "    # 予測を取得\n",
    "    batch_size = predictions.shape[0]\n",
    "    \n",
    "    # 各予測を展開\n",
    "    pred = predictions[0]  # 最初のバッチを取得\n",
    "    \n",
    "    # グリッドごとの予測を取得\n",
    "    grid_preds = pred.reshape(\n",
    "        (grid_size, grid_size, num_boxes, 5 + num_classes)\n",
    "    )\n",
    "    \n",
    "    # 位置情報を取得\n",
    "    cell_x = grid_preds[..., 0]  # セル相対x\n",
    "    cell_y = grid_preds[..., 1]  # セル相対y\n",
    "    cell_w = grid_preds[..., 2]  # セル相対w\n",
    "    cell_h = grid_preds[..., 3]  # セル相対h\n",
    "    confidence = grid_preds[..., 4]  # 信頼度\n",
    "    class_probs = grid_preds[..., 5:]  # クラス確率\n",
    "    \n",
    "    # 絶対座標に変換\n",
    "    absolute_x = (cell_x + np.arange(grid_size)) / grid_size\n",
    "    absolute_y = (cell_y + np.arange(grid_size)[:, np.newaxis]) / grid_size\n",
    "    absolute_w = cell_w * (1 / grid_size)  # 相対幅\n",
    "    absolute_h = cell_h * (1 / grid_size)  # 相対高さ\n",
    "    \n",
    "    # 最も確信度の高いクラスを取得\n",
    "    class_ids = np.argmax(class_probs, axis=-1)\n",
    "    class_confidences = np.max(class_probs, axis=-1)\n",
    "    \n",
    "    # 全体の信頼度を計算\n",
    "    overall_confidence = confidence * class_confidences\n",
    "    \n",
    "    # 検出結果をリストに格納\n",
    "    detections = []\n",
    "    \n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            for b in range(num_boxes):\n",
    "                conf = overall_confidence[i, j, b]\n",
    "                if conf > 0.3:  # 信頼度しきい値\n",
    "                    detection = {\n",
    "                        'x': absolute_x[i, j, b],\n",
    "                        'y': absolute_y[i, j, b],\n",
    "                        'w': absolute_w[i, j, b],\n",
    "                        'h': absolute_h[i, j, b],\n",
    "                        'confidence': conf,\n",
    "                        'class_id': class_ids[i, j, b],\n",
    "                        'class_prob': class_probs[i, j, b, class_ids[i, j, b]]\n",
    "                    }\n",
    "                    detections.append(detection)\n",
    "    \n",
    "    return detections\n",
    "\n",
    "def visualize_yolo_predictions(image, detections, grid_size=7):\n",
    "    \"\"\"YOLOの検出結果を可視化\"\"\"\n",
    "    # 画像サイズ\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    \n",
    "    # 画像のコピーを作成\n",
    "    vis_image = image.copy()\n",
    "    \n",
    "    # ランダムな色を生成\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, 20))\n",
    "    \n",
    "    # 検出を描画\n",
    "    for det in detections[:10]:  # 最初の10個のみ表示\n",
    "        # バウンディングボックスを計算\n",
    "        x1 = int((det['x'] - det['w']/2) * img_w)\n",
    "        y1 = int((det['y'] - det['h']/2) * img_h)\n",
    "        x2 = int((det['x'] + det['w']/2) * img_w)\n",
    "        y2 = int((det['y'] + det['h']/2) * img_h)\n",
    "        \n",
    "        # クラスの色を選択\n",
    "        color = colors[det['class_id']]\n",
    "        color = tuple(int(c * 255) for c in color[:3])\n",
    "        \n",
    "        # バウンディングボックスを描画\n",
    "        cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 3)\n",
    "        \n",
    "        # ラベルを描画\n",
    "        label = f\"Class {det['class_id']}: {det['confidence']:.2f}\"\n",
    "        cv2.putText(vis_image, label, (x1, y1-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"YOLO検出結果\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ダミーデータでテスト\n",
    "dummy_predictions = np.random.random((1, 7, 7, 2, 25))  # batch_size=1\n",
    "detections = yolo_decode_predictions(dummy_predictions)\n",
    "\n",
    "print(f\"検出された物体の数: {len(detections)}\")\n",
    "for i, det in enumerate(detections[:3]):\n",
    "    print(f\"物体 {i+1}: クラス={det['class_id']}, 信頼度={det['confidence']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 26.2: NMS（Non-Maximum Suppression）の実装\n",
    "\n",
    "複数のバウンディングボックスが重なっている場合に、最も良いものを選択するNMSを実装してください。"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_suppression(detections, iou_threshold=0.5, confidence_threshold=0.3):\n",
    "    \"\"\"Non-Maximum Suppressionの実装\"\"\"\n",
    "    # 信頼度でフィルタリング\n",
    "    filtered = [det for det in detections if det['confidence'] > confidence_threshold]\n",
    "    \n",
    "    if not filtered:\n",
    "        return []\n",
    "    \n",
    "    # クラスごとに処理\n",
    "    final_detections = []\n",
    "    \n",
    "    for class_id in range(20):  # クラス数\n",
    "        # 同じクラスの検出を抽出\n",
    "        class_detections = [det for det in filtered if det['class_id'] == class_id]\n",
    "        \n",
    "        if not class_detections:\n",
    "            continue\n",
    "        \n",
    "        # 信頼度でソート（降順）\n",
    "        class_detections.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # NMSを実行\n",
    "        while class_detections:\n",
    "            # 最も信頼度の高い検出を保持\n",
    "            best = class_detections.pop(0)\n",
    "            final_detections.append(best)\n",
    "            \n",
    "            # 重なりの度合いを計算（IoU）\n",
    "            boxes_to_remove = []\n",
    "            for i, det in enumerate(class_detections):\n",
    "                iou = calculate_iou(best, det)\n",
    "                if iou > iou_threshold:\n",
    "                    boxes_to_remove.append(i)\n",
    "            \n",
    "            # 重なっているボックスを削除\n",
    "            for i in reversed(boxes_to_remove):\n",
    "                class_detections.pop(i)\n",
    "    \n",
    "    return final_detections\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"2つのバウンディングボックスのIoUを計算\"\"\"\n",
    "    # 交差領域を計算\n",
    "    x1 = max(box1['x'] - box1['w']/2, box2['x'] - box2['w']/2)\n",
    "    y1 = max(box1['y'] - box1['h']/2, box2['y'] - box2['h']/2)\n",
    "    x2 = min(box1['x'] + box1['w']/2, box2['x'] + box2['w']/2)\n",
    "    y2 = min(box1['y'] + box1['h']/2, box2['y'] + box2['h']/2)\n",
    "    \n",
    "    # 交差領域がなければIoU=0\n",
    "    if x2 < x1 or y2 < y1:\n",
    "        return 0.0\n",
    "    \n",
    "    # 交差面積を計算\n",
    "    intersection = (x2 - x1) * (y2 - y1)\n",
    "    \n",
    "    # 各ボックスの面積\n",
    "    area1 = box1['w'] * box1['h']\n",
    "    area2 = box2['w'] * box2['h']\n",
    "    \n",
    "    # IoUを計算\n",
    "    union = area1 + area2 - intersection\n",
    "    iou = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def visualize_nms_demo():\n",
    "    \"\"\"NMSのデモンストレーション\"\"\"\n",
    "    # ダミーの検出結果\n",
    "    detections = [\n",
    "        {'x': 0.5, 'y': 0.5, 'w': 0.3, 'h': 0.4, 'confidence': 0.9, 'class_id': 0},\n",
    "        {'x': 0.52, 'y': 0.48, 'w': 0.3, 'h': 0.4, 'confidence': 0.85, 'class_id': 0},\n",
    "        {'x': 0.7, 'y': 0.6, 'w': 0.2, 'h': 0.2, 'confidence': 0.8, 'class_id': 0},\n",
    "        {'x': 0.8, 'y': 0.7, 'w': 0.15, 'h': 0.15, 'confidence': 0.75, 'class_id': 0},\n",
    "    ]\n",
    "    \n",
    "    # NMSを実行\n",
    "    nms_detections = non_max_suppression(detections, iou_threshold=0.5)\n",
    "    \n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # NMS前\n",
    "    ax = axes[0]\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title('NMS前')\n",
    "    \n",
    "    for i, det in enumerate(detections):\n",
    "        x1 = det['x'] - det['w']/2\n",
    "        y1 = det['y'] - det['h']/2\n",
    "        rect = plt.Rectangle((x1, y1), det['w'], det['h'],\n",
    "                            fill=False, edgecolor='red', linewidth=2,\n",
    "                            label=f'{det[\"confidence\"]:.2f}')\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(det['x'], det['y'], f'{det[\"confidence\"]:.2f}',\n",
    "                ha='center', va='center', fontsize=10, color='red')\n",
    "    \n",
    "    # NMS後\n",
    "    ax = axes[1]\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'NMS後 (IoU>{0.5})')\n",
    "    \n",
    "    for i, det in enumerate(nms_detections):\n",
    "        x1 = det['x'] - det['w']/2\n",
    "        y1 = det['y'] - det['h']/2\n",
    "        rect = plt.Rectangle((x1, y1), det['w'], det['h'],\n",
    "                            fill=False, edgecolor='blue', linewidth=3)\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(det['x'], det['y'], f'{det[\"confidence\"]:.2f}',\n",
    "                ha='center', va='center', fontsize=10, color='blue')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"NMS前の検出数: {len(detections)}\")\n",
    "    print(f\"NMS後の検出数: {len(nms_detections)}\")\n",
    "    print(f\"削除された検出数: {len(detections) - len(nms_detections)}\")\n",
    "\n",
    "# NMSデモの実行\n",
    "visualize_nms_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 26.3: 実践的な物体検出\n",
    "\n",
    "実際の画像を使って物体検出を実行してみましょう。"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_image_with_objects(num_objects=3):\n",
    "    \"\"\"サンプル画像の作成\"\"\"\n",
    "    # 空の画像を作成\n",
    "    image = np.ones((448, 448, 3), dtype=np.uint8) * 200  # 灰色の背景\n",
    "    \n",
    "    # ランダムな色で円形のオブジェクトを作成\n",
    "    colors = [\n",
    "        (255, 0, 0),    # 赤\n",
    "        (0, 255, 0),    # 緑\n",
    "        (0, 0, 255),    # 青\n",
    "        (255, 255, 0),  # 黄色\n",
    "        (255, 0, 255),  # マゼンタ\n",
    "    ]\n",
    "    \n",
    "    objects = []\n",
    "    \n",
    "    for i in range(num_objects):\n",
    "        # ランダムな位置とサイズ\n",
    "        x = np.random.randint(50, 400)\n",
    "        y = np.random.randint(50, 400)\n",
    "        radius = np.random.randint(30, 80)\n",
    "        color = colors[i % len(colors)]\n",
    "        \n",
    "        # 円を描画\n",
    "        cv2.circle(image, (x, y), radius, color, -1)\n",
    "        \n",
    "        # オブジェクト情報を保存\n",
    "        objects.append({\n",
    "            'x': x / 448,  # 正規化座標\n",
    "            'y': y / 448,\n",
    "            'w': (radius * 2) / 448,\n",
    "            'h': (radius * 2) / 448,\n",
    "            'class_id': i % 3,  # 0, 1, 2のクラス\n",
    "        })\n",
    "    \n",
    "    return image, objects\n",
    "\n",
    "# サンプル画像の作成\n",
    "sample_image, ground_truth = create_sample_image_with_objects(3)\n",
    "\n",
    "# 画像の表示\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"サンプル画像\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"地面の真理値（オブジェクト）:\")\n",
    "for i, obj in enumerate(ground_truth):\n",
    "    print(f\"  オブジェクト{i+1}: クラス={obj['class_id']}, 位置=({obj['x']:.3f}, {obj['y']:.3f}), サイズ=({obj['w']:.3f}, {obj['h']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_detections(ground_truth, predictions, iou_threshold=0.5):\n",
    "    \"\"\"検出結果の評価\"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # グラウンドトゥルースに対応する予測を探す\n",
    "    matched_gt = []\n",
    "    matched_pred = []\n",
    "    \n",
    "    for gt in ground_truth:\n",
    "        best_iou = 0\n",
    "        best_pred_idx = -1\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            if i in matched_pred:\n",
    "                continue  # すでにマッチ済み\n",
    "            \n",
    "            # 同じクラスのみ比較\n",
    "            if gt['class_id'] != pred['class_id']:\n",
    "                continue\n",
    "            \n",
    "            # IoUを計算\n",
    "            iou = calculate_iou(gt, pred)\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_pred_idx = i\n",
    "        \n",
    "        if best_iou > iou_threshold:\n",
    "            true_positives += 1\n",
    "            matched_pred.append(best_pred_idx)\n",
    "            matched_gt.append(True)\n",
    "        else:\n",
    "            false_negatives += 1\n",
    "            matched_gt.append(False)\n",
    "    \n",
    "    # マッチしなかった予測を偽陽性とする\n",
    "    false_positives = len(predictions) - len(matched_pred)\n",
    "    \n",
    "    # 評価指標の計算\n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "# 検出結果をシミュレーション\n",
    "simulated_predictions = [\n",
    "    {'x': 0.25, 'y': 0.25, 'w': 0.15, 'h': 0.15, 'confidence': 0.9, 'class_id': 0},\n",
    "    {'x': 0.65, 'y': 0.7, 'w': 0.2, 'h': 0.2, 'confidence': 0.8, 'class_id': 1},\n",
    "    {'x': 0.45, 'y': 0.45, 'w': 0.1, 'h': 0.1, 'confidence': 0.7, 'class_id': 2},\n",
    "    {'x': 0.8, 'y': 0.8, 'w': 0.05, 'h': 0.05, 'confidence': 0.6, 'class_id': 0},  # 誤検出\n",
    "]\n",
    "\n",
    "# 評価\n",
    "results = evaluate_detections(ground_truth, simulated_predictions)\n",
    "\n",
    "print(f\"検出結果の評価:\")\n",
    "print(f\"  真陽性 (TP): {results['true_positives']}\")\n",
    "print(f\"  偽陽性 (FP): {results['false_positives']}\")\n",
    "print(f\"  偽陰性 (FN): {results['false_negatives']}\")\n",
    "print(f\"  精度 (Precision): {results['precision']:.3f}\")\n",
    "print(f\"  再現率 (Recall): {results['recall']:.3f}\")\n",
    "print(f\"  F1スコア: {results['f1']:.3f}\")\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 真陽性を緑で表示\n",
    "for gt in ground_truth:\n",
    "    x1 = (gt['x'] - gt['w']/2) * 448\n",
    "    y1 = (gt['y'] - gt['h']/2) * 448\n",
    "    rect = plt.Rectangle((x1, y1), gt['w']*448, gt['h']*448,\n",
    "                        fill=False, edgecolor='green', linewidth=2,\n",
    "                        label='Ground Truth')\n",
    "    plt.gca().add_patch(rect)\n",
    "\n",
    "# 予測を表示\n",
    "for i, pred in enumerate(simulated_predictions):\n",
    "    x1 = (pred['x'] - pred['w']/2) * 448\n",
    "    y1 = (pred['y'] - pred['h']/2) * 448\n",
    "    \n",
    "    if i < 3:  # 真陽性\n",
    "        color = 'blue'\n",
    "        alpha = 1.0\n",
    "        label = 'True Positive' if i == 0 else None\n",
    "    else:  # 偽陽性\n",
    "        color = 'red'\n",
    "        alpha = 0.7\n",
    "        label = 'False Positive'\n",
    "    \n",
    "    rect = plt.Rectangle((x1, y1), pred['w']*448, pred['h']*448,\n",
    "                        fill=False, edgecolor=color, linewidth=2, alpha=alpha,\n",
    "                        label=label)\n",
    "    plt.gca().add_patch(rect)\n",
    "    plt.text(pred['x']*448, pred['y']*448, f\"{pred['confidence']:.2f}\",\n",
    "             ha='center', va='center', fontsize=10,\n",
    "             color='blue' if i < 3 else 'red')\n",
    "\n",
    "plt.xlim(0, 448)\n",
    "plt.ylim(0, 448)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('物体検出の評価')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Problem: 物体検出システムの統合\n",
    "\n",
    "以下の要件を満たす完全な物体検出システムを実装してください：\n",
    "\n",
    "1. YOLOの特徴抽出部分\n",
    "2. バウンディングボックスの予測\n",
    "3. NMSによる後処理\n",
    "4. 評価指標の計算\n",
    "5. 結果の可視化"
   ]
  },
  {
   "cell_type": "code",
    "execution_count": null,
    "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleObjectDetector:\n",
    "    \"\"\"シンプルな物体検出システム\"\"\"\n",
    "    def __init__(self, grid_size=7, num_boxes=2, num_classes=3):\n",
    "        self.grid_size = grid_size\n",
    "        self.num_boxes = num_boxes\n",
    "        self.num_classes = num_classes\n",
    "        self.model = None\n",
    "    \n",
    "    def build_model(self):\n",
    "        \"\"\"検出モデルを構築\"\"\"\n",
    "        inputs = keras.Input(shape=(448, 448, 3))\n",
    "        \n",
    "        # 簡単な特徴抽出器\n",
    "        x = layers.Conv2D(32, 3, padding='same', activation='relu')(inputs)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.MaxPooling2D(2)(x)\n",
    "        x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "        # 全結合層\n",
    "        x = layers.Dense(1024, activation='relu')(x)\n",
    "        x = layers.Dropout(0.5)(x)\n",
    "        \n",
    "        # YOLO出力層\n",
    "        output = layers.Dense(\n",
    "            self.grid_size * self.grid_size * (self.num_boxes * 5 + self.num_classes)\n",
    "        )(x)\n",
    "        \n",
    "        self.model = keras.Model(inputs=inputs, outputs=output)\n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, image):\n",
    "        \"\"\"画像からの物体検出\"\"\"\n",
    "        if self.model is None:\n",
    "            self.build_model()\n",
    "        \n",
    "        # 画像を前処理\n",
    "        if image.shape != (448, 448, 3):\n",
    "            image = cv2.resize(image, (448, 448))\n",
    "        \n",
    "        # モデルで予測\n",
    "        prediction = self.model.predict(image[np.newaxis, ...], verbose=0)[0]\n",
    "        \n",
    "        # 予測をデコード\n",
    "        detections = yolo_decode_predictions(\n",
    "            prediction[np.newaxis, ...],\n",
    "            self.grid_size,\n",
    "            self.num_boxes,\n",
    "            self.num_classes\n",
    "        )\n",
    "        \n",
    "        # NMSを適用\n",
    "        detections = non_max_suppression(detections, iou_threshold=0.5)\n",
    "        \n",
    "        return detections\n",
    "    \n",
    "    def evaluate(self, ground_truth, predictions):\n",
    "        \"\"\"評価指標の計算\"\"\"\n",
    "        return evaluate_detections(ground_truth, predictions)\n",
    "    \n",
    "    def visualize(self, image, detections, title=\"物体検出結果\"):\n",
    "        \"\"\"検出結果の可視化\"\"\"\n",
    "        # 画像のコピーを作成\n",
    "        vis_image = image.copy()\n",
    "        \n",
    "        # ランダムな色を生成\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, self.num_classes))\n",
    "        \n",
    "        # 検出を描画\n",
    "        for det in detections:\n",
    "            # バウンディングボックスを計算\n",
    "            x1 = int((det['x'] - det['w']/2) * 448)\n",
    "            y1 = int((det['y'] - det['h']/2) * 448)\n",
    "            x2 = int((det['x'] + det['w']/2) * 448)\n",
    "            y2 = int((det['y'] + det['h']/2) * 448)\n",
    "            \n",
    "            # クラスの色を選択\n",
    "            color = colors[det['class_id']]\n",
    "            color = tuple(int(c * 255) for c in color[:3])\n",
    "            \n",
    "            # バウンディングボックスを描画\n",
    "            cv2.rectangle(vis_image, (x1, y1), (x2, y2), color, 2)\n",
    "            \n",
    "            # ラベルを描画\n",
    "            label = f\"C{det['class_id']}: {det['confidence']:.2f}\"\n",
    "            cv2.putText(vis_image, label, (x1, y1-10),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# 検出システムのテスト\n",
    "detector = SimpleObjectDetector()\n",
    "\n",
    "# 複数のテスト画像を作成\n",
    "test_images = []\n",
    "test_ground_truths = []\n",
    "\n",
    "for i in range(3):\n",
    "    img, gt = create_sample_image_with_objects(num_objects=np.random.randint(2, 5))\n",
    "    test_images.append(img)\n",
    "    test_ground_truths.append(gt)\n",
    "\n",
    "# 予測（ダミーデータ）\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "\n",
    "for img, gt in zip(test_images, test_ground_truths):\n",
    "    # ダミーの予測を生成\n",
    "    predictions = []\n",
    "    \n",
    "    for obj in gt:\n",
    "        # 少しノイズを加えた予測を生成\n",
    "        pred = obj.copy()\n",
    "        pred['x'] += np.random.normal(0, 0.05)\n",
    "        pred['y'] += np.random.normal(0, 0.05)\n",
    "        pred['w'] += np.random.normal(0, 0.05)\n",
    "        pred['h'] += np.random.normal(0, 0.05)\n",
    "        pred['confidence'] = np.random.uniform(0.5, 0.95)\n",
    "        predictions.append(pred)\n",
    "    \n",
    "    # いくつかの偽陽性を追加\n",
    "    if len(predictions) < 5:\n",
    "        predictions.append({\n",
    "            'x': np.random.uniform(0.2, 0.8),\n",
    "            'y': np.random.uniform(0.2, 0.8),\n",
    "            'w': np.random.uniform(0.1, 0.3),\n",
    "            'h': np.random.uniform(0.1, 0.3),\n",
    "            'confidence': np.random.uniform(0.3, 0.7),\n",
    "            'class_id': np.random.randint(0, 3)\n",
    "        })\n",
    "    \n",
    "    all_predictions.append(predictions)\n",
    "    all_ground_truths.append(gt)\n",
    "\n",
    "# 評価\n",
    "for i, (img, gt, pred) in enumerate(zip(test_images, test_ground_truths, all_predictions)):\n",
    "    print(f\"\\nテスト画像 {i+1}:\")\n",
    "    results = detector.evaluate(gt, pred)\n",
    "    print(f\"  精度: {results['precision']:.3f}, 再現率: {results['recall']:.3f}, F1: {results['f1']:.3f}\")\n",
    "    \n",
    "    # 可視化\n",
    "    detector.visualize(img, pred, f\"テスト画像 {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Self-Check (理解度確認)\n",
    "\n",
    "本日の学習内容を確認しましょう：\n",
    "\n",
    "## 基礎知識\n",
    "- [ ] 物体検出の基本的な概念（バウンディングボックス、クラス、信頼度）を理解した\n",
    "- [ ] 2段階検出と一段階検出の違いを理解した\n",
    "- [ ] YOLOの基本原理（グリッド分割、予測形式）を理解した\n",
    "- [ ] NMS（Non-Maximum Suppression）の必要性を理解した\n",
    "\n",
    "## 実践力\n",
    "- [ ] YOLOの基本的な実装ができた\n",
    "- [ ] バウンディングボックスの予測と変換を実装できた\n",
    "- [ ] NMSを自前で実装できた\n",
    "- [ ] 評価指標（精度、再現率、F1スコア）を理解し計算できた\n",
    "\n",
    "## 深層理解\n",
    "- [ ] 物体検出の課題（スケール変化、オクルージョンなど）を理解した\n",
    "- [ ] 速度と精度のトレードオフを理解した\n",
    "- [ ] なぜNMSが必要なのかを理解した\n",
    "- [ ] 実際の応用での考慮事項を理解した\n",
    "\n",
    "---\n",
    "\n",
    "**お疲れ様でした！** Day 26はこれで終了です。\n",
    "\n",
    "次回（Day 27）は「画像生成の基礎」を学び、GANやVAEなどの生成モデルについて学びます。\n",
    "\n",
    "復習課題：\n",
    "1. COCOデータセットを使って実際の物体検出モデルをトレーニングしてみる\n",
    "2. さまざまなIoU閾値での性能を比較する\n",
    "3. Real-time物体検出を実装し、Webカメラからリアルタイムに物体を検出する\n",
    "4. 転移学習を使ってカスタムデータセットで物体検出モデルをファインチューニングする"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
