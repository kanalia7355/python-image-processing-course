{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 20: HOG特徴量とSVM\n",
    "\n",
    "## Learning Objectives\n",
    "- HOG特徴量の抽出方法を理解する\n",
    "- SVMによる物体分類を理解する\n",
    "- ヒューマン検出システムを実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG特徴量の概要\n",
    "\n",
    "Histogram of Oriented Gradients (HOG)は、物体検出で広く使われる特徴量です。画像の勾配の方向をヒストグラムで表現します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "def compute_gradients(image):\n",
    "    \"\"\"画像の勾配を計算する\"\"\"\n",
    "    # Sobelフィルタ\n",
    "    sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])\n",
    "    sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n",
    "    \n",
    "    # 勾配の計算\n",
    "    grad_x = ndimage.convolve(image.astype(float), sobel_x)\n",
    "    grad_y = ndimage.convolve(image.astype(float), sobel_y)\n",
    "    \n",
    "    # 勾配の大きさと方向\n",
    "    magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    angle = np.arctan2(grad_y, grad_x) * 180 / np.pi  # 度数法に変換\n",
    "    \n",
    "    # 角度を0-360度に正規化\n",
    "    angle = angle % 360\n",
    "    \n",
    "    return magnitude, angle\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"テスト用の画像を作成\"\"\"\n",
    "    # 100x100の白い画像\n",
    "    image = np.ones((100, 100)) * 255\n",
    "    \n",
    "    # 矩形パターンを作成\n",
    "    image[30:70, 30:70] = 100\n",
    "    \n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "# テスト画像の作成\n",
    "test_image = create_test_image()\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "plt.title('Test Image')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配の計算\n",
    "magnitude, angle = compute_gradients(test_image)\n",
    "\n",
    "# 勾配の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "ax1.imshow(magnitude, cmap='gray')\n",
    "ax1.set_title('Gradient Magnitude')\n",
    "ax1.axis('off')\n",
    "\n",
    "# 角度のヒートマップ\n",
    "ax2.imshow(angle, cmap='hsv', vmin=0, vmax=360)\n",
    "ax2.set_title('Gradient Angle')\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG特徴量の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hog_features(image, cell_size=8, bin_size=9):\n",
    "    \"\"\"HOG特徴量を計算する\"\"\"\n",
    "    # 1. 画像の勾配を計算\n",
    "    magnitude, angle = compute_gradients(image)\n",
    "    \n",
    "    # 2. セルに分割\n",
    "    h, w = image.shape\n",
    "    cells_h = h // cell_size\n",
    "    cells_w = w // cell_size\n",
    "    \n",
    "    # 3. 各セルのヒストグラムを計算\n",
    "    hog_features = []\n",
    "    \n",
    "    for cy in range(cells_h):\n",
    "        cell_hog = []\n",
    "        for cx in range(cells_w):\n",
    "            # セルの領域を切り出し\n",
    "            cell_mag = magnitude[cy*cell_size:(cy+1)*cell_size, cx*cell_size:(cx+1)*cell_size]\n",
    "            cell_angle = angle[cy*cell_size:(cy+1)*cell_size, cx*cell_size:(cx+1)*cell_size]\n",
    "            \n",
    "            # ヒストグラムの初期化\n",
    "            hist = np.zeros(bin_size)\n",
    "            \n",
    "            # 角度ビンに割り当て\n",
    "            bin_width = 360 / bin_size\n",
    "            \n",
    "            for y in range(cell_size):\n",
    "                for x in range(cell_size):\n",
    "                    if cell_mag[y, x] > 0:  # 勾配が0でないピクセルのみ\n",
    "                        # 角度をビンインデックスに変換\n",
    "                        bin_idx = int(cell_angle[y, x] / bin_width) % bin_size\n",
    "                        hist[bin_idx] += cell_mag[y, x]\n",
    "            \n",
    "            cell_hog.append(hist)\n",
    "        \n",
    "        hog_features.append(cell_hog)\n",
    "    \n",
    "    return np.array(hog_features), (cells_h, cells_w)\n",
    "\n",
    "# HOG特徴量の計算\n",
    "hog_features, (cells_h, cells_w) = compute_hog_features(test_image)\n",
    "print(f\"HOG特徴量の形状: {hog_features.shape}\")\n",
    "print(f\"セル数: {cells_h} x {cells_w}\")\n",
    "print(f\"各セルのヒストグラム（最初のセル）: {hog_features[0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hog_features(image, hog_features):\n",
    "    \"\"\"HOG特徴量を可視化する\"\"\"\n",
    "    magnitude, angle = compute_gradients(image)\n",
    "    h, w = image.shape\n",
    "    cell_size = h // hog_features.shape[0]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # 原始画像\n",
    "    ax1.imshow(image, cmap='gray')\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # HOG特徴量の可視化\n",
    "    ax2.imshow(image, cmap='gray')\n",
    "    \n",
    "    # 各セルに向きの矢印を描画\n",
    "    for cy in range(hog_features.shape[0]):\n",
    "        for cx in range(hog_features.shape[1]):\n",
    "            # セルの中心座標\n",
    "            center_y = cy * cell_size + cell_size // 2\n",
    "            center_x = cx * cell_size + cell_size // 2\n",
    "            \n",
    "            # ヒストグラムから主な向きを決定\n",
    "            hist = hog_features[cy, cx]\n",
    "            dominant_bin = np.argmax(hist)\n",
    "            \n",
    "            # ビンの角度を計算\n",
    "            angle = dominant_bin * (360 / len(hist))\n",
    "            \n",
    "            # 矢印の長さ（ヒストグラムの値に比例）\n",
    "            arrow_length = np.sqrt(np.sum(hist)) * 0.5\n",
    "            \n",
    "            # 角度をラジアンに変換\n",
    "            angle_rad = np.deg2rad(angle)\n",
    "            \n",
    "            # 矢印の終点座標\n",
    "            end_x = center_x + arrow_length * np.cos(angle_rad)\n",
    "            end_y = center_y + arrow_length * np.sin(angle_rad)\n",
    "            \n",
    "            # 矢印を描画\n",
    "            ax2.arrow(center_x, center_y, end_x - center_x, end_y - center_y,\n",
    "                     head_width=3, head_length=2, fc='red', ec='red')\n",
    "    \n",
    "    ax2.set_title('HOG Features')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# HOG特徴量の可視化\n",
    "visualize_hog_features(test_image, hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVMによる物体分類\n",
    "\n",
    "Support Vector Machine (SVM)を使って、HOG特徴量に基づいて物体を分類します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(num_positive=50, num_negative=50):\n",
    "    \"\"\"訓練データを作成する\"\"\"\n",
    "    X = []  # 特徴量\n",
    "    y = []  # ラベル（1: 正例, -1: 負例）\n",
    "    \n",
    "    # 正例（ヒューマンのような形状）\n",
    "    for i in range(num_positive):\n",
    "        # ランダムな位置に人間のような形状を作成\n",
    "        h, w = 64, 32\n",
    "        image = np.ones((h, w)) * 50  # 暗い背景\n",
    "        \n",
    "        # 身体（長方形）\n",
    "        body_y = np.random.randint(10, 40)\n",
    "        image[body_y:body_y+20, 8:w-8] = 200  # 明るい身体\n",
    "        \n",
    "        # 頭（円）\n",
    "        head_y = body_y - 10\n",
    "        head_x = w // 2\n",
    "        for y in range(max(0, head_y-8), min(h, head_y+8)):\n",
    "            for x in range(max(0, head_x-8), min(w, head_x+8)):\n",
    "                if (x - head_x)**2 + (y - head_y)**2 <= 64:  # 半径8の円\n",
    "                    image[y, x] = 200\n",
    "        \n",
    "        X.append(image)\n",
    "        y.append(1)\n",
    "    \n",
    "    # 負例（ランダムなノイズ）\n",
    "    for i in range(num_negative):\n",
    "        h, w = 64, 32\n",
    "        image = np.random.randint(0, 255, (h, w))\n",
    "        \n",
    "        X.append(image)\n",
    "        y.append(-1)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 訓練データの作成\n",
    "X_train, y_train = create_training_data()\n",
    "print(f\"訓練データの形状: {X_train.shape}\")\n",
    "print(f\"正例の数: {np.sum(y_train == 1)}\")\n",
    "print(f\"負例の数: {np.sum(y_train == -1)}\")\n",
    "\n",
    "# 訓練データの表示\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 正例を表示\n",
    "for i in range(5):\n",
    "    axes[i].imshow(X_train[i], cmap='gray')\n",
    "    axes[i].set_title('Positive')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "# 負例を表示\n",
    "for i in range(5, 10):\n",
    "    axes[i].imshow(X_train[i+num_positive], cmap='gray')\n",
    "    axes[i].set_title('Negative')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSVM:\n",
    "    \"\"\"シンプルなSVM実装\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_iters = n_iters\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # 重みの初期化\n",
    "        self.w = np.zeros(n_features)\n",
    "        self.b = 0\n",
    "        \n",
    "        # 勾配降下法\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                # 条件: y_i * (w · x_i + b) >= 1\n",
    "                condition = y[idx] * (np.dot(x_i, self.w) + self.b) >= 1\n",
    "                \n",
    "                if condition:\n",
    "                    # マージンから外れている点ではない場合\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w)\n",
    "                else:\n",
    "                    # マージンから外れている点の場合\n",
    "                    self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y[idx]))\n",
    "                    self.b -= self.lr * y[idx]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        approx = np.dot(X, self.w) + self.b\n",
    "        return np.sign(approx)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\"分類関数の値を返す（距離）\"\"\"\n",
    "        return np.dot(X, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features_batch(images):\n",
    "    \"\"\"画像バッチのHOG特徴量を抽出\"\"\"\n",
    "    features = []\n",
    "    for img in images:\n",
    "        # 画像を64x32にリサイズ（訓練データと同じサイズ）\n",
    "        from scipy.ndimage import zoom\n",
    "        if img.shape != (64, 32):\n",
    "            img_resized = zoom(img, (64/img.shape[0], 32/img.shape[1]), order=1)\n",
    "        else:\n",
    "            img_resized = img\n",
    "        \n",
    "        # HOG特徴量を抽出（1次元にフラット化）\n",
    "        hog_feat, _ = compute_hog_features(img_resized)\n",
    "        features.append(hog_feat.flatten())\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# 訓練データからHOG特徴量を抽出\n",
    "X_train_hog = extract_hog_features_batch(X_train)\n",
    "print(f\"HOG特徴量の形状: {X_train_hog.shape}\")\n",
    "\n",
    "# SVMの学習\n",
    "svm = SimpleSVM(learning_rate=0.01, n_iters=1000)\n",
    "svm.fit(X_train_hog, y_train)\n",
    "\n",
    "print(\"SVMの学習完了\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ヒューマン検出システムの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"2つのバウンディングボックスのIOUを計算\"\"\"\n",
    "    x1_min, y1_min, x1_max, y1_max = box1\n",
    "    x2_min, y2_min, x2_max, y2_max = box2\n",
    "    \n",
    "    # 交差領域を計算\n",
    "    inter_x_min = max(x1_min, x2_min)\n",
    "    inter_y_min = max(y1_min, y2_min)\n",
    "    inter_x_max = min(x1_max, x2_max)\n",
    "    inter_y_max = min(y1_max, y2_max)\n",
    "    \n",
    "    if inter_x_max < inter_x_min or inter_y_max < inter_y_min:\n",
    "        return 0.0\n",
    "    \n",
    "    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)\n",
    "    area1 = (x1_max - x1_min) * (y1_max - y1_min)\n",
    "    area2 = (x2_max - x2_min) * (y2_max - y2_min)\n",
    "    union_area = area1 + area2 - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0.0\n",
    "\n",
    "def sliding_window_hog_detection(image, window_size, step_size, svm, threshold=0):\n",
    "    \"\"\"スライディングウィンドウでヒューマン検出\"\"\"\n",
    "    detections = []\n",
    "    h, w = image.shape\n",
    "    win_h, win_w = window_size\n",
    "    \n",
    "    for y in range(0, h - win_h + 1, step_size):\n",
    "        for x in range(0, w - win_w + 1, step_size):\n",
    "            # ウィンドウを切り出し\n",
    "            window = image[y:y+win_h, x:x+win_w]\n",
    "            \n",
    "            # HOG特徴量を抽出\n",
    "            hog_feat, _ = compute_hog_features(window)\n",
    "            features = hog_feat.flatten().reshape(1, -1)\n",
    "            \n",
    "            # SVMで予測\n",
    "            decision_value = svm.decision_function(features)[0]\n",
    "            \n",
    "            # しきい値を超えていれば検出\n",
    "            if decision_value > threshold:\n",
    "                # スコアを保存\n",
    "                detections.append((x, y, win_w, win_h, decision_value))\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト画像を作成（ヒューマンを含む）\n",
    "def create_test_image_with_human():\n",
    "    \"\"\"ヒューマンを含むテスト画像\"\"\"\n",
    "    image = np.ones((200, 200)) * 50  # 暗い背景\n",
    "    \n",
    "    # ヒューマン1\n",
    "    body_y1, body_x1 = 50, 50\n",
    "    image[body_y1:body_y1+40, body_x1:body_x1+20] = 200  # 身体\n",
    "    # 頭\n",
    "    head_y1, head_x1 = body_y1 - 15, body_x1 + 5\n",
    "    for y in range(max(0, head_y1-10), min(200, head_y1+10)):\n",
    "        for x in range(max(0, head_x1-10), min(200, head_x1+10)):\n",
    "            if (x - head_x1)**2 + (y - head_y1)**2 <= 100:\n",
    "                image[y, x] = 200\n",
    "    \n",
    "    # ヒューマン2\n",
    "    body_y2, body_x2 = 120, 120\n",
    "    image[body_y2:body_y2+40, body_x2:body_x2+20] = 200  # 身体\n",
    "    # 頭\n",
    "    head_y2, head_x2 = body_y2 - 15, body_x2 + 5\n",
    "    for y in range(max(0, head_y2-10), min(200, head_y2+10)):\n",
    "        for x in range(max(0, head_x2-10), min(200, head_x2+10)):\n",
    "            if (x - head_x2)**2 + (y - head_y2)**2 <= 100:\n",
    "                image[y, x] = 200\n",
    "    \n",
    "    return image\n",
    "\n",
    "# テスト画像の作成と表示\n",
    "test_image_with_human = create_test_image_with_human()\n",
    "plt.imshow(test_image_with_human, cmap='gray')\n",
    "plt.title('Test Image with Humans')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ヒューマン検出を実行\n",
    "detections = sliding_window_hog_detection(\n",
    "    test_image_with_human,\n",
    "    window_size=(64, 32),\n",
    "    step_size=16,\n",
    "    svm=svm,\n",
    "    threshold=0\n",
    ")\n",
    "\n",
    "print(f\"検出されたヒューマン数: {len(detections)}\")\n",
    "for i, (x, y, w, h, score) in enumerate(detections):\n",
    "    print(f\"ヒューマン {i+1}: 位置=({x}, {y}), サイズ=({w}, {h}), スコア={score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_human_detections(image, detections):\n",
    "    \"\"\"ヒューマン検出結果を可視化\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    \n",
    "    # 検出枠を描画\n",
    "    for x, y, w, h, score in detections:\n",
    "        rect = Rectangle((x, y), w, h, linewidth=2, edgecolor='red', facecolor='none')\n",
    "        plt.gca().add_patch(rect)\n",
    "        # スコアを表示\n",
    "        plt.text(x, y-5, f'{score:.2f}', color='red', fontsize=10)\n",
    "    \n",
    "    plt.title('Human Detection Results')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 検出結果の可視化\n",
    "visualize_human_detections(test_image_with_human, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 誤検出の削除（NMSを使用）\n",
    "def nms_for_human_detections(detections, iou_threshold=0.3):\n",
    "    \"\"\"ヒューマン検出に対するNMS\"\"\"\n",
    "    if len(detections) == 0:\n",
    "        return []\n",
    "    \n",
    "    # スコア順にソート\n",
    "    detections_sorted = sorted(detections, key=lambda x: x[4], reverse=True)\n",
    "    \n",
    "    suppressed = []\n",
    "    used = [False] * len(detections_sorted)\n",
    "    \n",
    "    for i in range(len(detections_sorted)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        \n",
    "        suppressed.append(detections_sorted[i])\n",
    "        used[i] = True\n",
    "        \n",
    "        # 重なっている検出を抑制\n",
    "        for j in range(i+1, len(detections_sorted)):\n",
    "            if not used[j]:\n",
    "                box1 = (detections_sorted[i][0], detections_sorted[i][1], \n",
    "                       detections_sorted[i][2], detections_sorted[i][3])\n",
    "                box2 = (detections_sorted[j][0], detections_sorted[j][1], \n",
    "                       detections_sorted[j][2], detections_sorted[j][3])\n",
    "                \n",
    "                if calculate_iou(box1, box2) > iou_threshold:\n",
    "                    used[j] = True\n",
    "    \n",
    "    return suppressed\n",
    "\n",
    "# NMSを適用\n",
    "final_detections = nms_for_human_detections(detections)\n",
    "print(f\"NMS後の検出数: {len(final_detections)}\")\n",
    "\n",
    "# 最終結果の可視化\n",
    "visualize_human_detections(test_image_with_human, final_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめと次のステップ\n",
    "\n",
    "### 習得したスキル:\n",
    "- [x] HOG特徴量の抽出方法を理解した\n",
    "- [x] SVMによる物体分類を実装した\n",
    "- [x] ヒューマン検出システムを構築した\n",
    "- [x] スライディングウィンドウとHOGを組み合わせた\n",
    "\n",
    "### 考察:\n",
    "1. HOG特徴量は物体の形状を効果的に捉えられる\n",
    "2. SVMは2値分離に強く、物体検出に適している\n",
    "3. スライディングウィンドウとの組み合わせで、画像中の物体を検出できる\n",
    "4. NMSを使うことで重複検出を削除できる\n",
    "\n",
    "### 次のステップ:\n",
    "- より複雑な物体検出（顔検出など）\n",
    "- 深層学習による特徴量抽出（CNN）\n",
    "- 実-time物体検出の実装"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}